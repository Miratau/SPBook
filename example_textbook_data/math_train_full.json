{
    "data": [
        {
            "title": "1-1-definitions-of-statistics-probability-and-key-terms",
            "paragraphs": [
                {
                    "context": "In your classroom, try this exercise. Have class members write down the average time (in hours, to the nearest half-hour) they sleep per night. Your instructor will record the data. Then create a simple graph (called a dot plot) of the data. A dot plot consists of a number line and dots (or points) positioned above the number line. For example, consider the following data:\n\n5; 5.5; 6; 6; 6; 6.5; 6.5; 6.5; 6.5; 7; 7; 8; 8; 9\n\nThe dot plot for this data would be as follows:\n\nDoes your dot plot look the same as or different from the example? Why? If you did the same example in an English class with the same number of students, do you think the results would be the same? Why or why not?\n\nWhere do your data appear to cluster? How might you interpret the clustering?\n\nThe questions above ask you to analyze and interpret your data. With this example, you have begun your study of statistics.\n\nIn this course, you will learn how to organize and summarize data. Organizing and summarizing data is called descriptive statistics. Two ways to summarize data are by graphing and by using numbers (for example, finding an average). After you have studied probability and probability distributions, you will use formal methods for drawing conclusions from \"good\" data. The formal methods are called inferential statistics. Statistical inference uses probability to determine how confident we can be that our conclusions are correct.\n\nEffective interpretation of data (inference) is based on good procedures for producing data and thoughtful examination of the data. You will encounter what will seem to be too many mathematical formulas for interpreting data. The goal of statistics is not to perform numerous calculations using the formulas, but to gain an understanding of your data. The calculations can be done using a calculator or a computer. The understanding must come from you. If you can thoroughly grasp the basics of statistics, you can be more confident in the decisions you make in life.",
                    "id": "C_136166_0"
                }
            ],
            "section_title": "Collaborative Exercise",
            "chapter_learning_objectives": [],
            "chapter_summary": "The mathematical theory of statistics is easier to learn when you know the language. This module presents important terms that will be used throughout the text.",
            "chapter_introduction": "The science of statistics deals with the collection, analysis, interpretation, and presentation of data. We see and use data in our everyday lives. ",
            "bold_terms": [
                "statistics",
                "data",
                "dot plot",
                "descriptive statistics",
                "inferential statistics",
                "Probability",
                "fair",
                "Pearson",
                "population",
                "sample",
                "sampling",
                "statistic",
                "parameter",
                "representative sample",
                "variable",
                "numerical",
                "categorical",
                "Numerical variables",
                "Categorical variables",
                "Data",
                "Datum",
                "mean",
                "proportion",
                "average"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-1-definitions-of-statistics-probability-and-key-terms",
            "paragraphs": [
                {
                    "context": "Probability is a mathematical tool used to study randomness. It deals with the chance (the likelihood) of an event occurring. For example, if you toss a fair coin four times, the outcomes may not be two heads and two tails. However, if you toss the same coin 4,000 times, the outcomes will be close to half heads and half tails. The expected theoretical probability of heads in any one toss is $$\\(\\frac{1}{2}\\)$$ or 0.5. Even though the outcomes of a few repetitions are uncertain, there is a regular pattern of outcomes when there are many repetitions. After reading about the English statistician Karl Pearson who tossed a coin 24,000 times with a result of 12,012 heads, one of the authors tossed a coin 2,000 times. The results were 996 heads. The fraction $$\\(\\frac{996}{2000}\\)$$ is equal to 0.498 which is very close to 0.5, the expected probability.\n\nThe theory of probability began with the study of games of chance such as poker. Predictions take the form of probabilities. To predict the likelihood of an earthquake, of rain, or whether you will get an A in this course, we use probabilities. Doctors use probability to determine the chance of a vaccination causing the disease the vaccination is supposed to prevent. A stockbroker uses probability to determine the rate of return on a client's investments. You might use probability to decide to buy a lottery ticket or not. In your study of statistics, you will use the power of mathematics through probability calculations to analyze and interpret your data.",
                    "id": "C_87971_1"
                }
            ],
            "section_title": "Probability",
            "chapter_learning_objectives": [],
            "chapter_summary": "The mathematical theory of statistics is easier to learn when you know the language. This module presents important terms that will be used throughout the text.",
            "chapter_introduction": "The science of statistics deals with the collection, analysis, interpretation, and presentation of data. We see and use data in our everyday lives. ",
            "bold_terms": [
                "statistics",
                "data",
                "dot plot",
                "descriptive statistics",
                "inferential statistics",
                "Probability",
                "fair",
                "Pearson",
                "population",
                "sample",
                "sampling",
                "statistic",
                "parameter",
                "representative sample",
                "variable",
                "numerical",
                "categorical",
                "Numerical variables",
                "Categorical variables",
                "Data",
                "Datum",
                "mean",
                "proportion",
                "average"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-1-definitions-of-statistics-probability-and-key-terms",
            "paragraphs": [
                {
                    "context": "In statistics, we generally want to study a population. You can think of a population as a collection of persons, things, or objects under study. To study the population, we select a sample. The idea of sampling is to select a portion (or subset) of the larger population and study that portion (the sample) to gain information about the population. Data are the result of sampling from a population.\n\nBecause it takes a lot of time and money to examine an entire population, sampling is a very practical technique. If you wished to compute the overall grade point average at your school, it would make sense to select a sample of students who attend the school. The data collected from the sample would be the students' grade point averages. In presidential elections, opinion poll samples of 1,000\u20132,000 people are taken. The opinion poll is supposed to represent the views of the people in the entire country. Manufacturers of canned carbonated drinks take samples to determine if a 16 ounce can contains 16 ounces of carbonated drink.\n\nFrom the sample data, we can calculate a statistic. A statistic is a number that represents a property of the sample. For example, if we consider one math class to be a sample of the population of all math classes, then the average number of points earned by students in that one math class at the end of the term is an example of a statistic. The statistic is an estimate of a population parameter. A parameter is a numerical characteristic of the whole population that can be estimated by a statistic. Since we considered all math classes to be the population, then the average number of points earned per student over all the math classes is an example of a parameter.\n\nOne of the main concerns in the field of statistics is how accurately a statistic estimates a parameter. The accuracy really depends on how well the sample represents the population. The sample must contain the characteristics of the population in order to be a representative sample. We are interested in both the sample statistic and the population parameter in inferential statistics. In a later chapter, we will use the sample statistic to test the validity of the established population parameter.\n\nA variable, usually notated by capital letters such as X and Y, is a characteristic or measurement that can be determined for each member of a population. Variables may be numerical or categorical. Numerical variables take on values with equal units such as weight in pounds and time in hours. Categorical variables place the person or thing into a category. If we let X equal the number of points earned by one math student at the end of a term, then X is a numerical variable. If we let Y be a person's party affiliation, then some examples of Y include Republican, Democrat, and Independent. Y is a categorical variable. We could do some math with values of X (calculate the average number of points earned, for example), but it makes no sense to do math with values of Y (calculating an average party affiliation makes no sense).\n\nData are the actual values of the variable. They may be numbers or they may be words. Datum is a single value.\n\nTwo words that come up often in statistics are mean and proportion. If you were to take three exams in your math classes and obtain scores of 86, 75, and 92, you would calculate your mean score by adding the three exam scores and dividing by three (your mean score would be 84.3 to one decimal place). If, in your math class, there are 40 students and 22 are men and 18 are women, then the proportion of men students is $$\\(\\frac{22}{40}\\)$$ and the proportion of women students is $$\\(\\frac{18}{40}\\)$$. Mean and proportion are discussed in more detail in later chapters.",
                    "id": "C_539736_2"
                }
            ],
            "section_title": "Key Terms",
            "chapter_learning_objectives": [],
            "chapter_summary": "The mathematical theory of statistics is easier to learn when you know the language. This module presents important terms that will be used throughout the text.",
            "chapter_introduction": "The science of statistics deals with the collection, analysis, interpretation, and presentation of data. We see and use data in our everyday lives. ",
            "bold_terms": [
                "statistics",
                "data",
                "dot plot",
                "descriptive statistics",
                "inferential statistics",
                "Probability",
                "fair",
                "Pearson",
                "population",
                "sample",
                "sampling",
                "statistic",
                "parameter",
                "representative sample",
                "variable",
                "numerical",
                "categorical",
                "Numerical variables",
                "Categorical variables",
                "Data",
                "Datum",
                "mean",
                "proportion",
                "average"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-1-definitions-of-statistics-probability-and-key-terms",
            "paragraphs": [
                {
                    "context": "The words \"mean\" and \"average\" are often used interchangeably. The substitution of one word for the other is common practice. The technical term is \"arithmetic mean,\" and \"average\" is technically a center location. However, in practice among non-statisticians, \"average\" is commonly accepted for \"arithmetic mean.\"",
                    "id": "C_225839_3"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "The mathematical theory of statistics is easier to learn when you know the language. This module presents important terms that will be used throughout the text.",
            "chapter_introduction": "The science of statistics deals with the collection, analysis, interpretation, and presentation of data. We see and use data in our everyday lives. ",
            "bold_terms": [
                "statistics",
                "data",
                "dot plot",
                "descriptive statistics",
                "inferential statistics",
                "Probability",
                "fair",
                "Pearson",
                "population",
                "sample",
                "sampling",
                "statistic",
                "parameter",
                "representative sample",
                "variable",
                "numerical",
                "categorical",
                "Numerical variables",
                "Categorical variables",
                "Data",
                "Datum",
                "mean",
                "proportion",
                "average"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-1-definitions-of-statistics-probability-and-key-terms",
            "paragraphs": [
                {
                    "context": "Do the following exercise collaboratively with up to four people per group. Find a population, a sample, the parameter, the statistic, a variable, and data for the following study: You want to determine the average (mean) number of glasses of milk college students drink per day. Suppose yesterday, in your English class, you asked five students how many glasses of milk they drank the day before. The answers were 1, 0, 1, 3, and 4 glasses of milk.",
                    "id": "C_420810_4"
                }
            ],
            "section_title": "Collaborative Exercise",
            "chapter_learning_objectives": [],
            "chapter_summary": "The mathematical theory of statistics is easier to learn when you know the language. This module presents important terms that will be used throughout the text.",
            "chapter_introduction": "The science of statistics deals with the collection, analysis, interpretation, and presentation of data. We see and use data in our everyday lives. ",
            "bold_terms": [
                "statistics",
                "data",
                "dot plot",
                "descriptive statistics",
                "inferential statistics",
                "Probability",
                "fair",
                "Pearson",
                "population",
                "sample",
                "sampling",
                "statistic",
                "parameter",
                "representative sample",
                "variable",
                "numerical",
                "categorical",
                "Numerical variables",
                "Categorical variables",
                "Data",
                "Datum",
                "mean",
                "proportion",
                "average"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-2-data-sampling-and-variation-in-data-and-sampling",
            "paragraphs": [
                {
                    "context": "You may collect data as numbers and report it categorically. For example, the quiz scores for each student are recorded throughout the term. At the end of the term, the quiz scores are reported as A, B, C, D, or F.",
                    "id": "C_447042_0"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "Data are individual items of information that come from a population or sample. Data may be classified as qualitative (categorical), quantitative continuous, or quantitative discrete.Because it is not practical to measure the entire population in a study, researchers use samples to represent the population. A random sample is a representative group from the population chosen by using a method that gives each individual in the population an equal chance of being included in the sample. Random sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Convenience sampling is a nonrandom method of choosing a sample that often produces biaseddata.Samples that contain different individuals result in different data. This is true even when the samples are well-chosen and representative of the population. When properly selected, larger samples model the population more closely than smaller samples. There are many different potential problems that can affect the reliability of a sample. Statistical data needs to be critically analyzed, not simply accepted.",
            "chapter_introduction": "Data may come from a population or from a sample. Lowercase letters like $$\\(x\\)$$ or $$\\(y\\)$$ generally are used to represent data values. Most data can be put into the following categories:\n\nQualitative Quantitative \n\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative data. Qualitative data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\n\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\n\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\n\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often  the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like 2.4, 7.5, or 11.0, would be quantitative continuous data.",
            "bold_terms": [
                "Qualitative data",
                "categorical data",
                "Quantitative data",
                "counting",
                "measuring",
                "discrete",
                "continuous",
                "quantitative discrete data",
                "quantitative continuous data",
                "pie chart",
                "bar graph",
                "Pareto chart",
                "A sample should have the same characteristics as the population it is representing",
                "random sampling",
                "simple random sample",
                "Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample",
                "stratified sample",
                "proportionate",
                "cluster sample",
                "systematic sample",
                "Convenience sampling",
                "with replacement",
                "without replacement",
                "For any particular sample of 1,000",
                "with replacement for any particular sample",
                "sampling errors",
                "nonsampling errors",
                "a sampling bias",
                "Variation",
                "samples",
                "population",
                "variability in samples"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-2-data-sampling-and-variation-in-data-and-sampling",
            "paragraphs": [
                {
                    "context": "Below are tables comparing the number of part-time and full-time students at De Anza College and Foothill College enrolled for the spring 2010 quarter. The tables display counts (frequencies) and percentages or proportions (relative frequencies). The percent columns make comparing the same categories in the colleges easier. Displaying percentages along with the numbers is often helpful, but it is particularly important when comparing sets of data that do not have the same totals, such as the total enrollments for both colleges in this example. Notice how much larger the percentage for part-time students at Foothill College is compared to De Anza College.\n\nTables are a good way of organizing and displaying data.  But graphs can be even more helpful in understanding the data. There are no strict rules concerning which graphs to use.  Two graphs that are used to display qualitative data are pie charts and bar graphs.\n\nIn a pie chart, categories of data are represented by wedges in a circle and are proportional in size to the percent of individuals in each category.\n\nIn a bar graph, the length of the bar for each category is proportional to the number or percent of individuals in each category.  Bars may be vertical or horizontal.\n\nA Pareto chart consists of bars that are sorted into order by category size (largest to smallest).\n\nLook at Figure 1.5 and Figure 1.6 and determine which graph (pie or bar) you think displays the comparisons better.\n\nIt is a good idea to look at a variety of graphs to see which is the most helpful in displaying the data.  We might make different choices of what we think is the \u201cbest\u201d graph depending on the data and the context.  Our choice also depends on what we are using the data for.",
                    "id": "C_264026_1"
                }
            ],
            "section_title": "Qualitative Data Discussion",
            "chapter_learning_objectives": [],
            "chapter_summary": "Data are individual items of information that come from a population or sample. Data may be classified as qualitative (categorical), quantitative continuous, or quantitative discrete.Because it is not practical to measure the entire population in a study, researchers use samples to represent the population. A random sample is a representative group from the population chosen by using a method that gives each individual in the population an equal chance of being included in the sample. Random sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Convenience sampling is a nonrandom method of choosing a sample that often produces biaseddata.Samples that contain different individuals result in different data. This is true even when the samples are well-chosen and representative of the population. When properly selected, larger samples model the population more closely than smaller samples. There are many different potential problems that can affect the reliability of a sample. Statistical data needs to be critically analyzed, not simply accepted.",
            "chapter_introduction": "Data may come from a population or from a sample. Lowercase letters like $$\\(x\\)$$ or $$\\(y\\)$$ generally are used to represent data values. Most data can be put into the following categories:\n\nQualitative Quantitative \n\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative data. Qualitative data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\n\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\n\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\n\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often  the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like 2.4, 7.5, or 11.0, would be quantitative continuous data.",
            "bold_terms": [
                "Qualitative data",
                "categorical data",
                "Quantitative data",
                "counting",
                "measuring",
                "discrete",
                "continuous",
                "quantitative discrete data",
                "quantitative continuous data",
                "pie chart",
                "bar graph",
                "Pareto chart",
                "A sample should have the same characteristics as the population it is representing",
                "random sampling",
                "simple random sample",
                "Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample",
                "stratified sample",
                "proportionate",
                "cluster sample",
                "systematic sample",
                "Convenience sampling",
                "with replacement",
                "without replacement",
                "For any particular sample of 1,000",
                "with replacement for any particular sample",
                "sampling errors",
                "nonsampling errors",
                "a sampling bias",
                "Variation",
                "samples",
                "population",
                "variability in samples"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-2-data-sampling-and-variation-in-data-and-sampling",
            "paragraphs": [
                {
                    "context": "Sometimes percentages add up to be more than 100% (or less than 100%). In the graph, the percentages add to more than 100% because students can be in more than one category. A bar graph is appropriate to compare the relative size of the categories. A pie chart cannot be used.  It also could not be used if the percentages added to less than 100%.",
                    "id": "C_187356_2"
                }
            ],
            "section_title": "Percentages That Add to More (or Less) Than 100",
            "chapter_learning_objectives": [],
            "chapter_summary": "Data are individual items of information that come from a population or sample. Data may be classified as qualitative (categorical), quantitative continuous, or quantitative discrete.Because it is not practical to measure the entire population in a study, researchers use samples to represent the population. A random sample is a representative group from the population chosen by using a method that gives each individual in the population an equal chance of being included in the sample. Random sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Convenience sampling is a nonrandom method of choosing a sample that often produces biaseddata.Samples that contain different individuals result in different data. This is true even when the samples are well-chosen and representative of the population. When properly selected, larger samples model the population more closely than smaller samples. There are many different potential problems that can affect the reliability of a sample. Statistical data needs to be critically analyzed, not simply accepted.",
            "chapter_introduction": "Data may come from a population or from a sample. Lowercase letters like $$\\(x\\)$$ or $$\\(y\\)$$ generally are used to represent data values. Most data can be put into the following categories:\n\nQualitative Quantitative \n\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative data. Qualitative data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\n\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\n\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\n\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often  the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like 2.4, 7.5, or 11.0, would be quantitative continuous data.",
            "bold_terms": [
                "Qualitative data",
                "categorical data",
                "Quantitative data",
                "counting",
                "measuring",
                "discrete",
                "continuous",
                "quantitative discrete data",
                "quantitative continuous data",
                "pie chart",
                "bar graph",
                "Pareto chart",
                "A sample should have the same characteristics as the population it is representing",
                "random sampling",
                "simple random sample",
                "Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample",
                "stratified sample",
                "proportionate",
                "cluster sample",
                "systematic sample",
                "Convenience sampling",
                "with replacement",
                "without replacement",
                "For any particular sample of 1,000",
                "with replacement for any particular sample",
                "sampling errors",
                "nonsampling errors",
                "a sampling bias",
                "Variation",
                "samples",
                "population",
                "variability in samples"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-2-data-sampling-and-variation-in-data-and-sampling",
            "paragraphs": [
                {
                    "context": "The table displays Ethnicity of Students but is missing the \"Other/Unknown\" category.  This category contains people who did not feel they fit into any of the ethnicity categories or declined to respond.  Notice that the frequencies do not add up to the total number of students. In this situation, create a bar graph and not a pie chart.\n\nThe following graph is the same as the previous graph but the \u201cOther/Unknown\u201d percent (9.6%) has been included. The \u201cOther/Unknown\u201d category is large compared to some of the other categories (Native American, 0.6%, Pacific Islander 1.0%). This is important to know when we think about what the data are telling us.\n\nThis particular bar graph in Figure 1.9 can be difficult to understand visually. The graph in Figure 1.10 is a Pareto chart. The Pareto chart has the bars sorted from largest to smallest and is easier to read and interpret.",
                    "id": "C_96251_3"
                }
            ],
            "section_title": "Omitting Categories/Missing Data",
            "chapter_learning_objectives": [],
            "chapter_summary": "Data are individual items of information that come from a population or sample. Data may be classified as qualitative (categorical), quantitative continuous, or quantitative discrete.Because it is not practical to measure the entire population in a study, researchers use samples to represent the population. A random sample is a representative group from the population chosen by using a method that gives each individual in the population an equal chance of being included in the sample. Random sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Convenience sampling is a nonrandom method of choosing a sample that often produces biaseddata.Samples that contain different individuals result in different data. This is true even when the samples are well-chosen and representative of the population. When properly selected, larger samples model the population more closely than smaller samples. There are many different potential problems that can affect the reliability of a sample. Statistical data needs to be critically analyzed, not simply accepted.",
            "chapter_introduction": "Data may come from a population or from a sample. Lowercase letters like $$\\(x\\)$$ or $$\\(y\\)$$ generally are used to represent data values. Most data can be put into the following categories:\n\nQualitative Quantitative \n\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative data. Qualitative data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\n\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\n\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\n\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often  the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like 2.4, 7.5, or 11.0, would be quantitative continuous data.",
            "bold_terms": [
                "Qualitative data",
                "categorical data",
                "Quantitative data",
                "counting",
                "measuring",
                "discrete",
                "continuous",
                "quantitative discrete data",
                "quantitative continuous data",
                "pie chart",
                "bar graph",
                "Pareto chart",
                "A sample should have the same characteristics as the population it is representing",
                "random sampling",
                "simple random sample",
                "Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample",
                "stratified sample",
                "proportionate",
                "cluster sample",
                "systematic sample",
                "Convenience sampling",
                "with replacement",
                "without replacement",
                "For any particular sample of 1,000",
                "with replacement for any particular sample",
                "sampling errors",
                "nonsampling errors",
                "a sampling bias",
                "Variation",
                "samples",
                "population",
                "variability in samples"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-2-data-sampling-and-variation-in-data-and-sampling",
            "paragraphs": [
                {
                    "context": "The following pie charts have the \u201cOther/Unknown\u201d category included (since the percentages must add to 100%). The chart in Figure 1.11(b) is organized by the size of each wedge, which makes it a more visually informative graph than the unsorted, alphabetical graph in Figure 1.11(a).",
                    "id": "C_852834_4"
                }
            ],
            "section_title": "Pie Charts:  No Missing Data",
            "chapter_learning_objectives": [],
            "chapter_summary": "Data are individual items of information that come from a population or sample. Data may be classified as qualitative (categorical), quantitative continuous, or quantitative discrete.Because it is not practical to measure the entire population in a study, researchers use samples to represent the population. A random sample is a representative group from the population chosen by using a method that gives each individual in the population an equal chance of being included in the sample. Random sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Convenience sampling is a nonrandom method of choosing a sample that often produces biaseddata.Samples that contain different individuals result in different data. This is true even when the samples are well-chosen and representative of the population. When properly selected, larger samples model the population more closely than smaller samples. There are many different potential problems that can affect the reliability of a sample. Statistical data needs to be critically analyzed, not simply accepted.",
            "chapter_introduction": "Data may come from a population or from a sample. Lowercase letters like $$\\(x\\)$$ or $$\\(y\\)$$ generally are used to represent data values. Most data can be put into the following categories:\n\nQualitative Quantitative \n\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative data. Qualitative data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\n\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\n\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\n\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often  the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like 2.4, 7.5, or 11.0, would be quantitative continuous data.",
            "bold_terms": [
                "Qualitative data",
                "categorical data",
                "Quantitative data",
                "counting",
                "measuring",
                "discrete",
                "continuous",
                "quantitative discrete data",
                "quantitative continuous data",
                "pie chart",
                "bar graph",
                "Pareto chart",
                "A sample should have the same characteristics as the population it is representing",
                "random sampling",
                "simple random sample",
                "Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample",
                "stratified sample",
                "proportionate",
                "cluster sample",
                "systematic sample",
                "Convenience sampling",
                "with replacement",
                "without replacement",
                "For any particular sample of 1,000",
                "with replacement for any particular sample",
                "sampling errors",
                "nonsampling errors",
                "a sampling bias",
                "Variation",
                "samples",
                "population",
                "variability in samples"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-2-data-sampling-and-variation-in-data-and-sampling",
            "paragraphs": [
                {
                    "context": "Gathering information about an entire population often costs too much or is virtually impossible. Instead, we use a sample of the population. A sample should have the same characteristics as the population it is representing. Most statisticians use various methods of random sampling in an attempt to achieve this goal. This section will describe a few of the most common methods. There are several different methods of random sampling. In each form of random sampling, each member of a population initially has an equal chance of being selected for the sample. Each method has pros and cons. The easiest method to describe is called a simple random sample. Any group of n individuals is equally likely to be chosen as any other group of n individuals if the simple random sampling technique is used. In other words, each sample of the same size has an equal chance of being selected. For example, suppose Lisa wants to form a four-person study group (herself and three other people) from her pre-calculus class, which has 31 members not including Lisa. To choose a simple random sample of size three from the other members of her class, Lisa could put all 31 names in a hat, shake the hat, close her eyes, and pick out three names. A more technological way is for Lisa to first list the last names of the members of her class together with a two-digit number, as in Table 1.5:\n\nLisa can use a table of random numbers (found in many statistics books and mathematical handbooks), a calculator, or a computer to generate random numbers. For this example, suppose Lisa chooses to generate random numbers from a calculator. The numbers generated are as follows:\n\n0.94360; 0.99832; 0.14669; 0.51470; 0.40581; 0.73381; 0.04399\n\nLisa reads two-digit groups until she has chosen three class members (that is, she reads 0.94360 as thegroups 94, 43, 36, 60). Each random number may only contribute one class member. If she needed to, Lisacould have generated more random numbers.\n\nThe random numbers 0.94360 and 0.99832 do not contain appropriate two digit numbers. However the third random number, 0.14669, contains 14 (the fourth random number also contains 14), the fifth random number contains 05, and the seventh random number contains 04. The two-digit number 14 corresponds to Macierz, 05 corresponds to Cuningham, and 04 corresponds to Cuarismo. Besides herself, Lisa\u2019s group will consist of Marcierz, Cuningham, and Cuarismo.",
                    "id": "C_318166_5"
                }
            ],
            "section_title": "Sampling",
            "chapter_learning_objectives": [],
            "chapter_summary": "Data are individual items of information that come from a population or sample. Data may be classified as qualitative (categorical), quantitative continuous, or quantitative discrete.Because it is not practical to measure the entire population in a study, researchers use samples to represent the population. A random sample is a representative group from the population chosen by using a method that gives each individual in the population an equal chance of being included in the sample. Random sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Convenience sampling is a nonrandom method of choosing a sample that often produces biaseddata.Samples that contain different individuals result in different data. This is true even when the samples are well-chosen and representative of the population. When properly selected, larger samples model the population more closely than smaller samples. There are many different potential problems that can affect the reliability of a sample. Statistical data needs to be critically analyzed, not simply accepted.",
            "chapter_introduction": "Data may come from a population or from a sample. Lowercase letters like $$\\(x\\)$$ or $$\\(y\\)$$ generally are used to represent data values. Most data can be put into the following categories:\n\nQualitative Quantitative \n\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative data. Qualitative data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\n\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\n\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\n\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often  the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like 2.4, 7.5, or 11.0, would be quantitative continuous data.",
            "bold_terms": [
                "Qualitative data",
                "categorical data",
                "Quantitative data",
                "counting",
                "measuring",
                "discrete",
                "continuous",
                "quantitative discrete data",
                "quantitative continuous data",
                "pie chart",
                "bar graph",
                "Pareto chart",
                "A sample should have the same characteristics as the population it is representing",
                "random sampling",
                "simple random sample",
                "Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample",
                "stratified sample",
                "proportionate",
                "cluster sample",
                "systematic sample",
                "Convenience sampling",
                "with replacement",
                "without replacement",
                "For any particular sample of 1,000",
                "with replacement for any particular sample",
                "sampling errors",
                "nonsampling errors",
                "a sampling bias",
                "Variation",
                "samples",
                "population",
                "variability in samples"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-2-data-sampling-and-variation-in-data-and-sampling",
            "paragraphs": [
                {
                    "context": "To generate random numbers:\n\nPress MATH. Arrow over to PRB. Press 5:randInt(.  Enter 0, 30). Press ENTER for the first random number. Press ENTER two more times for the other 2 random numbers. If there is a repeat press ENTER again. \n\nNote: randInt(0, 30, 3) will generate 3 random numbers.\n\nBesides simple random sampling, there are other forms of sampling that involve a chance process for getting the sample. Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample.\n\nTo choose a stratified sample, divide the population into groups called strata and then take a proportionate number from each stratum. For example, you could stratify (group) your college population by department and then choose a proportionate simple random sample from each stratum (each department) to get a stratified random sample. To choose a simple random sample from each department, number each member of the first department, number each member of the second department, and do the same for the remaining departments. Then use simple random sampling to choose proportionate numbers from the first department and do the same for each of the remaining departments. Those numbers picked from the first department, picked from the second department, and so on represent the members who make up the stratified sample.\n\nTo choose a cluster sample, divide the population into clusters (groups) and then randomly select some of the clusters. All the members from these clusters are in the cluster sample. For example, if you randomly sample four departments from your college population, the four departments make up the cluster sample. Divide your college faculty by department. The departments are the clusters. Number each department, and then choose four different numbers using simple random sampling. All members of the four departments with those numbers are the cluster sample.\n\nTo choose a systematic sample, randomly select a starting point and take every nth piece of data from a listing of the population. For example, suppose you have to do a phone survey. Your phone book contains 20,000 residence listings. You must choose 400 names for the sample. Number the population 1\u201320,000 and then use a simple random sample to pick a number that represents the first name in the sample. Then choose every fiftieth name thereafter until you have a total of 400 names (you might have to go back to the beginning of your phone list). Systematic sampling is frequently chosen because it is a simple method.\n\nA type of sampling that is non-random is convenience sampling. Convenience sampling involves using results that are readily available. For example, a computer software store conducts a marketing study by interviewing potential customers who happen to be in the store browsing through the available software. The results of convenience sampling may be very good in some cases and highly biased (favor certain outcomes) in others.\n\nSampling data should be done very carefully. Collecting data carelessly can have devastating results. Surveys mailed to households and then returned may be very biased (they may favor a certain group). It is better for the person conducting the survey to select the sample respondents.\n\nTrue random sampling is done with replacement.  That is, once a member is picked, that member goes back into the population and thus may be chosen more than once. However for practical reasons, in most populations, simple random sampling is done without replacement. Surveys are typically done without replacement.  That is, a member of the population may be chosen only once.  Most samples are taken from large populations and the sample tends to be small in comparison to the population. Since this is the case, sampling without replacement is approximately the same as sampling with replacement because the chance of picking the same individual more than once with replacement is very low.\n\nIn a college population of 10,000 people, suppose you want to pick a sample of1,000 randomly for a survey. For any particular sample of 1,000, if you are sampling with replacement, \n\nthe chance of picking the first person is 1,000 out of 10,000 (0.1000); the chance of picking a different second person for this sample is 999 out of 10,000 (0.0999); the chance of picking the same person again is 1 out of 10,000 (very low).  \n\nIf you are sampling without replacement,\n\nthe chance of picking the first person for any particular sample is 1000 out of 10,000 (0.1000); the chance of picking a different second person is 999 out of 9,999 (0.0999); you do not replace the first person before picking the next person. \n\nCompare the fractions 999/10,000 and 999/9,999. For accuracy, carry the decimal answers to four decimal places. To four decimal places, these numbers are equivalent (0.0999).\n\nSampling without replacement instead of sampling with replacement becomes a mathematical issueonly when the population is small. For example, if the population is 25 people, the sample is ten, andyou are sampling with replacement for any particular sample, then the chance of picking the first person is ten out of 25, and the chance of picking a different second person is nine out of 25 (you replace the first person).\n\nIf you sample without replacement, then the chance of picking the first person is ten out of 25, and then the chance of picking the second person (who is different) is nine out of 24 (you do not replace the first person).\n\nCompare the fractions 9/25 and 9/24. To four decimal places, 9/25 = 0.3600 and 9/24 = 0.3750. Tofour decimal places, these numbers are not equivalent.\n\nWhen you analyze data, it is important to be aware of sampling errors and nonsampling errors. The actual process of sampling causes sampling errors. For example, the sample may not be large enough. Factors not related to the sampling process cause nonsampling errors. A defective counting device can cause a nonsampling error.\n\nIn reality, a sample will never be exactly representative of the population so there will always be some sampling error.  As a rule, the larger the sample, the smaller the sampling error.\n\nIn statistics, a sampling bias is created when a sample is collected from a population and some members of the population are not as likely to be chosen as others (remember, each member of the population should have an equally likely chance of being chosen).  When a sampling bias happens, there can be incorrect conclusions drawn about the population that is being studied.",
                    "id": "C_685839_6"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "Data are individual items of information that come from a population or sample. Data may be classified as qualitative (categorical), quantitative continuous, or quantitative discrete.Because it is not practical to measure the entire population in a study, researchers use samples to represent the population. A random sample is a representative group from the population chosen by using a method that gives each individual in the population an equal chance of being included in the sample. Random sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Convenience sampling is a nonrandom method of choosing a sample that often produces biaseddata.Samples that contain different individuals result in different data. This is true even when the samples are well-chosen and representative of the population. When properly selected, larger samples model the population more closely than smaller samples. There are many different potential problems that can affect the reliability of a sample. Statistical data needs to be critically analyzed, not simply accepted.",
            "chapter_introduction": "Data may come from a population or from a sample. Lowercase letters like $$\\(x\\)$$ or $$\\(y\\)$$ generally are used to represent data values. Most data can be put into the following categories:\n\nQualitative Quantitative \n\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative data. Qualitative data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\n\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\n\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\n\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often  the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like 2.4, 7.5, or 11.0, would be quantitative continuous data.",
            "bold_terms": [
                "Qualitative data",
                "categorical data",
                "Quantitative data",
                "counting",
                "measuring",
                "discrete",
                "continuous",
                "quantitative discrete data",
                "quantitative continuous data",
                "pie chart",
                "bar graph",
                "Pareto chart",
                "A sample should have the same characteristics as the population it is representing",
                "random sampling",
                "simple random sample",
                "Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample",
                "stratified sample",
                "proportionate",
                "cluster sample",
                "systematic sample",
                "Convenience sampling",
                "with replacement",
                "without replacement",
                "For any particular sample of 1,000",
                "with replacement for any particular sample",
                "sampling errors",
                "nonsampling errors",
                "a sampling bias",
                "Variation",
                "samples",
                "population",
                "variability in samples"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-2-data-sampling-and-variation-in-data-and-sampling",
            "paragraphs": [
                {
                    "context": "We need to evaluate the statistical studies we read about critically and analyze them before accepting the results of the studies. Common problems to be aware of include\n\nProblems with samples: A sample must be representative of the population. A sample that is not representative of the population is biased. Biased samples that are not representative of the population give results that are inaccurate and not valid. Self-selected samples: Responses only by people who choose to respond, such as call-insurveys, are often unreliable. Sample size issues: Samples that are too small may be unreliable. Larger samples are better, if possible. In some situations, having small samples is unavoidable and can still be used to draw conclusions. Examples: crash testing cars or medical testing for rare conditions Undue influence: \u00a0collecting data or asking questions in a way that influences the response Non-response or refusal of subject to participate: \u00a0The collected responses may no longer be representative of the population. \u00a0Often, people with strong positive or negative opinions may answer surveys, which can affect the results. Causality: A relationship between two variables does not mean that one causes the other to occur. They may be related (correlated) because of their relationship through a different variable. Self-funded or self-interest studies: A study performed by a person or organization in order to support their claim. Is the study impartial? Read the study carefully to evaluate the work. Do not automatically assume that the study is good, but do not automatically assume the study is bad either. Evaluate it on its merits and the work done. Misleading use of data: improperly displayed graphs, incomplete data, or lack of context Confounding: \u00a0When the effects of multiple factors on a response cannot be separated. \u00a0Confounding makes it difficult or impossible to draw valid conclusions about the effect of each factor. ",
                    "id": "C_602220_7"
                }
            ],
            "section_title": "Critical Evaluation",
            "chapter_learning_objectives": [],
            "chapter_summary": "Data are individual items of information that come from a population or sample. Data may be classified as qualitative (categorical), quantitative continuous, or quantitative discrete.Because it is not practical to measure the entire population in a study, researchers use samples to represent the population. A random sample is a representative group from the population chosen by using a method that gives each individual in the population an equal chance of being included in the sample. Random sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Convenience sampling is a nonrandom method of choosing a sample that often produces biaseddata.Samples that contain different individuals result in different data. This is true even when the samples are well-chosen and representative of the population. When properly selected, larger samples model the population more closely than smaller samples. There are many different potential problems that can affect the reliability of a sample. Statistical data needs to be critically analyzed, not simply accepted.",
            "chapter_introduction": "Data may come from a population or from a sample. Lowercase letters like $$\\(x\\)$$ or $$\\(y\\)$$ generally are used to represent data values. Most data can be put into the following categories:\n\nQualitative Quantitative \n\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative data. Qualitative data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\n\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\n\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\n\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often  the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like 2.4, 7.5, or 11.0, would be quantitative continuous data.",
            "bold_terms": [
                "Qualitative data",
                "categorical data",
                "Quantitative data",
                "counting",
                "measuring",
                "discrete",
                "continuous",
                "quantitative discrete data",
                "quantitative continuous data",
                "pie chart",
                "bar graph",
                "Pareto chart",
                "A sample should have the same characteristics as the population it is representing",
                "random sampling",
                "simple random sample",
                "Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample",
                "stratified sample",
                "proportionate",
                "cluster sample",
                "systematic sample",
                "Convenience sampling",
                "with replacement",
                "without replacement",
                "For any particular sample of 1,000",
                "with replacement for any particular sample",
                "sampling errors",
                "nonsampling errors",
                "a sampling bias",
                "Variation",
                "samples",
                "population",
                "variability in samples"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-2-data-sampling-and-variation-in-data-and-sampling",
            "paragraphs": [
                {
                    "context": "As a class, determine whether or not the following samples are representative. If they are not, discuss the reasons.\n\nTo find the average GPA of all students in a university, use all honor students at the university as the sample. To find out the most popular cereal among young people under the age of ten, stand outside a large supermarket for three hours and speak to every twentieth child under age ten who enters the supermarket. To find the average annual income of all adults in the United States, sample U.S. congressmen. Create a cluster sample by considering each state as a stratum (group).  By using simple random sampling, select states to be part of the cluster.  Then survey every U.S. congressman in the cluster. To determine the proportion of people taking public transportation to work, survey 20 people in New York City. Conduct the survey by sitting in Central Park on a bench and interviewing every person who sits next to you. To determine the average cost of a two-day stay in a hospital in Massachusetts, survey 100 hospitals across the state using simple random sampling. \n\nIf we were to examine two samples representing the same population, even if we used random sampling methods for the samples, they would not be exactly the same. Just as there is variation in data, there is variation in samples. As you become accustomed to sampling, the variability will begin to seem natural.",
                    "id": "C_211768_8"
                }
            ],
            "section_title": "Collaborative Exercise",
            "chapter_learning_objectives": [],
            "chapter_summary": "Data are individual items of information that come from a population or sample. Data may be classified as qualitative (categorical), quantitative continuous, or quantitative discrete.Because it is not practical to measure the entire population in a study, researchers use samples to represent the population. A random sample is a representative group from the population chosen by using a method that gives each individual in the population an equal chance of being included in the sample. Random sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Convenience sampling is a nonrandom method of choosing a sample that often produces biaseddata.Samples that contain different individuals result in different data. This is true even when the samples are well-chosen and representative of the population. When properly selected, larger samples model the population more closely than smaller samples. There are many different potential problems that can affect the reliability of a sample. Statistical data needs to be critically analyzed, not simply accepted.",
            "chapter_introduction": "Data may come from a population or from a sample. Lowercase letters like $$\\(x\\)$$ or $$\\(y\\)$$ generally are used to represent data values. Most data can be put into the following categories:\n\nQualitative Quantitative \n\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative data. Qualitative data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\n\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\n\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\n\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often  the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like 2.4, 7.5, or 11.0, would be quantitative continuous data.",
            "bold_terms": [
                "Qualitative data",
                "categorical data",
                "Quantitative data",
                "counting",
                "measuring",
                "discrete",
                "continuous",
                "quantitative discrete data",
                "quantitative continuous data",
                "pie chart",
                "bar graph",
                "Pareto chart",
                "A sample should have the same characteristics as the population it is representing",
                "random sampling",
                "simple random sample",
                "Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample",
                "stratified sample",
                "proportionate",
                "cluster sample",
                "systematic sample",
                "Convenience sampling",
                "with replacement",
                "without replacement",
                "For any particular sample of 1,000",
                "with replacement for any particular sample",
                "sampling errors",
                "nonsampling errors",
                "a sampling bias",
                "Variation",
                "samples",
                "population",
                "variability in samples"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-2-data-sampling-and-variation-in-data-and-sampling",
            "paragraphs": [
                {
                    "context": "Variation is present in any set of data. For example, 16-ounce cans of beverage may contain more or less than 16 ounces of liquid. In one study, eight 16 ounce cans were measured and produced the following amount (in ounces) of beverage:\n\n15.8; 16.1; 15.2; 14.8; 15.8; 15.9; 16.0; 15.5\n\nMeasurements of the amount of beverage in a 16-ounce can may vary because different people make the measurements or because the exact amount, 16 ounces of liquid, was not put into the cans. Manufacturers regularly run tests to determine if the amount of beverage in a 16-ounce can falls within the desired range.\n\nBe aware that as you take data, your data may vary somewhat from the data someone else is taking for the same purpose. This is completely natural. However, if two or more of you are taking the same data and get very different results, it is time for you and the others to reevaluate your data-taking methods and your accuracy.",
                    "id": "C_379231_9"
                }
            ],
            "section_title": "Variation in Data",
            "chapter_learning_objectives": [],
            "chapter_summary": "Data are individual items of information that come from a population or sample. Data may be classified as qualitative (categorical), quantitative continuous, or quantitative discrete.Because it is not practical to measure the entire population in a study, researchers use samples to represent the population. A random sample is a representative group from the population chosen by using a method that gives each individual in the population an equal chance of being included in the sample. Random sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Convenience sampling is a nonrandom method of choosing a sample that often produces biaseddata.Samples that contain different individuals result in different data. This is true even when the samples are well-chosen and representative of the population. When properly selected, larger samples model the population more closely than smaller samples. There are many different potential problems that can affect the reliability of a sample. Statistical data needs to be critically analyzed, not simply accepted.",
            "chapter_introduction": "Data may come from a population or from a sample. Lowercase letters like $$\\(x\\)$$ or $$\\(y\\)$$ generally are used to represent data values. Most data can be put into the following categories:\n\nQualitative Quantitative \n\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative data. Qualitative data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\n\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\n\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\n\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often  the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like 2.4, 7.5, or 11.0, would be quantitative continuous data.",
            "bold_terms": [
                "Qualitative data",
                "categorical data",
                "Quantitative data",
                "counting",
                "measuring",
                "discrete",
                "continuous",
                "quantitative discrete data",
                "quantitative continuous data",
                "pie chart",
                "bar graph",
                "Pareto chart",
                "A sample should have the same characteristics as the population it is representing",
                "random sampling",
                "simple random sample",
                "Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample",
                "stratified sample",
                "proportionate",
                "cluster sample",
                "systematic sample",
                "Convenience sampling",
                "with replacement",
                "without replacement",
                "For any particular sample of 1,000",
                "with replacement for any particular sample",
                "sampling errors",
                "nonsampling errors",
                "a sampling bias",
                "Variation",
                "samples",
                "population",
                "variability in samples"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-2-data-sampling-and-variation-in-data-and-sampling",
            "paragraphs": [
                {
                    "context": "It was mentioned previously that two or more samples from the same population, taken randomly, and having close to the same characteristics of the population will likely be different from each other. Suppose Doreen and Jung both decide to study the average amount of time students at their college sleep each night.  Doreen and Jung each take samples of 500 students. Doreen uses systematic sampling and Jung uses cluster sampling. Doreen's sample will be different from Jung's sample. Even if Doreen and Jung used the same sampling method, in all likelihood their samples would be different. Neither would be wrong, however. \n\nThink about what contributes to making Doreen\u2019s and Jung\u2019s samples different. \n\nIf Doreen and Jung took larger samples (i.e. the number of data values is increased), their sample results (the average amount of time a student sleeps) might be closer to the actual population average. But still, their samples would be, in all likelihood, different from each other. This variability in samples cannot be stressed enough.",
                    "id": "C_445229_10"
                }
            ],
            "section_title": "Variation in Samples",
            "chapter_learning_objectives": [],
            "chapter_summary": "Data are individual items of information that come from a population or sample. Data may be classified as qualitative (categorical), quantitative continuous, or quantitative discrete.Because it is not practical to measure the entire population in a study, researchers use samples to represent the population. A random sample is a representative group from the population chosen by using a method that gives each individual in the population an equal chance of being included in the sample. Random sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Convenience sampling is a nonrandom method of choosing a sample that often produces biaseddata.Samples that contain different individuals result in different data. This is true even when the samples are well-chosen and representative of the population. When properly selected, larger samples model the population more closely than smaller samples. There are many different potential problems that can affect the reliability of a sample. Statistical data needs to be critically analyzed, not simply accepted.",
            "chapter_introduction": "Data may come from a population or from a sample. Lowercase letters like $$\\(x\\)$$ or $$\\(y\\)$$ generally are used to represent data values. Most data can be put into the following categories:\n\nQualitative Quantitative \n\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative data. Qualitative data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\n\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\n\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\n\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often  the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like 2.4, 7.5, or 11.0, would be quantitative continuous data.",
            "bold_terms": [
                "Qualitative data",
                "categorical data",
                "Quantitative data",
                "counting",
                "measuring",
                "discrete",
                "continuous",
                "quantitative discrete data",
                "quantitative continuous data",
                "pie chart",
                "bar graph",
                "Pareto chart",
                "A sample should have the same characteristics as the population it is representing",
                "random sampling",
                "simple random sample",
                "Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample",
                "stratified sample",
                "proportionate",
                "cluster sample",
                "systematic sample",
                "Convenience sampling",
                "with replacement",
                "without replacement",
                "For any particular sample of 1,000",
                "with replacement for any particular sample",
                "sampling errors",
                "nonsampling errors",
                "a sampling bias",
                "Variation",
                "samples",
                "population",
                "variability in samples"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-2-data-sampling-and-variation-in-data-and-sampling",
            "paragraphs": [
                {
                    "context": "The size of a sample (often called the number of observations) is important. The examples you have seen in this book so far have been small. Samples of only a few hundred observations, or even smaller, are sufficient for many purposes. In polling, samples that are from 1,200 to 1,500 observations are considered large enough and good enough if the survey is random and is well done. You will learn why when you study confidence intervals.\n\nBe aware that many large samples are biased. For example, call-in surveys are invariably biased, because people choose to respond or not.",
                    "id": "C_580267_11"
                }
            ],
            "section_title": "Size of a Sample",
            "chapter_learning_objectives": [],
            "chapter_summary": "Data are individual items of information that come from a population or sample. Data may be classified as qualitative (categorical), quantitative continuous, or quantitative discrete.Because it is not practical to measure the entire population in a study, researchers use samples to represent the population. A random sample is a representative group from the population chosen by using a method that gives each individual in the population an equal chance of being included in the sample. Random sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Convenience sampling is a nonrandom method of choosing a sample that often produces biaseddata.Samples that contain different individuals result in different data. This is true even when the samples are well-chosen and representative of the population. When properly selected, larger samples model the population more closely than smaller samples. There are many different potential problems that can affect the reliability of a sample. Statistical data needs to be critically analyzed, not simply accepted.",
            "chapter_introduction": "Data may come from a population or from a sample. Lowercase letters like $$\\(x\\)$$ or $$\\(y\\)$$ generally are used to represent data values. Most data can be put into the following categories:\n\nQualitative Quantitative \n\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative data. Qualitative data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\n\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\n\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\n\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often  the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like 2.4, 7.5, or 11.0, would be quantitative continuous data.",
            "bold_terms": [
                "Qualitative data",
                "categorical data",
                "Quantitative data",
                "counting",
                "measuring",
                "discrete",
                "continuous",
                "quantitative discrete data",
                "quantitative continuous data",
                "pie chart",
                "bar graph",
                "Pareto chart",
                "A sample should have the same characteristics as the population it is representing",
                "random sampling",
                "simple random sample",
                "Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample",
                "stratified sample",
                "proportionate",
                "cluster sample",
                "systematic sample",
                "Convenience sampling",
                "with replacement",
                "without replacement",
                "For any particular sample of 1,000",
                "with replacement for any particular sample",
                "sampling errors",
                "nonsampling errors",
                "a sampling bias",
                "Variation",
                "samples",
                "population",
                "variability in samples"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-2-data-sampling-and-variation-in-data-and-sampling",
            "paragraphs": [
                {
                    "context": "Divide into groups of two, three, or four. Your instructor will give each group one six-sided die. Try this experiment twice. Roll one fair die (six-sided) 20 times. Record the number of ones, twos, threes, fours, fives, and sixes you get in Table 1.7 and Table 1.8 (\u201cfrequency\u201d is the number of times a particular face of the die occurs):\n\nDid the two experiments have the same results? Probably not. If you did the experiment a third time, do you expect the results to be identical to the first or second experiment? Why or why not? \n\nWhich experiment had the correct results? They both did. The job of the statistician is to see through the variability and draw appropriate conclusions.",
                    "id": "C_740177_12"
                }
            ],
            "section_title": "Collaborative Exercise",
            "chapter_learning_objectives": [],
            "chapter_summary": "Data are individual items of information that come from a population or sample. Data may be classified as qualitative (categorical), quantitative continuous, or quantitative discrete.Because it is not practical to measure the entire population in a study, researchers use samples to represent the population. A random sample is a representative group from the population chosen by using a method that gives each individual in the population an equal chance of being included in the sample. Random sampling methods include simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Convenience sampling is a nonrandom method of choosing a sample that often produces biaseddata.Samples that contain different individuals result in different data. This is true even when the samples are well-chosen and representative of the population. When properly selected, larger samples model the population more closely than smaller samples. There are many different potential problems that can affect the reliability of a sample. Statistical data needs to be critically analyzed, not simply accepted.",
            "chapter_introduction": "Data may come from a population or from a sample. Lowercase letters like $$\\(x\\)$$ or $$\\(y\\)$$ generally are used to represent data values. Most data can be put into the following categories:\n\nQualitative Quantitative \n\nQualitative data are the result of categorizing or describing attributes of a population. Qualitative data are also often called categorical data. Hair color, blood type, ethnic group, the car a person drives, and the street a person lives on are examples of qualitative data. Qualitative data are generally described by words or letters. For instance, hair color might be black, dark brown, light brown, blonde, gray, or red. Blood type might be AB+, O-, or B+. Researchers often prefer to use quantitative data over qualitative data because it lends itself more easily to mathematical analysis. For example, it does not make sense to find an average hair color or blood type.\n\nQuantitative data are always numbers. Quantitative data are the result of counting or measuring attributes of a population. Amount of money, pulse rate, weight, number of people living in your town, and number of students who take statistics are examples of quantitative data. Quantitative data may be either discrete or continuous.\n\nAll data that are the result of counting are called quantitative discrete data. These data take on only certain numerical values. If you count the number of phone calls you receive for each day of the week, you might get values such as zero, one, two, or three.\n\nData that are not only made up of counting numbers, but that may include fractions, decimals, or irrational numbers, are called quantitative continuous data. Continuous data are often  the results of measurements like lengths, weights, or times. A list of the lengths in minutes for all the phone calls that you make in a week, with numbers like 2.4, 7.5, or 11.0, would be quantitative continuous data.",
            "bold_terms": [
                "Qualitative data",
                "categorical data",
                "Quantitative data",
                "counting",
                "measuring",
                "discrete",
                "continuous",
                "quantitative discrete data",
                "quantitative continuous data",
                "pie chart",
                "bar graph",
                "Pareto chart",
                "A sample should have the same characteristics as the population it is representing",
                "random sampling",
                "simple random sample",
                "Other well-known random sampling methods are the stratified sample, the cluster sample, and the systematic sample",
                "stratified sample",
                "proportionate",
                "cluster sample",
                "systematic sample",
                "Convenience sampling",
                "with replacement",
                "without replacement",
                "For any particular sample of 1,000",
                "with replacement for any particular sample",
                "sampling errors",
                "nonsampling errors",
                "a sampling bias",
                "Variation",
                "samples",
                "population",
                "variability in samples"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-3-frequency-frequency-tables-and-levels-of-measurement",
            "paragraphs": [
                {
                    "context": "A simple way to round off answers is to carry your final answer one more decimal place than was present in the original data. Round off only the final answer. Do not round off any intermediate results, if possible. If it becomes necessary to round off intermediate results, carry them to at least twice as many decimal places as the final answer. For example, the average of the three quiz scores four, six, and nine is 6.3, rounded off to the nearest tenth, because the data are whole numbers. Most answers will be rounded off in this manner.\n\nIt is not necessary to reduce most fractions in this course. Especially in Probability Topics, the chapter on probability, it is more helpful to leave an answer as an unreduced fraction.",
                    "id": "C_803000_0"
                }
            ],
            "section_title": "Answers and Rounding Off",
            "chapter_learning_objectives": [],
            "chapter_summary": "Some calculations generate numbers that are artificially precise. It is not necessary to report a value to eight decimal places when the measures that generated that value were only accurate to the nearest tenth. Round off your final answer to one more decimal place than was present in the original data. This means that if you have data measured to the nearest tenth of a unit, report the final statistic to the nearest hundredth.In addition to rounding your answers, you can measure your data using the following four levels of measurement.Nominal scale level: data that cannot be ordered nor can it be used in calculations Ordinal scale level: data that can be ordered; the differences cannot be measured Interval scale level: data with a definite ordering but no starting point; the differences can be measured, but there is no such thing as a ratio. Ratio scale level: data with a starting point that can be ordered; the differences have meaning and ratios can be calculated. When organizing data, it is important to know how many times a value appears. How many statistics students study five hours or more for an exam? What percent of families on our block own two pets? Frequency, relative frequency, and cumulative relative frequency are measures that answer questions like these.",
            "chapter_introduction": "Once you have a set of data, you will need to organize it so that you can analyze how frequently each datum occurs in the set. However, when calculating the frequency, you may need to round your answers so that they are as precise as possible.",
            "bold_terms": [
                "level of measurement",
                "Nominal scale level",
                "Ordinal scale level",
                "Interval scale level",
                "Ratio scale level",
                "nominal scale",
                "qualitative (categorical",
                "ordinal scale",
                "interval scale",
                "ratio scale",
                "frequency",
                "relative frequency",
                "Cumulative relative frequency",
                "grouped",
                "five",
                "three",
                "15",
                "40",
                "17",
                "12",
                "seven",
                "one"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-3-frequency-frequency-tables-and-levels-of-measurement",
            "paragraphs": [
                {
                    "context": "The way a set of data is measured is called its level of measurement. Correct statistical procedures depend on a researcher being familiar with levels of measurement. Not every statistical operation can be used with every set of data. Data can be classified into four levels of measurement. They are (from lowest to highest level):\n\nNominal scale level Ordinal scale level Interval scale level Ratio scale level \n\nData that is measured using a nominal scale is qualitative (categorical). Categories, colors, names, labels and favorite foods along with yes or no responses are examples of nominal level data. Nominal scale data are not ordered. For example, trying to classify people according to their favorite food does not make any sense. Putting pizza first and sushi second is not meaningful.\n\nSmartphone companies are another example of nominal scale data. The data are the names of the companies that make smartphones, but there is no agreed upon order of these brands, even though people may have personal preferences. Nominal scale data cannot be used in calculations.\n\nData that is measured using an ordinal scale is similar to nominal scale data but there is a big difference. The ordinal scale data can be ordered. An example of ordinal scale data is a list of the top five national parks in the United States. The top five national parks in the United States can be ranked from one to five but we cannot measure differences between the data.\n\nAnother example of using the ordinal scale is a cruise survey where the responses to questions about the cruise are \u201cexcellent,\u201d \u201cgood,\u201d \u201csatisfactory,\u201d and \u201cunsatisfactory.\u201d  These responses are ordered from the most desired response to the least desired.  But the differences between two pieces of data cannot be measured. Like the nominal scale data, ordinal scale data cannot be used in calculations.\n\nData that is measured using the interval scale is similar to ordinal level data because it has a definite ordering but there is a difference between data. The differences between interval scale data can be measured though the data does not have a starting point.\n\nTemperature scales like Celsius (C) and Fahrenheit (F) are measured by using the interval scale. In both temperature measurements, 40\u00b0 is equal to 100\u00b0 minus 60\u00b0. Differences make sense. But 0 degrees does not because, in both scales, 0 is not the absolute lowest temperature. Temperatures like  -10\u00b0 F and -15\u00b0 C exist and are colder than 0.\n\nInterval level data can be used in calculations, but one type of comparison cannot be done.  80\u00b0 C is not four times as hot as 20\u00b0 C (nor is 80\u00b0 F four times as hot as 20\u00b0 F). There is no meaning to the ratio of 80 to 20 (or four to one).\n\nData that is measured using the ratio scale takes care of the ratio problem and gives you the most information. Ratio scale data is like interval scale data, but it has a 0 point and ratios can be calculated. For example, four multiple choice statistics final exam scores are 80, 68, 20 and 92 (out of a possible 100 points). The exams are machine-graded.\n\nThe data can be put in order from lowest to highest:  20, 68, 80, 92.\n\nThe differences between the data have meaning. The score 92 is more than the score 68 by 24 points.Ratios can be calculated. The smallest score is 0. So 80 is four times 20. The score of 80 is four times better than the score of 20.",
                    "id": "C_337840_1"
                }
            ],
            "section_title": "Levels of Measurement",
            "chapter_learning_objectives": [],
            "chapter_summary": "Some calculations generate numbers that are artificially precise. It is not necessary to report a value to eight decimal places when the measures that generated that value were only accurate to the nearest tenth. Round off your final answer to one more decimal place than was present in the original data. This means that if you have data measured to the nearest tenth of a unit, report the final statistic to the nearest hundredth.In addition to rounding your answers, you can measure your data using the following four levels of measurement.Nominal scale level: data that cannot be ordered nor can it be used in calculations Ordinal scale level: data that can be ordered; the differences cannot be measured Interval scale level: data with a definite ordering but no starting point; the differences can be measured, but there is no such thing as a ratio. Ratio scale level: data with a starting point that can be ordered; the differences have meaning and ratios can be calculated. When organizing data, it is important to know how many times a value appears. How many statistics students study five hours or more for an exam? What percent of families on our block own two pets? Frequency, relative frequency, and cumulative relative frequency are measures that answer questions like these.",
            "chapter_introduction": "Once you have a set of data, you will need to organize it so that you can analyze how frequently each datum occurs in the set. However, when calculating the frequency, you may need to round your answers so that they are as precise as possible.",
            "bold_terms": [
                "level of measurement",
                "Nominal scale level",
                "Ordinal scale level",
                "Interval scale level",
                "Ratio scale level",
                "nominal scale",
                "qualitative (categorical",
                "ordinal scale",
                "interval scale",
                "ratio scale",
                "frequency",
                "relative frequency",
                "Cumulative relative frequency",
                "grouped",
                "five",
                "three",
                "15",
                "40",
                "17",
                "12",
                "seven",
                "one"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-3-frequency-frequency-tables-and-levels-of-measurement",
            "paragraphs": [
                {
                    "context": "Twenty students were asked how many hours they worked per day. Their responses, in hours, are as follows: 5; 6; 3; 3; 2; 4; 7; 5; 2; 3; 5; 6; 5; 4; 4; 3; 5; 2; 5; 3.\n\nTable 1.9 lists the different data values in ascending order and their frequencies. \n\nA frequency is the number of times a value of the data occurs. According to Table 1.9, there are three students who work two hours, five students who work three hours, and so on. The sum of the values in the frequency column, 20, represents the total number of students included in the sample.\n\nA relative frequency is the ratio (fraction or proportion) of the number of times a value of the data occurs in the set of all outcomes to the total number of outcomes. To find the relative frequencies, divide each frequency by the total number of students in the sample\u2013in this case, 20. Relative frequencies can be written as fractions, percents, or decimals.\n\nThe sum of the values in the relative frequency column of Table 1.10 is $$\\(\\frac{20}{20}\\)$$, or 1.\n\nCumulative relative frequency is the accumulation of the previous relativefrequencies. To find the cumulative relative frequencies, add all the previous relative frequencies tothe relative frequency for the current row, as shown in Table 1.11.\n\nThe last entry of the cumulative relative frequency column is one, indicating that one hundred percent of the data has been accumulated.",
                    "id": "C_714485_2"
                }
            ],
            "section_title": "Frequency",
            "chapter_learning_objectives": [],
            "chapter_summary": "Some calculations generate numbers that are artificially precise. It is not necessary to report a value to eight decimal places when the measures that generated that value were only accurate to the nearest tenth. Round off your final answer to one more decimal place than was present in the original data. This means that if you have data measured to the nearest tenth of a unit, report the final statistic to the nearest hundredth.In addition to rounding your answers, you can measure your data using the following four levels of measurement.Nominal scale level: data that cannot be ordered nor can it be used in calculations Ordinal scale level: data that can be ordered; the differences cannot be measured Interval scale level: data with a definite ordering but no starting point; the differences can be measured, but there is no such thing as a ratio. Ratio scale level: data with a starting point that can be ordered; the differences have meaning and ratios can be calculated. When organizing data, it is important to know how many times a value appears. How many statistics students study five hours or more for an exam? What percent of families on our block own two pets? Frequency, relative frequency, and cumulative relative frequency are measures that answer questions like these.",
            "chapter_introduction": "Once you have a set of data, you will need to organize it so that you can analyze how frequently each datum occurs in the set. However, when calculating the frequency, you may need to round your answers so that they are as precise as possible.",
            "bold_terms": [
                "level of measurement",
                "Nominal scale level",
                "Ordinal scale level",
                "Interval scale level",
                "Ratio scale level",
                "nominal scale",
                "qualitative (categorical",
                "ordinal scale",
                "interval scale",
                "ratio scale",
                "frequency",
                "relative frequency",
                "Cumulative relative frequency",
                "grouped",
                "five",
                "three",
                "15",
                "40",
                "17",
                "12",
                "seven",
                "one"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-3-frequency-frequency-tables-and-levels-of-measurement",
            "paragraphs": [
                {
                    "context": "Because of rounding, the relative frequency column may not always sum to one, and the last entry in the cumulative relative frequency column may not be one. However, they each should be close to one.\n\nTable 1.12 represents the heights, in inches, of a sample of 100 male semiprofessional soccer players.\n\nThe data in this table have been grouped into the following intervals:\n\n59.95 to 61.95 inches 61.95 to 63.95 inches 63.95 to 65.95 inches 65.95 to 67.95 inches 67.95 to 69.95 inches 69.95 to 71.95 inches 71.95 to 73.95 inches 73.95 to 75.95 inches ",
                    "id": "C_552208_3"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "Some calculations generate numbers that are artificially precise. It is not necessary to report a value to eight decimal places when the measures that generated that value were only accurate to the nearest tenth. Round off your final answer to one more decimal place than was present in the original data. This means that if you have data measured to the nearest tenth of a unit, report the final statistic to the nearest hundredth.In addition to rounding your answers, you can measure your data using the following four levels of measurement.Nominal scale level: data that cannot be ordered nor can it be used in calculations Ordinal scale level: data that can be ordered; the differences cannot be measured Interval scale level: data with a definite ordering but no starting point; the differences can be measured, but there is no such thing as a ratio. Ratio scale level: data with a starting point that can be ordered; the differences have meaning and ratios can be calculated. When organizing data, it is important to know how many times a value appears. How many statistics students study five hours or more for an exam? What percent of families on our block own two pets? Frequency, relative frequency, and cumulative relative frequency are measures that answer questions like these.",
            "chapter_introduction": "Once you have a set of data, you will need to organize it so that you can analyze how frequently each datum occurs in the set. However, when calculating the frequency, you may need to round your answers so that they are as precise as possible.",
            "bold_terms": [
                "level of measurement",
                "Nominal scale level",
                "Ordinal scale level",
                "Interval scale level",
                "Ratio scale level",
                "nominal scale",
                "qualitative (categorical",
                "ordinal scale",
                "interval scale",
                "ratio scale",
                "frequency",
                "relative frequency",
                "Cumulative relative frequency",
                "grouped",
                "five",
                "three",
                "15",
                "40",
                "17",
                "12",
                "seven",
                "one"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-3-frequency-frequency-tables-and-levels-of-measurement",
            "paragraphs": [
                {
                    "context": "This example is used again in Descriptive Statistics, where the method used to compute the intervals will be explained.\n\nIn this sample, there are five players whose heights fall within the interval 59.95\u201361.95 inches, three players whose heights fall within the interval 61.95\u201363.95 inches, 15 players whose heights fall within the interval 63.95\u201365.95 inches, 40 players whose heights fall within the interval 65.95\u201367.95 inches, 17 players whose heights fall within the interval 67.95\u201369.95 inches, 12 players whose heights fall within the interval 69.95\u201371.95, seven players whose heights fall within the interval 71.95\u201373.95, and one player whose heights fall within the interval 73.95\u201375.95. All heights fall between the endpoints of an interval and not at the endpoints.",
                    "id": "C_964272_4"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "Some calculations generate numbers that are artificially precise. It is not necessary to report a value to eight decimal places when the measures that generated that value were only accurate to the nearest tenth. Round off your final answer to one more decimal place than was present in the original data. This means that if you have data measured to the nearest tenth of a unit, report the final statistic to the nearest hundredth.In addition to rounding your answers, you can measure your data using the following four levels of measurement.Nominal scale level: data that cannot be ordered nor can it be used in calculations Ordinal scale level: data that can be ordered; the differences cannot be measured Interval scale level: data with a definite ordering but no starting point; the differences can be measured, but there is no such thing as a ratio. Ratio scale level: data with a starting point that can be ordered; the differences have meaning and ratios can be calculated. When organizing data, it is important to know how many times a value appears. How many statistics students study five hours or more for an exam? What percent of families on our block own two pets? Frequency, relative frequency, and cumulative relative frequency are measures that answer questions like these.",
            "chapter_introduction": "Once you have a set of data, you will need to organize it so that you can analyze how frequently each datum occurs in the set. However, when calculating the frequency, you may need to round your answers so that they are as precise as possible.",
            "bold_terms": [
                "level of measurement",
                "Nominal scale level",
                "Ordinal scale level",
                "Interval scale level",
                "Ratio scale level",
                "nominal scale",
                "qualitative (categorical",
                "ordinal scale",
                "interval scale",
                "ratio scale",
                "frequency",
                "relative frequency",
                "Cumulative relative frequency",
                "grouped",
                "five",
                "three",
                "15",
                "40",
                "17",
                "12",
                "seven",
                "one"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-3-frequency-frequency-tables-and-levels-of-measurement",
            "paragraphs": [
                {
                    "context": "In your class, have someone conduct a survey of the number of siblings (brothers and sisters) each student has. Create a frequency table. Add to it a relative frequency column and a cumulative relative frequency column. Answer the following questions:\n\nWhat percentage of the students in your class have no siblings? What percentage of the students have from one to three siblings? What percentage of the students have fewer than three siblings? ",
                    "id": "C_806759_5"
                }
            ],
            "section_title": "Collaborative Exercise",
            "chapter_learning_objectives": [],
            "chapter_summary": "Some calculations generate numbers that are artificially precise. It is not necessary to report a value to eight decimal places when the measures that generated that value were only accurate to the nearest tenth. Round off your final answer to one more decimal place than was present in the original data. This means that if you have data measured to the nearest tenth of a unit, report the final statistic to the nearest hundredth.In addition to rounding your answers, you can measure your data using the following four levels of measurement.Nominal scale level: data that cannot be ordered nor can it be used in calculations Ordinal scale level: data that can be ordered; the differences cannot be measured Interval scale level: data with a definite ordering but no starting point; the differences can be measured, but there is no such thing as a ratio. Ratio scale level: data with a starting point that can be ordered; the differences have meaning and ratios can be calculated. When organizing data, it is important to know how many times a value appears. How many statistics students study five hours or more for an exam? What percent of families on our block own two pets? Frequency, relative frequency, and cumulative relative frequency are measures that answer questions like these.",
            "chapter_introduction": "Once you have a set of data, you will need to organize it so that you can analyze how frequently each datum occurs in the set. However, when calculating the frequency, you may need to round your answers so that they are as precise as possible.",
            "bold_terms": [
                "level of measurement",
                "Nominal scale level",
                "Ordinal scale level",
                "Interval scale level",
                "Ratio scale level",
                "nominal scale",
                "qualitative (categorical",
                "ordinal scale",
                "interval scale",
                "ratio scale",
                "frequency",
                "relative frequency",
                "Cumulative relative frequency",
                "grouped",
                "five",
                "three",
                "15",
                "40",
                "17",
                "12",
                "seven",
                "one"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "1-4-experimental-design-and-ethics",
            "paragraphs": [
                {
                    "context": "The widespread misuse and misrepresentation of statistical information often gives the field a bad name. Some say that \u201cnumbers don\u2019t lie,\u201d but the people who use numbers to support their claims often do.\n\nA recent investigation of famous social psychologist, Diederik Stapel, has led to the retraction of his articles from some of the world\u2019s top journals including Journal of Experimental Social Psychology, Social Psychology, Basic and Applied Social Psychology, British Journal of Social Psychology, and the magazine Science. Diederik Stapel is a former professor at Tilburg University in the Netherlands. Over the past two years, an extensive investigation involving three universities where Stapel has worked concluded that the psychologist is guilty of fraud on a colossal scale. Falsified data taints over 55 papers he authored and 10 Ph.D. dissertations that he supervised.\n\nStapel did not deny that his deceit was driven by ambition. But it was more complicated than that, he told me. He insisted that he loved social psychology but had been frustrated by the messiness of experimental data, which rarely led to clear conclusions. His lifelong obsession with elegance and order, he said, led him to concoct sexy results that journals found attractive. \u201cIt was a quest for aesthetics, for beauty\u2014instead of the truth,\u201d he said. He described his behavior as an addiction that drove him to carry out acts of increasingly daring fraud, like a junkie seeking a bigger and better high.2\n\nThe committee investigating Stapel concluded that he is guilty of several practices including:\n\ncreating datasets, which largely confirmed the prior expectations, altering data in existing datasets, changing measuring instruments without reporting the change, and misrepresenting the number of experimental subjects. \n\nClearly, it is never acceptable to falsify data the way this researcher did. Sometimes, however, violations of ethics are not as easy to spot.\n\nResearchers have a responsibility to verify that proper methods are being followed. The report describing the investigation of Stapel\u2019s fraud states that, \u201cstatistical flaws frequently revealed a lack of familiarity with elementary statistics.\u201d3 Many of Stapel\u2019s co-authors should have spotted irregularities in his data. Unfortunately, they did not know very much about statistical analysis, and they simply trusted that he was collecting and reporting data properly.\n\nMany types of statistical fraud are difficult to spot. Some researchers simply stop collecting data once they have just enough to prove what they had hoped to prove. They don\u2019t want to take the chance that a more extensive study would complicate their lives by producing data contradicting their hypothesis.\n\nProfessional organizations, like the American Statistical Association, clearly define expectations for researchers. There are even laws in the federal code about the use of research data.\n\nWhen a statistical study uses human participants, as in medical studies, both ethics and the law dictate that researchers should be mindful of the safety of their research subjects. The U.S. Department of Health and Human Services oversees federal regulations of research studies with the aim of protecting participants. When a university or other research institution engages in research, it must ensure the safety of all human subjects. For this reason, research institutions establish oversight committees known as Institutional Review Boards (IRB). All planned studies must be approved in advance by the IRB. Key protections that are mandated by law include the following:\n\nRisks to participants must be minimized and reasonable with respect to projected benefits. Participants must give informed consent. This means that the risks of participation must be clearly explained to the subjects of the study. Subjects must consent in writing, and researchers are required to keep documentation of their consent. Data collected from individuals must be guarded carefully to protect their privacy. \n\nThese ideas may seem fundamental, but they can be very difficult to verify in practice. Is removing a participant\u2019s name from the data record sufficient to protect privacy? Perhaps the person\u2019s identity could be discovered from the data that remains. What happens if the study does not proceed as planned and risks arise that were not anticipated? When is informed consent really necessary? Suppose your doctor wants a blood sample to check your cholesterol level. Once the sample has been tested, you expect the lab to dispose of the remaining blood. At that point the blood becomes biological waste. Does a researcher have the right to take it for use in a study?\n\nIt is important that students of statistics take time to consider the ethical questions that arise in statistical studies. How prevalent is fraud in statistical studies? You might be surprised\u2014and disappointed. There is a website dedicated to cataloging retractions of study articles that have been proven fraudulent. A quick glance will show that the misuse of statistics is a bigger problem than most people realize.\n\nVigilance against fraud requires knowledge. Learning the basic theory of statistics will empower you to analyze statistical studies critically.",
                    "id": "C_195159_0"
                }
            ],
            "section_title": "Ethics",
            "chapter_learning_objectives": [],
            "chapter_summary": "A poorly designed study will not produce reliable data. There are certain key components that must beincluded in every experiment. To eliminate lurking variables, subjects must be assigned randomly to different treatment groups. One of the groups must act as a control group, demonstrating what happens when the active treatment is not applied. Participants in the control group receive a placebo treatment that looks exactly like the active treatments but cannot influence the response variable. To preserve the integrity of the placebo, both researchers and subjects may be blinded. When a study is designed properly, the only difference between treatment groups is the one imposed by the researcher. Therefore, when groups respond differently to different treatments, the difference must be due to the influence of the explanatory variable.\u201cAn ethics problem arises when you are considering an action that benefits you or some cause you support, hurts or reduces benefits to others, and violates some rule.\u201d (Andrew Gelman, \u201cOpen Data and Open Methods,\u201d Ethics and Statistics, http://www.stat.columbia.edu/~gelman/research/published/ChanceEthics1.pdf (accessed May 1, 2013).) Ethical violations in statistics are not always easy to spot. Professional associations and federal agencies post guidelines for proper conduct. It is important that you learn basic statistical procedures so that you can recognize proper data analysis.",
            "chapter_introduction": "Does aspirin reduce the risk of heart attacks? Is one brand of fertilizer more effective at growing roses than another? Is fatigue as dangerous to a driver as the influence of alcohol? Questions like these are answered using randomized experiments. In this module, you will learn important aspects of experimental design. Proper study design ensures the production of reliable, accurate data.\n\nThe purpose of an experiment is to investigate the relationship between two variables. When one variable causes change in another, we call the first variable the explanatory variable. The affected variable is called the response variable. In a randomized experiment, the researcher manipulates values of the explanatory variable and measures the resulting changes in the response variable. The different values of the explanatory variable are called treatments. An experimental unit is a single object or individual to be measured.\n\nYou want to investigate the effectiveness of vitamin E in preventing disease. You recruit a group of subjects and ask them if they regularly take vitamin E. You notice that the subjects who take vitamin E exhibit better health on average than those who do not. Does this prove that vitamin E is effective in disease prevention? It does not. There are many differences between the two groups compared in addition to vitamin E consumption. People who take vitamin E regularly often take other steps to improve their health: exercise, diet, other vitamin supplements, choosing not to smoke. Any one of these factors could be influencing health. As described, this study does not prove that vitamin E is the key to disease prevention.\n\nAdditional variables that can cloud a study are called lurking variables. In order to prove that the explanatory variable is causing a change in the response variable, it is necessary to isolate the explanatory variable. The researcher must design her experiment in such a way that there is only one difference between groups being compared: the planned treatments. This is accomplished by the random assignment of experimental units to treatment groups. When subjects are assigned treatments randomly, all of the potential lurking variables are spread equally among the groups. At this point the only difference between groups is the one imposed by the researcher. Different outcomes measured in the response variable, therefore, must be a direct result of the different treatments. In this way, an experiment can prove a cause-and-effect connection between the explanatory and response variables.\n\nThe power of suggestion can have an important influence on the outcome of an experiment. Studies have shown that the expectation of the study participant can be as important as the actual medication. In one study of performance-enhancing drugs, researchers noted:\n\nResults showed that believing one had taken the substance resulted in [performance] times almost as fast as those associated with consuming the drug itself. In contrast, taking the drug without knowledge yielded no significant performance increment.1\n\nWhen participation in a study prompts a physical response from a participant, it is difficult to isolate the effects of the explanatory variable. To counter the power of suggestion, researchers set aside one treatment group as a control group. This group is given a placebo treatment\u2013a treatment that cannot influence the response variable. The control group helps researchers balance the effects of being in an experiment with the effects of the active treatments. Of course, if you are participating in a study and you know that you are receiving a pill which contains no actual medication, then the power of suggestion is no longer a factor. Blinding in a randomized experiment preserves the power of suggestion. When a person involved in a research study is blinded, he does not know who is receiving the active treatment(s) and who is receiving the placebo treatment. A double-blind experiment is one in which both the subjects and the researchers involved with the subjects are blinded.",
            "bold_terms": [
                "explanatory variable",
                "response variable",
                "treatments",
                "experimental unit",
                "lurking variables",
                "random assignment",
                "control group",
                "placebo",
                "Blinding",
                "double-blind experiment",
                "Institutional Review Boards (IRB",
                "informed consent"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "also called mean; a number that describes the central tendency of the data"
                },
                {
                    "name": "Blinding",
                    "description": "not telling participants which treatment a subject is receiving"
                },
                {
                    "name": "Categorical Variable",
                    "description": "variables that take on values that are names or labels"
                },
                {
                    "name": "Cluster Sampling",
                    "description": "a method for selecting a random sample and dividing the population into groups (clusters); use simple random sampling to select a set of clusters. Every individual in the chosen clusters is included in the sample."
                },
                {
                    "name": "Continuous Random Variable",
                    "description": "a random variable (RV) whose outcomes are measured; the height of trees in the forest is a continuous RV."
                },
                {
                    "name": "Control Group",
                    "description": "a group in a randomized experiment that receives an inactive treatment but is otherwise managed exactly as the other groups"
                },
                {
                    "name": "Convenience Sampling",
                    "description": "a nonrandom method of selecting a sample; this method selects individuals that are easily accessible and may result in biased data."
                },
                {
                    "name": "Cumulative Relative Frequency",
                    "description": "      The term applies to an ordered set of observations from smallest to largest. The cumulative relative frequency is the sum of the relative frequencies for all values that are less than or equal to the given value.    "
                },
                {
                    "name": "Data",
                    "description": "a set of observations (a set of possible outcomes); most data can be put into two groups: qualitative (an attribute whose value is indicated by a label) or quantitative (an attribute whose value is indicated by a number). Quantitative data can be separated into two subgroups: discrete and continuous. Data is discrete if it is the result of counting (such as the number of students of a given ethnic group in a class or the number of books on a shelf). Data is continuous if it is the result of measuring (such as distance traveled or weight of luggage)"
                },
                {
                    "name": "Discrete Random Variable",
                    "description": "a random variable (RV) whose outcomes are counted"
                },
                {
                    "name": "Double-blinding",
                    "description": "the act of blinding both the subjects of an experiment and the researchers who work with the subjects"
                },
                {
                    "name": "Experimental Unit",
                    "description": "any individual or object to be measured"
                },
                {
                    "name": "Explanatory Variable",
                    "description": "the independent variable in an experiment; the value controlled by researchers"
                },
                {
                    "name": "Frequency",
                    "description": "   the number of times a value of the data occurs"
                },
                {
                    "name": "Informed Consent",
                    "description": "Any human subject in a research study must be cognizant of any risks or costs associated with the study. The subject has the right to know the nature of the treatments included in the study, their potential risks, and their potential benefits. Consent must be given freely by an informed, fit participant."
                },
                {
                    "name": "Institutional Review Board",
                    "description": "a committee tasked with oversight of research programs that involve human subjects"
                },
                {
                    "name": "Lurking Variable",
                    "description": "a variable that has an effect on a study even though it is neither an explanatory variable nor a response variable"
                },
                {
                    "name": "Nonsampling Error",
                    "description": "an issue that affects the reliability of sampling data other than natural variation; it includes a variety of human errors including poor study design, biased sampling methods, inaccurate information provided by study participants, data entry errors, and poor analysis."
                },
                {
                    "name": "Numerical Variable",
                    "description": "variables that take on values that are indicated by numbers"
                },
                {
                    "name": "Parameter",
                    "description": "a number that is used to represent a population characteristic and that generally cannot be determined easily"
                },
                {
                    "name": "Placebo",
                    "description": "an inactive treatment that has no real effect on the explanatory variable"
                },
                {
                    "name": "Population",
                    "description": "all individuals, objects, or measurements whose properties are being studied"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur"
                },
                {
                    "name": "Proportion",
                    "description": "the number of successes divided by the total number in the sample"
                },
                {
                    "name": "Qualitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Quantitative Data",
                    "description": "See Data."
                },
                {
                    "name": "Random Assignment",
                    "description": "the act of organizing experimental units into treatment groups using random methods"
                },
                {
                    "name": "Random Sampling",
                    "description": "a method of selecting a sample that gives every member of the population an equal chance of being selected."
                },
                {
                    "name": "Relative Frequency",
                    "description": "the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes to the total number of outcomes"
                },
                {
                    "name": "Representative Sample",
                    "description": "a subset of the population that has the same characteristics as the population"
                },
                {
                    "name": "Response Variable",
                    "description": "the dependent variable in an experiment; the value that is measured for change at the end of an experiment"
                },
                {
                    "name": "Sample",
                    "description": "a subset of the population studied"
                },
                {
                    "name": "Sampling Bias",
                    "description": "not all members of the population are equally likely to be selected"
                },
                {
                    "name": "Sampling Error",
                    "description": "the natural variation that results from selecting a sample to represent a larger population; this variation decreases as the sample size increases, so selecting larger samples reduces sampling error."
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "Once a member of the population is selected for inclusion in a sample, that member is returned to the population for the selection of the next individual."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "A member of the population may be chosen for inclusion in a sample only once. If chosen, the member is not returned to the population before the next selection."
                },
                {
                    "name": "Simple Random Sampling",
                    "description": "a straightforward method for selecting a random sample; give each member of the population a number. Use a random number generator to select a set of labels. These randomly selected labels identify the members of your sample."
                },
                {
                    "name": "Statistic",
                    "description": "a numerical characteristic of the sample; a statistic estimates the corresponding population parameter."
                },
                {
                    "name": "Stratified Sampling",
                    "description": "a method for selecting a random sample used to ensure that subgroups of the population are represented adequately; divide the population into groups (strata). Use simple random sampling to identify a proportionate number of individuals from each stratum."
                },
                {
                    "name": "Systematic Sampling",
                    "description": "a method for selecting a random sample; list the members of the population. Use simple random sampling to select a starting point in the population. Let k = (number of individuals in the population)/(number of individuals needed in the sample). Choose every kth individual in the list starting with the one that was randomly selected. If necessary, return to the beginning of the population list to complete your sample."
                },
                {
                    "name": "Treatments",
                    "description": "different values or components of the explanatory variable applied in an experiment"
                },
                {
                    "name": "Variable",
                    "description": "a characteristic of interest for each person or object in a population"
                }
            ]
        },
        {
            "title": "2-2-histograms-frequency-polygons-and-time-series-graphs",
            "paragraphs": [
                {
                    "context": "Go to Appendix G Notes for the TI-83, 83+, 84, 84+ Calculators. There are calculator instructions for entering data and for creating a customized histogram. Create the histogram for Example 2.8.\n\nPress Y=. Press CLEAR to delete any equations. Press STAT 1:EDIT. If L1 has data in it, arrow up into the name L1, press CLEAR and then arrow down. If necessary, do the same for L2. Into L1, enter 1, 2, 3, 4, 5, 6. Into L2, enter 11, 10, 16, 6, 5, 2. Press WINDOW. Set Xmin = .5, Xmax = 6.5, Xscl = (6.5 \u2013 .5)/6, Ymin = \u20131, Ymax = 20, Yscl = 1, Xres = 1. Press 2nd Y=. Start by pressing 4:Plotsoff ENTER. Press 2nd Y=. Press 1:Plot1. Press ENTER. Arrow down to TYPE. Arrow to the 3rd picture (histogram). Press ENTER. Arrow down to Xlist: Enter L1 (2nd 1). Arrow down to Freq. Enter L2 (2nd 2). Press GRAPH. Use the TRACE key and the arrow keys to examine the histogram. ",
                    "id": "C_379786_0"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "A histogram is a graphic version of a frequency distribution. The graph consists of bars of equal width drawn adjacent to each other. The horizontal scale represents classes of quantitative data values and the vertical scale represents frequencies. The heights of the bars correspond to frequency values. Histograms are typically used for large, continuous, quantitative data sets. A frequency polygon can also be used when graphing large data sets with data points that repeat. The data usually goes on y-axis with the frequency being graphed on the x-axis. Time series graphs can be helpful when looking at large amounts of data for one variable over a period of time.",
            "chapter_introduction": "For most of the work you do in this book, you will use a histogram to display the data. One advantage of a histogram is that it can readily display large data sets. A rule of thumb is to use a histogram when the data set consists of 100 values or more.\n\nA histogram consists of contiguous (adjoining) boxes. It has both a horizontal axis and a vertical axis. The horizontal axis is labeled with what the data represents (for instance, distance from your home to school). The vertical axis is labeled either frequency or relative frequency (or percent frequency or probability). The graph will have the same shape with either label. The histogram (like the stemplot) can give you the shape of the data, the center, and the spread of the data.\n\nThe relative frequency is equal to the frequency for an observed value of the data divided by the total number of data values in the sample. (Remember, frequency is defined as the number of times an answer occurs.) If:\n\nf = frequency n = total number of data values (or the sum of the individual frequencies), and RF = relative frequency, \n\nthen:\n\n$$\\[{\\text{RF} = \\frac{f}{n}}{}\\]$$\n\nFor example, if three students in Mr. Ahab's English class of 40 students received from 90% to 100%, then, <newline count=\"1\"/>f = 3, n = 40, and RF = $$\\(\\frac{f}{n}\\)$$ = $$\\(\\frac{3}{40}\\)$$ = 0.075. 7.5% of the students received 90\u2013100%. 90\u2013100% are quantitative measures.\n\nTo construct a histogram, first decide how many bars or intervals, also called classes, represent the data. Many histograms consist of five to 15 bars or classes for clarity. The number of bars needs to be chosen. Choose a starting point for the first interval to be less than the smallest data value. A convenient starting point is a lower value carried out to one more decimal place than the value with the most decimal places. For example, if the value with the most decimal places is 6.1 and this is the smallest value, a convenient starting point is 6.05 (6.1 \u2013 0.05 = 6.05). We say that 6.05 has more precision. If the value with the most decimal places is 2.23 and the lowest value is 1.5, a convenient starting point is 1.495 (1.5 \u2013 0.005 = 1.495). If the value with the most decimal places is 3.234 and the lowest value is 1.0, a convenient starting point is 0.9995 (1.0 \u2013 0.0005 = 0.9995). If all the data happen to be integers and the smallest value is two, then a convenient starting point is 1.5 (2 \u2013 0.5 = 1.5). Also, when the starting point and other boundaries are carried to one additional decimal place, no data value will fall on a boundary. The next two examples go into detail about how to construct a histogram using continuous data and how to create a histogram using discrete data.",
            "bold_terms": [
                "histogram",
                "frequency",
                "relative frequency",
                "To construct a histogram",
                "bars",
                "intervals",
                "convenient starting point",
                "paired data set"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-2-histograms-frequency-polygons-and-time-series-graphs",
            "paragraphs": [
                {
                    "context": "Count the money (bills and change) in your pocket or purse. Your instructor will record the amounts. As a class, construct a histogram displaying the data. Discuss how many intervals you think is appropriate. You may want to experiment with the number of intervals.",
                    "id": "C_597468_1"
                }
            ],
            "section_title": "Collaborative Exercise",
            "chapter_learning_objectives": [],
            "chapter_summary": "A histogram is a graphic version of a frequency distribution. The graph consists of bars of equal width drawn adjacent to each other. The horizontal scale represents classes of quantitative data values and the vertical scale represents frequencies. The heights of the bars correspond to frequency values. Histograms are typically used for large, continuous, quantitative data sets. A frequency polygon can also be used when graphing large data sets with data points that repeat. The data usually goes on y-axis with the frequency being graphed on the x-axis. Time series graphs can be helpful when looking at large amounts of data for one variable over a period of time.",
            "chapter_introduction": "For most of the work you do in this book, you will use a histogram to display the data. One advantage of a histogram is that it can readily display large data sets. A rule of thumb is to use a histogram when the data set consists of 100 values or more.\n\nA histogram consists of contiguous (adjoining) boxes. It has both a horizontal axis and a vertical axis. The horizontal axis is labeled with what the data represents (for instance, distance from your home to school). The vertical axis is labeled either frequency or relative frequency (or percent frequency or probability). The graph will have the same shape with either label. The histogram (like the stemplot) can give you the shape of the data, the center, and the spread of the data.\n\nThe relative frequency is equal to the frequency for an observed value of the data divided by the total number of data values in the sample. (Remember, frequency is defined as the number of times an answer occurs.) If:\n\nf = frequency n = total number of data values (or the sum of the individual frequencies), and RF = relative frequency, \n\nthen:\n\n$$\\[{\\text{RF} = \\frac{f}{n}}{}\\]$$\n\nFor example, if three students in Mr. Ahab's English class of 40 students received from 90% to 100%, then, <newline count=\"1\"/>f = 3, n = 40, and RF = $$\\(\\frac{f}{n}\\)$$ = $$\\(\\frac{3}{40}\\)$$ = 0.075. 7.5% of the students received 90\u2013100%. 90\u2013100% are quantitative measures.\n\nTo construct a histogram, first decide how many bars or intervals, also called classes, represent the data. Many histograms consist of five to 15 bars or classes for clarity. The number of bars needs to be chosen. Choose a starting point for the first interval to be less than the smallest data value. A convenient starting point is a lower value carried out to one more decimal place than the value with the most decimal places. For example, if the value with the most decimal places is 6.1 and this is the smallest value, a convenient starting point is 6.05 (6.1 \u2013 0.05 = 6.05). We say that 6.05 has more precision. If the value with the most decimal places is 2.23 and the lowest value is 1.5, a convenient starting point is 1.495 (1.5 \u2013 0.005 = 1.495). If the value with the most decimal places is 3.234 and the lowest value is 1.0, a convenient starting point is 0.9995 (1.0 \u2013 0.0005 = 0.9995). If all the data happen to be integers and the smallest value is two, then a convenient starting point is 1.5 (2 \u2013 0.5 = 1.5). Also, when the starting point and other boundaries are carried to one additional decimal place, no data value will fall on a boundary. The next two examples go into detail about how to construct a histogram using continuous data and how to create a histogram using discrete data.",
            "bold_terms": [
                "histogram",
                "frequency",
                "relative frequency",
                "To construct a histogram",
                "bars",
                "intervals",
                "convenient starting point",
                "paired data set"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-2-histograms-frequency-polygons-and-time-series-graphs",
            "paragraphs": [
                {
                    "context": "Frequency polygons are analogous to line graphs, and just as line graphs make continuous data visually easy to interpret, so too do frequency polygons.\n\nTo construct a frequency polygon, first examine the data and decide on the number of intervals, or class intervals, to use on the x-axis and y-axis. After choosing the appropriate ranges, begin plotting the data points. After all the points are plotted, draw line segments to connect them.\n\nFrequency polygons are useful for comparing distributions. This is achieved by overlaying the frequency polygons drawn for different data sets.\n\nSuppose that we want to study the temperature range of a region for an entire month. Every day at noon we note the temperature and write this down in a log. A variety of statistical studies could be done with this data. We could find the mean or the median temperature for the month. We could construct a histogram displaying the number of days that temperatures reach a certain range of values. However, all of these methods ignore a portion of the data that we have collected.\n\nOne feature of the data that we may want to consider is that of time. Since each date is paired with the temperature reading for the day, we don\u2018t have to think of the data as being random. We can instead use the times given to impose a chronological order on the data. A graph that recognizes this ordering and displays the changing temperature as the month progresses is called a time series graph.",
                    "id": "C_360280_2"
                }
            ],
            "section_title": "Frequency Polygons",
            "chapter_learning_objectives": [],
            "chapter_summary": "A histogram is a graphic version of a frequency distribution. The graph consists of bars of equal width drawn adjacent to each other. The horizontal scale represents classes of quantitative data values and the vertical scale represents frequencies. The heights of the bars correspond to frequency values. Histograms are typically used for large, continuous, quantitative data sets. A frequency polygon can also be used when graphing large data sets with data points that repeat. The data usually goes on y-axis with the frequency being graphed on the x-axis. Time series graphs can be helpful when looking at large amounts of data for one variable over a period of time.",
            "chapter_introduction": "For most of the work you do in this book, you will use a histogram to display the data. One advantage of a histogram is that it can readily display large data sets. A rule of thumb is to use a histogram when the data set consists of 100 values or more.\n\nA histogram consists of contiguous (adjoining) boxes. It has both a horizontal axis and a vertical axis. The horizontal axis is labeled with what the data represents (for instance, distance from your home to school). The vertical axis is labeled either frequency or relative frequency (or percent frequency or probability). The graph will have the same shape with either label. The histogram (like the stemplot) can give you the shape of the data, the center, and the spread of the data.\n\nThe relative frequency is equal to the frequency for an observed value of the data divided by the total number of data values in the sample. (Remember, frequency is defined as the number of times an answer occurs.) If:\n\nf = frequency n = total number of data values (or the sum of the individual frequencies), and RF = relative frequency, \n\nthen:\n\n$$\\[{\\text{RF} = \\frac{f}{n}}{}\\]$$\n\nFor example, if three students in Mr. Ahab's English class of 40 students received from 90% to 100%, then, <newline count=\"1\"/>f = 3, n = 40, and RF = $$\\(\\frac{f}{n}\\)$$ = $$\\(\\frac{3}{40}\\)$$ = 0.075. 7.5% of the students received 90\u2013100%. 90\u2013100% are quantitative measures.\n\nTo construct a histogram, first decide how many bars or intervals, also called classes, represent the data. Many histograms consist of five to 15 bars or classes for clarity. The number of bars needs to be chosen. Choose a starting point for the first interval to be less than the smallest data value. A convenient starting point is a lower value carried out to one more decimal place than the value with the most decimal places. For example, if the value with the most decimal places is 6.1 and this is the smallest value, a convenient starting point is 6.05 (6.1 \u2013 0.05 = 6.05). We say that 6.05 has more precision. If the value with the most decimal places is 2.23 and the lowest value is 1.5, a convenient starting point is 1.495 (1.5 \u2013 0.005 = 1.495). If the value with the most decimal places is 3.234 and the lowest value is 1.0, a convenient starting point is 0.9995 (1.0 \u2013 0.0005 = 0.9995). If all the data happen to be integers and the smallest value is two, then a convenient starting point is 1.5 (2 \u2013 0.5 = 1.5). Also, when the starting point and other boundaries are carried to one additional decimal place, no data value will fall on a boundary. The next two examples go into detail about how to construct a histogram using continuous data and how to create a histogram using discrete data.",
            "bold_terms": [
                "histogram",
                "frequency",
                "relative frequency",
                "To construct a histogram",
                "bars",
                "intervals",
                "convenient starting point",
                "paired data set"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-2-histograms-frequency-polygons-and-time-series-graphs",
            "paragraphs": [
                {
                    "context": "To construct a time series graph, we must look at both pieces of our paired data set. We start with a standard Cartesian coordinate system. The horizontal axis is used to plot the date or time increments, and the vertical axis is used to plot the values of the variable that we are measuring. By doing this, we make each point on the graph correspond to a date and a measured quantity. The points on the graph are typically connected by straight lines in the order in which they occur.",
                    "id": "C_570695_3"
                }
            ],
            "section_title": "Constructing a Time Series Graph",
            "chapter_learning_objectives": [],
            "chapter_summary": "A histogram is a graphic version of a frequency distribution. The graph consists of bars of equal width drawn adjacent to each other. The horizontal scale represents classes of quantitative data values and the vertical scale represents frequencies. The heights of the bars correspond to frequency values. Histograms are typically used for large, continuous, quantitative data sets. A frequency polygon can also be used when graphing large data sets with data points that repeat. The data usually goes on y-axis with the frequency being graphed on the x-axis. Time series graphs can be helpful when looking at large amounts of data for one variable over a period of time.",
            "chapter_introduction": "For most of the work you do in this book, you will use a histogram to display the data. One advantage of a histogram is that it can readily display large data sets. A rule of thumb is to use a histogram when the data set consists of 100 values or more.\n\nA histogram consists of contiguous (adjoining) boxes. It has both a horizontal axis and a vertical axis. The horizontal axis is labeled with what the data represents (for instance, distance from your home to school). The vertical axis is labeled either frequency or relative frequency (or percent frequency or probability). The graph will have the same shape with either label. The histogram (like the stemplot) can give you the shape of the data, the center, and the spread of the data.\n\nThe relative frequency is equal to the frequency for an observed value of the data divided by the total number of data values in the sample. (Remember, frequency is defined as the number of times an answer occurs.) If:\n\nf = frequency n = total number of data values (or the sum of the individual frequencies), and RF = relative frequency, \n\nthen:\n\n$$\\[{\\text{RF} = \\frac{f}{n}}{}\\]$$\n\nFor example, if three students in Mr. Ahab's English class of 40 students received from 90% to 100%, then, <newline count=\"1\"/>f = 3, n = 40, and RF = $$\\(\\frac{f}{n}\\)$$ = $$\\(\\frac{3}{40}\\)$$ = 0.075. 7.5% of the students received 90\u2013100%. 90\u2013100% are quantitative measures.\n\nTo construct a histogram, first decide how many bars or intervals, also called classes, represent the data. Many histograms consist of five to 15 bars or classes for clarity. The number of bars needs to be chosen. Choose a starting point for the first interval to be less than the smallest data value. A convenient starting point is a lower value carried out to one more decimal place than the value with the most decimal places. For example, if the value with the most decimal places is 6.1 and this is the smallest value, a convenient starting point is 6.05 (6.1 \u2013 0.05 = 6.05). We say that 6.05 has more precision. If the value with the most decimal places is 2.23 and the lowest value is 1.5, a convenient starting point is 1.495 (1.5 \u2013 0.005 = 1.495). If the value with the most decimal places is 3.234 and the lowest value is 1.0, a convenient starting point is 0.9995 (1.0 \u2013 0.0005 = 0.9995). If all the data happen to be integers and the smallest value is two, then a convenient starting point is 1.5 (2 \u2013 0.5 = 1.5). Also, when the starting point and other boundaries are carried to one additional decimal place, no data value will fall on a boundary. The next two examples go into detail about how to construct a histogram using continuous data and how to create a histogram using discrete data.",
            "bold_terms": [
                "histogram",
                "frequency",
                "relative frequency",
                "To construct a histogram",
                "bars",
                "intervals",
                "convenient starting point",
                "paired data set"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-2-histograms-frequency-polygons-and-time-series-graphs",
            "paragraphs": [
                {
                    "context": "Time series graphs are important tools in various applications of statistics. When recording values of the same variable over an extended period of time, sometimes it is difficult to discern any trend or pattern. However, once the same data points are displayed graphically, some features jump out. Time series graphs make trends easy to spot.",
                    "id": "C_458678_4"
                }
            ],
            "section_title": "Uses of a Time Series Graph",
            "chapter_learning_objectives": [],
            "chapter_summary": "A histogram is a graphic version of a frequency distribution. The graph consists of bars of equal width drawn adjacent to each other. The horizontal scale represents classes of quantitative data values and the vertical scale represents frequencies. The heights of the bars correspond to frequency values. Histograms are typically used for large, continuous, quantitative data sets. A frequency polygon can also be used when graphing large data sets with data points that repeat. The data usually goes on y-axis with the frequency being graphed on the x-axis. Time series graphs can be helpful when looking at large amounts of data for one variable over a period of time.",
            "chapter_introduction": "For most of the work you do in this book, you will use a histogram to display the data. One advantage of a histogram is that it can readily display large data sets. A rule of thumb is to use a histogram when the data set consists of 100 values or more.\n\nA histogram consists of contiguous (adjoining) boxes. It has both a horizontal axis and a vertical axis. The horizontal axis is labeled with what the data represents (for instance, distance from your home to school). The vertical axis is labeled either frequency or relative frequency (or percent frequency or probability). The graph will have the same shape with either label. The histogram (like the stemplot) can give you the shape of the data, the center, and the spread of the data.\n\nThe relative frequency is equal to the frequency for an observed value of the data divided by the total number of data values in the sample. (Remember, frequency is defined as the number of times an answer occurs.) If:\n\nf = frequency n = total number of data values (or the sum of the individual frequencies), and RF = relative frequency, \n\nthen:\n\n$$\\[{\\text{RF} = \\frac{f}{n}}{}\\]$$\n\nFor example, if three students in Mr. Ahab's English class of 40 students received from 90% to 100%, then, <newline count=\"1\"/>f = 3, n = 40, and RF = $$\\(\\frac{f}{n}\\)$$ = $$\\(\\frac{3}{40}\\)$$ = 0.075. 7.5% of the students received 90\u2013100%. 90\u2013100% are quantitative measures.\n\nTo construct a histogram, first decide how many bars or intervals, also called classes, represent the data. Many histograms consist of five to 15 bars or classes for clarity. The number of bars needs to be chosen. Choose a starting point for the first interval to be less than the smallest data value. A convenient starting point is a lower value carried out to one more decimal place than the value with the most decimal places. For example, if the value with the most decimal places is 6.1 and this is the smallest value, a convenient starting point is 6.05 (6.1 \u2013 0.05 = 6.05). We say that 6.05 has more precision. If the value with the most decimal places is 2.23 and the lowest value is 1.5, a convenient starting point is 1.495 (1.5 \u2013 0.005 = 1.495). If the value with the most decimal places is 3.234 and the lowest value is 1.0, a convenient starting point is 0.9995 (1.0 \u2013 0.0005 = 0.9995). If all the data happen to be integers and the smallest value is two, then a convenient starting point is 1.5 (2 \u2013 0.5 = 1.5). Also, when the starting point and other boundaries are carried to one additional decimal place, no data value will fall on a boundary. The next two examples go into detail about how to construct a histogram using continuous data and how to create a histogram using discrete data.",
            "bold_terms": [
                "histogram",
                "frequency",
                "relative frequency",
                "To construct a histogram",
                "bars",
                "intervals",
                "convenient starting point",
                "paired data set"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-3-measures-of-the-location-of-the-data",
            "paragraphs": [
                {
                    "context": "A potential outlier is a data point that is significantly different from the other data points. These special data points may be errors or some kind of abnormality or they may be a key to understanding the data.",
                    "id": "C_915552_0"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "The values that divide a rank-ordered set of data into 100 equal parts are called percentiles. Percentiles are used to compare and interpret data. For example, an observation at the 50th percentile would be greater than 50 percent of the other observations in the set. Quartiles divide data into quarters. The first quartile (Q1) is the 25th percentile,the second quartile (Q2 or median) is 50th percentile, and the third quartile (Q3) is the 75th percentile. The interquartile range, or IQR, is the range of the middle 50 percent of the data values. The IQR is found by subtracting Q1 from Q3, and can help determine outliers by using the following two expressions.Q3 + IQR(1.5) Q1 \u2013 IQR(1.5) ",
            "chapter_introduction": "The common measures of location are quartiles and percentiles\n\nQuartiles are special percentiles. The first quartile, Q1, is the same as the 25th percentile, and the third quartile, Q3, is the same as the 75th percentile. The median, M, is called both the second quartile and the 50th percentile.\n\nTo calculate quartiles and percentiles, the data must be ordered from smallest to largest. Quartiles divide ordered data into quarters. Percentiles divide ordered data into hundredths. To score in the 90th percentile of an exam does not mean, necessarily, that you received 90% on a test. It means that 90% of test scores are the same or less than your score and 10% of the test scores are the same or greater than your test score.\n\nPercentiles are useful for comparing values. For this reason, universities and colleges use percentiles extensively. One instance in which colleges and universities use percentiles is when SAT results are used to determine a minimum testing score that will be used as an acceptance factor. For example, suppose Duke accepts SAT scores at or above the 75th percentile. That translates into a score of at least 1220.\n\nPercentiles are mostly used with very large populations. Therefore, if you were to say that 90% of the test scores are less (and not the same or less) than your score, it would be acceptable because removing one particular data value is not significant. \n\nThe median is a number that measures the \"center\" of the data. You can think of the median as the \"middle value,\" but it does not actually have to be one of the observed values. It is a number that separates ordered data into halves. Half the values are the same number or smaller than the median, and half the values are the same number or larger. For example, consider the following data.1; 11.5; 6; 7.2; 4; 8; 9; 10; 6.8; 8.3; 2; 2; 10; 1Ordered from smallest to largest:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nSince there are 14 observations, the median is between the seventh value, 6.8, and the eighth value, 7.2. To find the median, add the two values together and divide by two.\n\n$$\\[\\frac{6.8 + 7.2}{2} = 7\\]$$\n\nThe median is seven. Half of the values are smaller than seven and half of the values are larger than seven.\n\nQuartiles are numbers that separate the data into quarters. Quartiles may or may not be part of the data. To find the quartiles, first find the median or second quartile. The first quartile, Q1, is the middle value of the lower half of the data, and the third quartile, Q3, is the middle value, or median, of the upper half of the data. To get the idea, consider the same data set:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nThe median or second quartile is seven. The lower half of the data are 1, 1, 2, 2, 4, 6, 6.8. The middle value of the lower half is two.1; 1; 2; 2; 4; 6; 6.8\n\nThe number two, which is part of the data, is the first quartile. One-fourth of the entire sets of values are the same as or less than two and three-fourths of the values are more than two.\n\nThe upper half of the data is 7.2, 8, 8.3, 9, 10, 10, 11.5. The middle value of the upper half is nine.\n\nThe third quartile, Q3, is nine. Three-fourths (75%) of the ordered data set are less than nine. One-fourth (25%) of the ordered data set are greater than nine. The third quartile is part of the data set in this example.\n\nThe interquartile range is a number that indicates the spread of the middle half or the middle 50% of the data. It is the difference between the third quartile (Q3) and the first quartile (Q1).\n\nIQR = Q3 \u2013 Q1\n\nThe IQR can help to determine potential outliers. A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile. Potential outliers always require further investigation.",
            "bold_terms": [
                "quartiles",
                "percentiles",
                "median",
                "Quartiles",
                "second quartile",
                "first quartile",
                "third quartile",
                "interquartile range",
                "outliers",
                "A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-3-measures-of-the-location-of-the-data",
            "paragraphs": [
                {
                    "context": "Your instructor or a member of the class will ask everyone in class how many sweaters they own. Answer the following questions:\n\n How many students were surveyed? What kind of sampling did you do? Construct two different histograms. For each, starting value = _____ ending value = ____.  Find the median, first quartile, and third quartile. Construct a table of the data to find the following:the 10th percentilethe 70th percentilethe percent of students who own less than four sweaters ",
                    "id": "C_414842_1"
                }
            ],
            "section_title": "Collaborative Exercise",
            "chapter_learning_objectives": [],
            "chapter_summary": "The values that divide a rank-ordered set of data into 100 equal parts are called percentiles. Percentiles are used to compare and interpret data. For example, an observation at the 50th percentile would be greater than 50 percent of the other observations in the set. Quartiles divide data into quarters. The first quartile (Q1) is the 25th percentile,the second quartile (Q2 or median) is 50th percentile, and the third quartile (Q3) is the 75th percentile. The interquartile range, or IQR, is the range of the middle 50 percent of the data values. The IQR is found by subtracting Q1 from Q3, and can help determine outliers by using the following two expressions.Q3 + IQR(1.5) Q1 \u2013 IQR(1.5) ",
            "chapter_introduction": "The common measures of location are quartiles and percentiles\n\nQuartiles are special percentiles. The first quartile, Q1, is the same as the 25th percentile, and the third quartile, Q3, is the same as the 75th percentile. The median, M, is called both the second quartile and the 50th percentile.\n\nTo calculate quartiles and percentiles, the data must be ordered from smallest to largest. Quartiles divide ordered data into quarters. Percentiles divide ordered data into hundredths. To score in the 90th percentile of an exam does not mean, necessarily, that you received 90% on a test. It means that 90% of test scores are the same or less than your score and 10% of the test scores are the same or greater than your test score.\n\nPercentiles are useful for comparing values. For this reason, universities and colleges use percentiles extensively. One instance in which colleges and universities use percentiles is when SAT results are used to determine a minimum testing score that will be used as an acceptance factor. For example, suppose Duke accepts SAT scores at or above the 75th percentile. That translates into a score of at least 1220.\n\nPercentiles are mostly used with very large populations. Therefore, if you were to say that 90% of the test scores are less (and not the same or less) than your score, it would be acceptable because removing one particular data value is not significant. \n\nThe median is a number that measures the \"center\" of the data. You can think of the median as the \"middle value,\" but it does not actually have to be one of the observed values. It is a number that separates ordered data into halves. Half the values are the same number or smaller than the median, and half the values are the same number or larger. For example, consider the following data.1; 11.5; 6; 7.2; 4; 8; 9; 10; 6.8; 8.3; 2; 2; 10; 1Ordered from smallest to largest:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nSince there are 14 observations, the median is between the seventh value, 6.8, and the eighth value, 7.2. To find the median, add the two values together and divide by two.\n\n$$\\[\\frac{6.8 + 7.2}{2} = 7\\]$$\n\nThe median is seven. Half of the values are smaller than seven and half of the values are larger than seven.\n\nQuartiles are numbers that separate the data into quarters. Quartiles may or may not be part of the data. To find the quartiles, first find the median or second quartile. The first quartile, Q1, is the middle value of the lower half of the data, and the third quartile, Q3, is the middle value, or median, of the upper half of the data. To get the idea, consider the same data set:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nThe median or second quartile is seven. The lower half of the data are 1, 1, 2, 2, 4, 6, 6.8. The middle value of the lower half is two.1; 1; 2; 2; 4; 6; 6.8\n\nThe number two, which is part of the data, is the first quartile. One-fourth of the entire sets of values are the same as or less than two and three-fourths of the values are more than two.\n\nThe upper half of the data is 7.2, 8, 8.3, 9, 10, 10, 11.5. The middle value of the upper half is nine.\n\nThe third quartile, Q3, is nine. Three-fourths (75%) of the ordered data set are less than nine. One-fourth (25%) of the ordered data set are greater than nine. The third quartile is part of the data set in this example.\n\nThe interquartile range is a number that indicates the spread of the middle half or the middle 50% of the data. It is the difference between the third quartile (Q3) and the first quartile (Q1).\n\nIQR = Q3 \u2013 Q1\n\nThe IQR can help to determine potential outliers. A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile. Potential outliers always require further investigation.",
            "bold_terms": [
                "quartiles",
                "percentiles",
                "median",
                "Quartiles",
                "second quartile",
                "first quartile",
                "third quartile",
                "interquartile range",
                "outliers",
                "A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-3-measures-of-the-location-of-the-data",
            "paragraphs": [
                {
                    "context": "If you were to do a little research, you would find several formulas for calculating the kth percentile. Here is one of them.\n\nk = the kth percentile. It may or may not be part of the data.\n\ni = the index (ranking or position of a data value)\n\nn = the total number of data\n\nOrder the data from smallest to largest. Calculate $$\\(i = \\frac{k}{100}(n + 1)\\)$$ If i is an integer, then the kth percentile is the data value in the ith position in the ordered set of data. If i is not an integer, then round i up and round i down to the nearest integers. Average the two data values in these two positions in the ordered data set. This is easier to understand in an example. ",
                    "id": "C_626325_2"
                }
            ],
            "section_title": "A Formula for Finding the kth Percentile",
            "chapter_learning_objectives": [],
            "chapter_summary": "The values that divide a rank-ordered set of data into 100 equal parts are called percentiles. Percentiles are used to compare and interpret data. For example, an observation at the 50th percentile would be greater than 50 percent of the other observations in the set. Quartiles divide data into quarters. The first quartile (Q1) is the 25th percentile,the second quartile (Q2 or median) is 50th percentile, and the third quartile (Q3) is the 75th percentile. The interquartile range, or IQR, is the range of the middle 50 percent of the data values. The IQR is found by subtracting Q1 from Q3, and can help determine outliers by using the following two expressions.Q3 + IQR(1.5) Q1 \u2013 IQR(1.5) ",
            "chapter_introduction": "The common measures of location are quartiles and percentiles\n\nQuartiles are special percentiles. The first quartile, Q1, is the same as the 25th percentile, and the third quartile, Q3, is the same as the 75th percentile. The median, M, is called both the second quartile and the 50th percentile.\n\nTo calculate quartiles and percentiles, the data must be ordered from smallest to largest. Quartiles divide ordered data into quarters. Percentiles divide ordered data into hundredths. To score in the 90th percentile of an exam does not mean, necessarily, that you received 90% on a test. It means that 90% of test scores are the same or less than your score and 10% of the test scores are the same or greater than your test score.\n\nPercentiles are useful for comparing values. For this reason, universities and colleges use percentiles extensively. One instance in which colleges and universities use percentiles is when SAT results are used to determine a minimum testing score that will be used as an acceptance factor. For example, suppose Duke accepts SAT scores at or above the 75th percentile. That translates into a score of at least 1220.\n\nPercentiles are mostly used with very large populations. Therefore, if you were to say that 90% of the test scores are less (and not the same or less) than your score, it would be acceptable because removing one particular data value is not significant. \n\nThe median is a number that measures the \"center\" of the data. You can think of the median as the \"middle value,\" but it does not actually have to be one of the observed values. It is a number that separates ordered data into halves. Half the values are the same number or smaller than the median, and half the values are the same number or larger. For example, consider the following data.1; 11.5; 6; 7.2; 4; 8; 9; 10; 6.8; 8.3; 2; 2; 10; 1Ordered from smallest to largest:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nSince there are 14 observations, the median is between the seventh value, 6.8, and the eighth value, 7.2. To find the median, add the two values together and divide by two.\n\n$$\\[\\frac{6.8 + 7.2}{2} = 7\\]$$\n\nThe median is seven. Half of the values are smaller than seven and half of the values are larger than seven.\n\nQuartiles are numbers that separate the data into quarters. Quartiles may or may not be part of the data. To find the quartiles, first find the median or second quartile. The first quartile, Q1, is the middle value of the lower half of the data, and the third quartile, Q3, is the middle value, or median, of the upper half of the data. To get the idea, consider the same data set:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nThe median or second quartile is seven. The lower half of the data are 1, 1, 2, 2, 4, 6, 6.8. The middle value of the lower half is two.1; 1; 2; 2; 4; 6; 6.8\n\nThe number two, which is part of the data, is the first quartile. One-fourth of the entire sets of values are the same as or less than two and three-fourths of the values are more than two.\n\nThe upper half of the data is 7.2, 8, 8.3, 9, 10, 10, 11.5. The middle value of the upper half is nine.\n\nThe third quartile, Q3, is nine. Three-fourths (75%) of the ordered data set are less than nine. One-fourth (25%) of the ordered data set are greater than nine. The third quartile is part of the data set in this example.\n\nThe interquartile range is a number that indicates the spread of the middle half or the middle 50% of the data. It is the difference between the third quartile (Q3) and the first quartile (Q1).\n\nIQR = Q3 \u2013 Q1\n\nThe IQR can help to determine potential outliers. A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile. Potential outliers always require further investigation.",
            "bold_terms": [
                "quartiles",
                "percentiles",
                "median",
                "Quartiles",
                "second quartile",
                "first quartile",
                "third quartile",
                "interquartile range",
                "outliers",
                "A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-3-measures-of-the-location-of-the-data",
            "paragraphs": [
                {
                    "context": "You can calculate percentiles using calculators and computers. There are a variety of online calculators.",
                    "id": "C_727510_3"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "The values that divide a rank-ordered set of data into 100 equal parts are called percentiles. Percentiles are used to compare and interpret data. For example, an observation at the 50th percentile would be greater than 50 percent of the other observations in the set. Quartiles divide data into quarters. The first quartile (Q1) is the 25th percentile,the second quartile (Q2 or median) is 50th percentile, and the third quartile (Q3) is the 75th percentile. The interquartile range, or IQR, is the range of the middle 50 percent of the data values. The IQR is found by subtracting Q1 from Q3, and can help determine outliers by using the following two expressions.Q3 + IQR(1.5) Q1 \u2013 IQR(1.5) ",
            "chapter_introduction": "The common measures of location are quartiles and percentiles\n\nQuartiles are special percentiles. The first quartile, Q1, is the same as the 25th percentile, and the third quartile, Q3, is the same as the 75th percentile. The median, M, is called both the second quartile and the 50th percentile.\n\nTo calculate quartiles and percentiles, the data must be ordered from smallest to largest. Quartiles divide ordered data into quarters. Percentiles divide ordered data into hundredths. To score in the 90th percentile of an exam does not mean, necessarily, that you received 90% on a test. It means that 90% of test scores are the same or less than your score and 10% of the test scores are the same or greater than your test score.\n\nPercentiles are useful for comparing values. For this reason, universities and colleges use percentiles extensively. One instance in which colleges and universities use percentiles is when SAT results are used to determine a minimum testing score that will be used as an acceptance factor. For example, suppose Duke accepts SAT scores at or above the 75th percentile. That translates into a score of at least 1220.\n\nPercentiles are mostly used with very large populations. Therefore, if you were to say that 90% of the test scores are less (and not the same or less) than your score, it would be acceptable because removing one particular data value is not significant. \n\nThe median is a number that measures the \"center\" of the data. You can think of the median as the \"middle value,\" but it does not actually have to be one of the observed values. It is a number that separates ordered data into halves. Half the values are the same number or smaller than the median, and half the values are the same number or larger. For example, consider the following data.1; 11.5; 6; 7.2; 4; 8; 9; 10; 6.8; 8.3; 2; 2; 10; 1Ordered from smallest to largest:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nSince there are 14 observations, the median is between the seventh value, 6.8, and the eighth value, 7.2. To find the median, add the two values together and divide by two.\n\n$$\\[\\frac{6.8 + 7.2}{2} = 7\\]$$\n\nThe median is seven. Half of the values are smaller than seven and half of the values are larger than seven.\n\nQuartiles are numbers that separate the data into quarters. Quartiles may or may not be part of the data. To find the quartiles, first find the median or second quartile. The first quartile, Q1, is the middle value of the lower half of the data, and the third quartile, Q3, is the middle value, or median, of the upper half of the data. To get the idea, consider the same data set:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nThe median or second quartile is seven. The lower half of the data are 1, 1, 2, 2, 4, 6, 6.8. The middle value of the lower half is two.1; 1; 2; 2; 4; 6; 6.8\n\nThe number two, which is part of the data, is the first quartile. One-fourth of the entire sets of values are the same as or less than two and three-fourths of the values are more than two.\n\nThe upper half of the data is 7.2, 8, 8.3, 9, 10, 10, 11.5. The middle value of the upper half is nine.\n\nThe third quartile, Q3, is nine. Three-fourths (75%) of the ordered data set are less than nine. One-fourth (25%) of the ordered data set are greater than nine. The third quartile is part of the data set in this example.\n\nThe interquartile range is a number that indicates the spread of the middle half or the middle 50% of the data. It is the difference between the third quartile (Q3) and the first quartile (Q1).\n\nIQR = Q3 \u2013 Q1\n\nThe IQR can help to determine potential outliers. A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile. Potential outliers always require further investigation.",
            "bold_terms": [
                "quartiles",
                "percentiles",
                "median",
                "Quartiles",
                "second quartile",
                "first quartile",
                "third quartile",
                "interquartile range",
                "outliers",
                "A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-3-measures-of-the-location-of-the-data",
            "paragraphs": [
                {
                    "context": "Order the data from smallest to largest. x = the number of data values counting from the bottom of the data list up to but not including the data value for which you want to find the percentile. y = the number of data values equal to the data value for which you want to find the percentile. n = the total number of data. Calculate $$\\(\\frac{x + 0.5y}{n}\\)$$(100). Then round to the nearest integer. ",
                    "id": "C_189603_4"
                }
            ],
            "section_title": "A Formula for Finding the Percentile of a Value in a Data Set",
            "chapter_learning_objectives": [],
            "chapter_summary": "The values that divide a rank-ordered set of data into 100 equal parts are called percentiles. Percentiles are used to compare and interpret data. For example, an observation at the 50th percentile would be greater than 50 percent of the other observations in the set. Quartiles divide data into quarters. The first quartile (Q1) is the 25th percentile,the second quartile (Q2 or median) is 50th percentile, and the third quartile (Q3) is the 75th percentile. The interquartile range, or IQR, is the range of the middle 50 percent of the data values. The IQR is found by subtracting Q1 from Q3, and can help determine outliers by using the following two expressions.Q3 + IQR(1.5) Q1 \u2013 IQR(1.5) ",
            "chapter_introduction": "The common measures of location are quartiles and percentiles\n\nQuartiles are special percentiles. The first quartile, Q1, is the same as the 25th percentile, and the third quartile, Q3, is the same as the 75th percentile. The median, M, is called both the second quartile and the 50th percentile.\n\nTo calculate quartiles and percentiles, the data must be ordered from smallest to largest. Quartiles divide ordered data into quarters. Percentiles divide ordered data into hundredths. To score in the 90th percentile of an exam does not mean, necessarily, that you received 90% on a test. It means that 90% of test scores are the same or less than your score and 10% of the test scores are the same or greater than your test score.\n\nPercentiles are useful for comparing values. For this reason, universities and colleges use percentiles extensively. One instance in which colleges and universities use percentiles is when SAT results are used to determine a minimum testing score that will be used as an acceptance factor. For example, suppose Duke accepts SAT scores at or above the 75th percentile. That translates into a score of at least 1220.\n\nPercentiles are mostly used with very large populations. Therefore, if you were to say that 90% of the test scores are less (and not the same or less) than your score, it would be acceptable because removing one particular data value is not significant. \n\nThe median is a number that measures the \"center\" of the data. You can think of the median as the \"middle value,\" but it does not actually have to be one of the observed values. It is a number that separates ordered data into halves. Half the values are the same number or smaller than the median, and half the values are the same number or larger. For example, consider the following data.1; 11.5; 6; 7.2; 4; 8; 9; 10; 6.8; 8.3; 2; 2; 10; 1Ordered from smallest to largest:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nSince there are 14 observations, the median is between the seventh value, 6.8, and the eighth value, 7.2. To find the median, add the two values together and divide by two.\n\n$$\\[\\frac{6.8 + 7.2}{2} = 7\\]$$\n\nThe median is seven. Half of the values are smaller than seven and half of the values are larger than seven.\n\nQuartiles are numbers that separate the data into quarters. Quartiles may or may not be part of the data. To find the quartiles, first find the median or second quartile. The first quartile, Q1, is the middle value of the lower half of the data, and the third quartile, Q3, is the middle value, or median, of the upper half of the data. To get the idea, consider the same data set:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nThe median or second quartile is seven. The lower half of the data are 1, 1, 2, 2, 4, 6, 6.8. The middle value of the lower half is two.1; 1; 2; 2; 4; 6; 6.8\n\nThe number two, which is part of the data, is the first quartile. One-fourth of the entire sets of values are the same as or less than two and three-fourths of the values are more than two.\n\nThe upper half of the data is 7.2, 8, 8.3, 9, 10, 10, 11.5. The middle value of the upper half is nine.\n\nThe third quartile, Q3, is nine. Three-fourths (75%) of the ordered data set are less than nine. One-fourth (25%) of the ordered data set are greater than nine. The third quartile is part of the data set in this example.\n\nThe interquartile range is a number that indicates the spread of the middle half or the middle 50% of the data. It is the difference between the third quartile (Q3) and the first quartile (Q1).\n\nIQR = Q3 \u2013 Q1\n\nThe IQR can help to determine potential outliers. A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile. Potential outliers always require further investigation.",
            "bold_terms": [
                "quartiles",
                "percentiles",
                "median",
                "Quartiles",
                "second quartile",
                "first quartile",
                "third quartile",
                "interquartile range",
                "outliers",
                "A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-3-measures-of-the-location-of-the-data",
            "paragraphs": [
                {
                    "context": "A percentile indicates the relative standing of a data value when data are sorted into numerical order from smallest to largest. Percentages of data values are less than or equal to the pth percentile. For example, 15% of data values are less than or equal to the 15th percentile.\n\nLow percentiles always correspond to lower data values. High percentiles always correspond to higher data values. \n\nA percentile may or may not correspond to a value judgment about whether it is \"good\" or \"bad.\" The interpretation of whether a certain percentile is \"good\" or \"bad\" depends on the context of the situation to which the data applies. In some situations, a low percentile would be considered \"good;\" in other contexts a high percentile might be considered \"good\". In many situations, there is no value judgment that applies.\n\nUnderstanding how to interpret percentiles properly is important not only when describing data, but also when calculating probabilities in later chapters of this text.",
                    "id": "C_262017_5"
                }
            ],
            "section_title": "Interpreting Percentiles, Quartiles, and Median",
            "chapter_learning_objectives": [],
            "chapter_summary": "The values that divide a rank-ordered set of data into 100 equal parts are called percentiles. Percentiles are used to compare and interpret data. For example, an observation at the 50th percentile would be greater than 50 percent of the other observations in the set. Quartiles divide data into quarters. The first quartile (Q1) is the 25th percentile,the second quartile (Q2 or median) is 50th percentile, and the third quartile (Q3) is the 75th percentile. The interquartile range, or IQR, is the range of the middle 50 percent of the data values. The IQR is found by subtracting Q1 from Q3, and can help determine outliers by using the following two expressions.Q3 + IQR(1.5) Q1 \u2013 IQR(1.5) ",
            "chapter_introduction": "The common measures of location are quartiles and percentiles\n\nQuartiles are special percentiles. The first quartile, Q1, is the same as the 25th percentile, and the third quartile, Q3, is the same as the 75th percentile. The median, M, is called both the second quartile and the 50th percentile.\n\nTo calculate quartiles and percentiles, the data must be ordered from smallest to largest. Quartiles divide ordered data into quarters. Percentiles divide ordered data into hundredths. To score in the 90th percentile of an exam does not mean, necessarily, that you received 90% on a test. It means that 90% of test scores are the same or less than your score and 10% of the test scores are the same or greater than your test score.\n\nPercentiles are useful for comparing values. For this reason, universities and colleges use percentiles extensively. One instance in which colleges and universities use percentiles is when SAT results are used to determine a minimum testing score that will be used as an acceptance factor. For example, suppose Duke accepts SAT scores at or above the 75th percentile. That translates into a score of at least 1220.\n\nPercentiles are mostly used with very large populations. Therefore, if you were to say that 90% of the test scores are less (and not the same or less) than your score, it would be acceptable because removing one particular data value is not significant. \n\nThe median is a number that measures the \"center\" of the data. You can think of the median as the \"middle value,\" but it does not actually have to be one of the observed values. It is a number that separates ordered data into halves. Half the values are the same number or smaller than the median, and half the values are the same number or larger. For example, consider the following data.1; 11.5; 6; 7.2; 4; 8; 9; 10; 6.8; 8.3; 2; 2; 10; 1Ordered from smallest to largest:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nSince there are 14 observations, the median is between the seventh value, 6.8, and the eighth value, 7.2. To find the median, add the two values together and divide by two.\n\n$$\\[\\frac{6.8 + 7.2}{2} = 7\\]$$\n\nThe median is seven. Half of the values are smaller than seven and half of the values are larger than seven.\n\nQuartiles are numbers that separate the data into quarters. Quartiles may or may not be part of the data. To find the quartiles, first find the median or second quartile. The first quartile, Q1, is the middle value of the lower half of the data, and the third quartile, Q3, is the middle value, or median, of the upper half of the data. To get the idea, consider the same data set:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nThe median or second quartile is seven. The lower half of the data are 1, 1, 2, 2, 4, 6, 6.8. The middle value of the lower half is two.1; 1; 2; 2; 4; 6; 6.8\n\nThe number two, which is part of the data, is the first quartile. One-fourth of the entire sets of values are the same as or less than two and three-fourths of the values are more than two.\n\nThe upper half of the data is 7.2, 8, 8.3, 9, 10, 10, 11.5. The middle value of the upper half is nine.\n\nThe third quartile, Q3, is nine. Three-fourths (75%) of the ordered data set are less than nine. One-fourth (25%) of the ordered data set are greater than nine. The third quartile is part of the data set in this example.\n\nThe interquartile range is a number that indicates the spread of the middle half or the middle 50% of the data. It is the difference between the third quartile (Q3) and the first quartile (Q1).\n\nIQR = Q3 \u2013 Q1\n\nThe IQR can help to determine potential outliers. A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile. Potential outliers always require further investigation.",
            "bold_terms": [
                "quartiles",
                "percentiles",
                "median",
                "Quartiles",
                "second quartile",
                "first quartile",
                "third quartile",
                "interquartile range",
                "outliers",
                "A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-3-measures-of-the-location-of-the-data",
            "paragraphs": [
                {
                    "context": "When writing the interpretation of a percentile in the context of the given data, the sentence should contain the following information.\n\ninformation about the context of the situation being considered the data value (value of the variable) that represents the percentile the percent of individuals or items with data values below the percentile the percent of individuals or items with data values above the percentile. ",
                    "id": "C_13369_6"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "The values that divide a rank-ordered set of data into 100 equal parts are called percentiles. Percentiles are used to compare and interpret data. For example, an observation at the 50th percentile would be greater than 50 percent of the other observations in the set. Quartiles divide data into quarters. The first quartile (Q1) is the 25th percentile,the second quartile (Q2 or median) is 50th percentile, and the third quartile (Q3) is the 75th percentile. The interquartile range, or IQR, is the range of the middle 50 percent of the data values. The IQR is found by subtracting Q1 from Q3, and can help determine outliers by using the following two expressions.Q3 + IQR(1.5) Q1 \u2013 IQR(1.5) ",
            "chapter_introduction": "The common measures of location are quartiles and percentiles\n\nQuartiles are special percentiles. The first quartile, Q1, is the same as the 25th percentile, and the third quartile, Q3, is the same as the 75th percentile. The median, M, is called both the second quartile and the 50th percentile.\n\nTo calculate quartiles and percentiles, the data must be ordered from smallest to largest. Quartiles divide ordered data into quarters. Percentiles divide ordered data into hundredths. To score in the 90th percentile of an exam does not mean, necessarily, that you received 90% on a test. It means that 90% of test scores are the same or less than your score and 10% of the test scores are the same or greater than your test score.\n\nPercentiles are useful for comparing values. For this reason, universities and colleges use percentiles extensively. One instance in which colleges and universities use percentiles is when SAT results are used to determine a minimum testing score that will be used as an acceptance factor. For example, suppose Duke accepts SAT scores at or above the 75th percentile. That translates into a score of at least 1220.\n\nPercentiles are mostly used with very large populations. Therefore, if you were to say that 90% of the test scores are less (and not the same or less) than your score, it would be acceptable because removing one particular data value is not significant. \n\nThe median is a number that measures the \"center\" of the data. You can think of the median as the \"middle value,\" but it does not actually have to be one of the observed values. It is a number that separates ordered data into halves. Half the values are the same number or smaller than the median, and half the values are the same number or larger. For example, consider the following data.1; 11.5; 6; 7.2; 4; 8; 9; 10; 6.8; 8.3; 2; 2; 10; 1Ordered from smallest to largest:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nSince there are 14 observations, the median is between the seventh value, 6.8, and the eighth value, 7.2. To find the median, add the two values together and divide by two.\n\n$$\\[\\frac{6.8 + 7.2}{2} = 7\\]$$\n\nThe median is seven. Half of the values are smaller than seven and half of the values are larger than seven.\n\nQuartiles are numbers that separate the data into quarters. Quartiles may or may not be part of the data. To find the quartiles, first find the median or second quartile. The first quartile, Q1, is the middle value of the lower half of the data, and the third quartile, Q3, is the middle value, or median, of the upper half of the data. To get the idea, consider the same data set:1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nThe median or second quartile is seven. The lower half of the data are 1, 1, 2, 2, 4, 6, 6.8. The middle value of the lower half is two.1; 1; 2; 2; 4; 6; 6.8\n\nThe number two, which is part of the data, is the first quartile. One-fourth of the entire sets of values are the same as or less than two and three-fourths of the values are more than two.\n\nThe upper half of the data is 7.2, 8, 8.3, 9, 10, 10, 11.5. The middle value of the upper half is nine.\n\nThe third quartile, Q3, is nine. Three-fourths (75%) of the ordered data set are less than nine. One-fourth (25%) of the ordered data set are greater than nine. The third quartile is part of the data set in this example.\n\nThe interquartile range is a number that indicates the spread of the middle half or the middle 50% of the data. It is the difference between the third quartile (Q3) and the first quartile (Q1).\n\nIQR = Q3 \u2013 Q1\n\nThe IQR can help to determine potential outliers. A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile. Potential outliers always require further investigation.",
            "bold_terms": [
                "quartiles",
                "percentiles",
                "median",
                "Quartiles",
                "second quartile",
                "first quartile",
                "third quartile",
                "interquartile range",
                "outliers",
                "A value is suspected to be a potential outlier if it is less than (1.5)(IQR) below the first quartile or more than (1.5)(IQR) above the third quartile"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-4-box-plots",
            "paragraphs": [
                {
                    "context": "You may encounter box-and-whisker plots that have dots marking outlier values. In those cases, the whiskers are not extending to the minimum and maximum values.\n\nConsider, again, this dataset.\n\n1; 1; 2; 2; 4; 6; 6.8; 7.2; 8; 8.3; 9; 10; 10; 11.5\n\nThe first quartile is two, the median is seven, and the third quartile is nine. The smallest value is one, and the largest value is 11.5. The following image shows the constructed box plot.",
                    "id": "C_348154_0"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "Box plots are a type of graph that can help visually organize data. To graph a box plot the following data points must be calculated: the minimum value, the first quartile, the median, the third quartile, and the maximum value. Once the box plot is graphed, you can display and compare distributions of data.",
            "chapter_introduction": "Box plots (also called box-and-whisker plots or box-whisker plots) give a good graphical image of the concentration of the data. They also show how far the extreme values are from most of the data. A box plot is constructed from five values: the minimum value, the first quartile, the median, the third quartile, and the maximum value. We use these values to compare how close other data values are to them.\n\nTo construct a box plot, use a horizontal or vertical number line and a rectangular box. The smallest and largest data values label the endpoints of the axis. The first quartile marks one end of the box and the third quartile marks the other end of the box. Approximately the middle 50 percent of the data fall inside the box. The \"whiskers\" extend from the ends of the box to the smallest and largest data values. The median or second quartile can be between the first and third quartiles, or it can be one, or the other, or both. The box plot gives a good, quick picture of the data.",
            "bold_terms": [
                "Box plots",
                "box-and-whisker plots",
                "box-whisker plots",
                "the middle 50 percent of the data fall inside the box",
                "scaled number line"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-4-box-plots",
            "paragraphs": [
                {
                    "context": "See the calculator instructions on the TI web site or in the appendix.\n\nThe two whiskers extend from the first quartile to the smallest value and from the third quartile to the largest value. The median is shown with a dashed line.",
                    "id": "C_948365_1"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "Box plots are a type of graph that can help visually organize data. To graph a box plot the following data points must be calculated: the minimum value, the first quartile, the median, the third quartile, and the maximum value. Once the box plot is graphed, you can display and compare distributions of data.",
            "chapter_introduction": "Box plots (also called box-and-whisker plots or box-whisker plots) give a good graphical image of the concentration of the data. They also show how far the extreme values are from most of the data. A box plot is constructed from five values: the minimum value, the first quartile, the median, the third quartile, and the maximum value. We use these values to compare how close other data values are to them.\n\nTo construct a box plot, use a horizontal or vertical number line and a rectangular box. The smallest and largest data values label the endpoints of the axis. The first quartile marks one end of the box and the third quartile marks the other end of the box. Approximately the middle 50 percent of the data fall inside the box. The \"whiskers\" extend from the ends of the box to the smallest and largest data values. The median or second quartile can be between the first and third quartiles, or it can be one, or the other, or both. The box plot gives a good, quick picture of the data.",
            "bold_terms": [
                "Box plots",
                "box-and-whisker plots",
                "box-whisker plots",
                "the middle 50 percent of the data fall inside the box",
                "scaled number line"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-4-box-plots",
            "paragraphs": [
                {
                    "context": "It is important to start a box plot with a scaled number line. Otherwise the box plot may not be useful.",
                    "id": "C_7139_2"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "Box plots are a type of graph that can help visually organize data. To graph a box plot the following data points must be calculated: the minimum value, the first quartile, the median, the third quartile, and the maximum value. Once the box plot is graphed, you can display and compare distributions of data.",
            "chapter_introduction": "Box plots (also called box-and-whisker plots or box-whisker plots) give a good graphical image of the concentration of the data. They also show how far the extreme values are from most of the data. A box plot is constructed from five values: the minimum value, the first quartile, the median, the third quartile, and the maximum value. We use these values to compare how close other data values are to them.\n\nTo construct a box plot, use a horizontal or vertical number line and a rectangular box. The smallest and largest data values label the endpoints of the axis. The first quartile marks one end of the box and the third quartile marks the other end of the box. Approximately the middle 50 percent of the data fall inside the box. The \"whiskers\" extend from the ends of the box to the smallest and largest data values. The median or second quartile can be between the first and third quartiles, or it can be one, or the other, or both. The box plot gives a good, quick picture of the data.",
            "bold_terms": [
                "Box plots",
                "box-and-whisker plots",
                "box-whisker plots",
                "the middle 50 percent of the data fall inside the box",
                "scaled number line"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-4-box-plots",
            "paragraphs": [
                {
                    "context": "To find the minimum, maximum, and quartiles:\n\nEnter data into the list editor (Pres STAT 1:EDIT). If you need to clear the list, arrow up to the name L1, press CLEAR, and then arrow down.\n\nPut the data values into the list L1.\n\nPress STAT and arrow to CALC. Press 1:1-VarStats. Enter L1.\n\nPress ENTER.\n\nUse the down and up arrow keys to scroll.\n\nSmallest value = 59.\n\nLargest value = 77.\n\nQ1: First quartile = 64.5.\n\nQ2: Second quartile or median = 66.\n\nQ3: Third quartile = 70.\n\nTo construct the box plot:\n\nPress 4:Plotsoff. Press ENTER.\n\nArrow down and then use the right arrow key to go to the fifth picture, which is the box plot. Press ENTER.\n\nArrow down to Xlist: Press 2nd 1 for L1\n\nArrow down to Freq: Press ALPHA. Press 1.\n\nPress Zoom. Press 9: ZoomStat.\n\nPress TRACE, and use the arrow keys to examine the box plot.\n\nFor some sets of data, some of the largest value, smallest value, first quartile, median, and third quartile may be the same. For instance, you might have a data set in which the median and the third quartile are the same. In this case, the diagram would not have a dotted line inside the box displaying the median. The right side of the box would display both the third quartile and the median. For example, if the smallest value and the first quartile were both one, the median and the third quartile were both five, and the largest value was seven, the box plot would look like:\n\nIn this case, at least 25% of the values are equal to one. Twenty-five percent of the values are between one and five, inclusive. At least 25% of the values are equal to five. The top 25% of the values fall between five and seven, inclusive.",
                    "id": "C_762213_3"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "Box plots are a type of graph that can help visually organize data. To graph a box plot the following data points must be calculated: the minimum value, the first quartile, the median, the third quartile, and the maximum value. Once the box plot is graphed, you can display and compare distributions of data.",
            "chapter_introduction": "Box plots (also called box-and-whisker plots or box-whisker plots) give a good graphical image of the concentration of the data. They also show how far the extreme values are from most of the data. A box plot is constructed from five values: the minimum value, the first quartile, the median, the third quartile, and the maximum value. We use these values to compare how close other data values are to them.\n\nTo construct a box plot, use a horizontal or vertical number line and a rectangular box. The smallest and largest data values label the endpoints of the axis. The first quartile marks one end of the box and the third quartile marks the other end of the box. Approximately the middle 50 percent of the data fall inside the box. The \"whiskers\" extend from the ends of the box to the smallest and largest data values. The median or second quartile can be between the first and third quartiles, or it can be one, or the other, or both. The box plot gives a good, quick picture of the data.",
            "bold_terms": [
                "Box plots",
                "box-and-whisker plots",
                "box-whisker plots",
                "the middle 50 percent of the data fall inside the box",
                "scaled number line"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-5-measures-of-the-center-of-the-data",
            "paragraphs": [
                {
                    "context": "The words \u201cmean\u201d and \u201caverage\u201d are often used interchangeably. The substitution of one word for the other is common practice. The technical term is \u201carithmetic mean\u201d and \u201caverage\u201d is technically a center location. However, in practice among non-statisticians, \u201caverage\" is commonly accepted for \u201carithmetic mean.\u201d\n\nWhen each value in the data set is not unique, the mean can be calculated by multiplying each distinct value by its frequency and then dividing the sum by the total number of data values. The letter used to represent the sample mean is an x with a bar over it (pronounced \u201cx bar\u201d): $$\\(\\overline{x}\\)$$.\n\nThe Greek letter \u03bc (pronounced \"mew\") represents the population mean. One of the requirements for the sample mean to be a good estimate of the population mean is for the sample taken to be truly random.\n\nTo see that both ways of calculating the mean are the same, consider the sample:1; 1; 1; 2; 2; 3; 4; 4; 4; 4; 4\n\n$$\\[\\overline{x} = \\frac{1 + 1 + 1 + 2 + 2 + 3 + 4 + 4 + 4 + 4 + 4}{11} = 2.7\\]$$\n\n$$\\[\\overline{x} = \\frac{3(1) + 2(2) + 1(3) + 5(4)}{11} = 2.7\\]$$\n\nIn the second calculation, the frequencies are 3, 2, 1, and 5.\n\nYou can quickly find the location of the median by using the expression $$\\(\\frac{n + 1}{2}\\)$$.\n\nThe letter n is the total number of data values in the sample. If n is an odd number, the median is the middle value of the ordered data (ordered smallest to largest). If n is an even number, the median is equal to the two middle values added together and divided by two after the data has been ordered. For example, if the total number of data values is 97, then $$\\(\\frac{n + 1}{2}\\)$$=$$\\(\\frac{97 + 1}{2}\\)$$ = 49. The median is the 49th value in the ordered data. If the total number of data values is 100, then $$\\(\\frac{n + 1}{2}\\)$$=$$\\(\\frac{100 + 1}{2}\\)$$ = 50.5. The median occurs midway between the 50th and 51st values. The location of the median and the value of the median are not the same. The upper case letter M is often used to represent the median. The next example illustrates the location of the median and the value of the median.",
                    "id": "C_642114_0"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "The mean and the median can be calculated to help you find the \"center\" of a data set. The mean is the best estimate for the actual data set, but the median is the best measurement when a data set contains several outliers or extreme values. The mode will tell you the most frequently occurring datum (or data) in your data set. The mean, median, and mode are extremely helpful when you need to analyze your data, but if your data set consists of ranges which lack specific values, the mean may seem impossible to calculate. However, the mean can be approximated if you add the lower boundary with the upper boundary and divide by two to find the midpoint of each interval. Multiply each midpoint by the number of values found in the corresponding range. Divide the sum of these values by the total number of data values in the set.",
            "chapter_introduction": "The \"center\" of a data set is also a way of describing location.The two most widely used measures of the \"center\" of the data are the mean (average) and the median. To calculate the mean weight of 50 people, add the 50 weights together and divide by 50. To find the  median weight of the 50 people, order the data and find the number that splits the data into two equal parts. The median is generally a better measure of the center when there are extreme values or outliers because it is not affected by the precise numerical values of the outliers. The mean is the most common measure of the center.",
            "bold_terms": [
                "mean",
                "median",
                "mean weight",
                "median weight",
                "sample mean",
                "population mean",
                "not",
                "mode",
                "sampling distribution",
                "relative frequency distribution",
                "Sampling and Data",
                "relative frequency table",
                "If you let the number of samples get very large (say, 300 million or more), the relative frequency table becomes a relative frequency distribution",
                "statistic"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-5-measures-of-the-center-of-the-data",
            "paragraphs": [
                {
                    "context": "To find the mean and the median:\n\nClear list L1.  Pres STAT 4:ClrList. Enter 2nd 1 for list L1. Press ENTER.\n\nEnter data into the list editor.  Press STAT 1:EDIT.\n\nPut the data values into list L1.\n\nPress STAT and arrow to CALC.  Press 1:1-VarStats. Press 2nd 1 for L1 and then ENTER.\n\nPress the down and up arrow keys to scroll.\n\n$$\\(\\overline{x}\\)$$ = 23.6, M = 24\n\nAnother measure of the center is the mode. The mode is the most frequent value. There can be more than one mode in a data set as long as those values have the same frequency and that frequency is the highest. A data set with two modes is called bimodal.",
                    "id": "C_598429_1"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "The mean and the median can be calculated to help you find the \"center\" of a data set. The mean is the best estimate for the actual data set, but the median is the best measurement when a data set contains several outliers or extreme values. The mode will tell you the most frequently occurring datum (or data) in your data set. The mean, median, and mode are extremely helpful when you need to analyze your data, but if your data set consists of ranges which lack specific values, the mean may seem impossible to calculate. However, the mean can be approximated if you add the lower boundary with the upper boundary and divide by two to find the midpoint of each interval. Multiply each midpoint by the number of values found in the corresponding range. Divide the sum of these values by the total number of data values in the set.",
            "chapter_introduction": "The \"center\" of a data set is also a way of describing location.The two most widely used measures of the \"center\" of the data are the mean (average) and the median. To calculate the mean weight of 50 people, add the 50 weights together and divide by 50. To find the  median weight of the 50 people, order the data and find the number that splits the data into two equal parts. The median is generally a better measure of the center when there are extreme values or outliers because it is not affected by the precise numerical values of the outliers. The mean is the most common measure of the center.",
            "bold_terms": [
                "mean",
                "median",
                "mean weight",
                "median weight",
                "sample mean",
                "population mean",
                "not",
                "mode",
                "sampling distribution",
                "relative frequency distribution",
                "Sampling and Data",
                "relative frequency table",
                "If you let the number of samples get very large (say, 300 million or more), the relative frequency table becomes a relative frequency distribution",
                "statistic"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-5-measures-of-the-center-of-the-data",
            "paragraphs": [
                {
                    "context": "The Law of Large Numbers says that if you take samples of larger and larger size from any population, then the mean $$\\(\\overline{x}\\)$$ of the sample is very likely to get closer and closer to \u00b5. This is discussed in more detail later in the text.",
                    "id": "C_115761_2"
                }
            ],
            "section_title": "The Law of Large Numbers and the Mean",
            "chapter_learning_objectives": [],
            "chapter_summary": "The mean and the median can be calculated to help you find the \"center\" of a data set. The mean is the best estimate for the actual data set, but the median is the best measurement when a data set contains several outliers or extreme values. The mode will tell you the most frequently occurring datum (or data) in your data set. The mean, median, and mode are extremely helpful when you need to analyze your data, but if your data set consists of ranges which lack specific values, the mean may seem impossible to calculate. However, the mean can be approximated if you add the lower boundary with the upper boundary and divide by two to find the midpoint of each interval. Multiply each midpoint by the number of values found in the corresponding range. Divide the sum of these values by the total number of data values in the set.",
            "chapter_introduction": "The \"center\" of a data set is also a way of describing location.The two most widely used measures of the \"center\" of the data are the mean (average) and the median. To calculate the mean weight of 50 people, add the 50 weights together and divide by 50. To find the  median weight of the 50 people, order the data and find the number that splits the data into two equal parts. The median is generally a better measure of the center when there are extreme values or outliers because it is not affected by the precise numerical values of the outliers. The mean is the most common measure of the center.",
            "bold_terms": [
                "mean",
                "median",
                "mean weight",
                "median weight",
                "sample mean",
                "population mean",
                "not",
                "mode",
                "sampling distribution",
                "relative frequency distribution",
                "Sampling and Data",
                "relative frequency table",
                "If you let the number of samples get very large (say, 300 million or more), the relative frequency table becomes a relative frequency distribution",
                "statistic"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-5-measures-of-the-center-of-the-data",
            "paragraphs": [
                {
                    "context": "You can think of a sampling distribution as a  relative frequency distribution with a great many samples. (See Sampling and Data for a review of relative frequency). Suppose thirty randomly selected students were asked the number of movies they watched the previous week. The results are in the relative frequency table shown below.\n\nIf you let the number of samples get very large (say, 300 million or more), the relative frequency table becomes a relative frequency distribution.\n\nA statistic is a number calculated from a sample. Statistic examples include the mean, the median and the mode as well as others.  The sample mean $$\\(\\overline{x}\\)$$ is an example of a statistic which estimates the population mean \u03bc.",
                    "id": "C_951207_3"
                }
            ],
            "section_title": "Sampling Distributions and Statistic of a Sampling Distribution",
            "chapter_learning_objectives": [],
            "chapter_summary": "The mean and the median can be calculated to help you find the \"center\" of a data set. The mean is the best estimate for the actual data set, but the median is the best measurement when a data set contains several outliers or extreme values. The mode will tell you the most frequently occurring datum (or data) in your data set. The mean, median, and mode are extremely helpful when you need to analyze your data, but if your data set consists of ranges which lack specific values, the mean may seem impossible to calculate. However, the mean can be approximated if you add the lower boundary with the upper boundary and divide by two to find the midpoint of each interval. Multiply each midpoint by the number of values found in the corresponding range. Divide the sum of these values by the total number of data values in the set.",
            "chapter_introduction": "The \"center\" of a data set is also a way of describing location.The two most widely used measures of the \"center\" of the data are the mean (average) and the median. To calculate the mean weight of 50 people, add the 50 weights together and divide by 50. To find the  median weight of the 50 people, order the data and find the number that splits the data into two equal parts. The median is generally a better measure of the center when there are extreme values or outliers because it is not affected by the precise numerical values of the outliers. The mean is the most common measure of the center.",
            "bold_terms": [
                "mean",
                "median",
                "mean weight",
                "median weight",
                "sample mean",
                "population mean",
                "not",
                "mode",
                "sampling distribution",
                "relative frequency distribution",
                "Sampling and Data",
                "relative frequency table",
                "If you let the number of samples get very large (say, 300 million or more), the relative frequency table becomes a relative frequency distribution",
                "statistic"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-5-measures-of-the-center-of-the-data",
            "paragraphs": [
                {
                    "context": "When only grouped data is available, you do not know the individual data values (we only know intervals and interval frequencies); therefore, you cannot compute an exact mean for the data set. What we must do is estimate the actual mean by calculating the mean of a frequency table. A frequency table is a data representation in which grouped data is displayed along with the corresponding frequencies. To calculate the mean from a grouped frequency table we can apply the basic definition of mean: mean = $$\\(\\frac{data\\ sum}{number\\ of\\ data\\ values}\\)$$ We simply need to modify the definition to fit within the restrictions of a frequency table.\n\nSince we do not know the individual data values we can instead find the midpoint of each interval. The midpoint is $$\\(\\frac{lower\\ boundary + upper\\ boundary}{2}\\)$$. We can now modify the mean definition to be $$\\(Mean\\ of\\ Frequency\\ Table = \\frac{\\sum{fm}}{\\sum f}\\)$$ where f = the frequency of the interval and m = the midpoint of the interval.",
                    "id": "C_707997_4"
                }
            ],
            "section_title": "Calculating the Mean of Grouped Frequency Tables",
            "chapter_learning_objectives": [],
            "chapter_summary": "The mean and the median can be calculated to help you find the \"center\" of a data set. The mean is the best estimate for the actual data set, but the median is the best measurement when a data set contains several outliers or extreme values. The mode will tell you the most frequently occurring datum (or data) in your data set. The mean, median, and mode are extremely helpful when you need to analyze your data, but if your data set consists of ranges which lack specific values, the mean may seem impossible to calculate. However, the mean can be approximated if you add the lower boundary with the upper boundary and divide by two to find the midpoint of each interval. Multiply each midpoint by the number of values found in the corresponding range. Divide the sum of these values by the total number of data values in the set.",
            "chapter_introduction": "The \"center\" of a data set is also a way of describing location.The two most widely used measures of the \"center\" of the data are the mean (average) and the median. To calculate the mean weight of 50 people, add the 50 weights together and divide by 50. To find the  median weight of the 50 people, order the data and find the number that splits the data into two equal parts. The median is generally a better measure of the center when there are extreme values or outliers because it is not affected by the precise numerical values of the outliers. The mean is the most common measure of the center.",
            "bold_terms": [
                "mean",
                "median",
                "mean weight",
                "median weight",
                "sample mean",
                "population mean",
                "not",
                "mode",
                "sampling distribution",
                "relative frequency distribution",
                "Sampling and Data",
                "relative frequency table",
                "If you let the number of samples get very large (say, 300 million or more), the relative frequency table becomes a relative frequency distribution",
                "statistic"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-7-measures-of-the-spread-of-the-data",
            "paragraphs": [
                {
                    "context": "provides a numerical measure of the overall amount of variation in a data set, and can be used to determine whether a particular data value is close to or far from the mean. ",
                    "id": "C_611252_0"
                }
            ],
            "section_title": "The standard deviation",
            "chapter_learning_objectives": [],
            "chapter_summary": "The standard deviation can help you calculate the spread of data. There are different equations to use if are calculating the standard deviation of a sample or of a population. The Standard Deviation allows us to compare individual data or classes to the data set mean numerically. s = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or s = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ is the formula for calculating the standard deviation of a sample. To calculate the standard deviation of a population, we would use the population mean, \u03bc, and the formula \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\mu)}^{2}}{N}}\\)$$ or \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\mu)}^{2}}{N}}\\)$$. ",
            "chapter_introduction": "An important characteristic of any set of data is the variation in the data. In some data sets, the data values are concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean. The most common measure of variation, or spread, is the standard deviation. The standard deviation is a number that measures how far data values are from their mean.",
            "bold_terms": [
                "standard deviation",
                "Rosa waits for seven minutes",
                "two minutes longer than the average",
                "one standard deviation above the average",
                "Binh waits for one minute",
                "four minutes less than the average",
                "two standard deviations below the average",
                "one",
                "right",
                "two",
                "left",
                "value = mean + (#ofSTDEV)(standard deviation",
                "two standard deviations less than the mean",
                "value = mean + (#ofSTDEVs)(standard deviation",
                "sample",
                "Population",
                "deviation",
                "variance",
                "average of the squares of the deviations",
                "population",
                "sample",
                "n \u2013 1",
                "n - 1",
                "sampling variability of a statistic",
                "standard error of the mean",
                "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics",
                "If you add the deviations, the sum is always zero",
                "The sample variance is an estimate of the population variance",
                "always graph your data",
                "STAT",
                "1:Edit",
                "L1",
                "L2",
                "CALC",
                "1: 1-Var Stats",
                "2nd",
                "2 Enter"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-7-measures-of-the-spread-of-the-data",
            "paragraphs": [
                {
                    "context": "The standard deviation is always positive or zero. The standard deviation is small when the data are all concentrated close to the mean, exhibiting little variation or spread. The standard deviation is larger when the data values are more spread out from the mean, exhibiting more variation.\n\nSuppose that we are studying the amount of time customers wait in line at the checkout at supermarket A and supermarket B. the average wait time at both supermarkets is five minutes. At supermarket A, the standard deviation for the wait time is two minutes; at supermarket B the standard deviation for the wait time is four minutes.\n\nBecause supermarket B has a higher standard deviation, we know that there is more variation in the wait times at supermarket B. Overall, wait times at supermarket B are more spread out from the average; wait times at  supermarket A are more concentrated near the average.",
                    "id": "C_919156_1"
                }
            ],
            "section_title": "The standard deviation provides a measure of the overall variation in a data set",
            "chapter_learning_objectives": [],
            "chapter_summary": "The standard deviation can help you calculate the spread of data. There are different equations to use if are calculating the standard deviation of a sample or of a population. The Standard Deviation allows us to compare individual data or classes to the data set mean numerically. s = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or s = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ is the formula for calculating the standard deviation of a sample. To calculate the standard deviation of a population, we would use the population mean, \u03bc, and the formula \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\mu)}^{2}}{N}}\\)$$ or \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\mu)}^{2}}{N}}\\)$$. ",
            "chapter_introduction": "An important characteristic of any set of data is the variation in the data. In some data sets, the data values are concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean. The most common measure of variation, or spread, is the standard deviation. The standard deviation is a number that measures how far data values are from their mean.",
            "bold_terms": [
                "standard deviation",
                "Rosa waits for seven minutes",
                "two minutes longer than the average",
                "one standard deviation above the average",
                "Binh waits for one minute",
                "four minutes less than the average",
                "two standard deviations below the average",
                "one",
                "right",
                "two",
                "left",
                "value = mean + (#ofSTDEV)(standard deviation",
                "two standard deviations less than the mean",
                "value = mean + (#ofSTDEVs)(standard deviation",
                "sample",
                "Population",
                "deviation",
                "variance",
                "average of the squares of the deviations",
                "population",
                "sample",
                "n \u2013 1",
                "n - 1",
                "sampling variability of a statistic",
                "standard error of the mean",
                "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics",
                "If you add the deviations, the sum is always zero",
                "The sample variance is an estimate of the population variance",
                "always graph your data",
                "STAT",
                "1:Edit",
                "L1",
                "L2",
                "CALC",
                "1: 1-Var Stats",
                "2nd",
                "2 Enter"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-7-measures-of-the-spread-of-the-data",
            "paragraphs": [
                {
                    "context": "Suppose that Rosa and Binh both shop at supermarket A. Rosa waits at the checkout counter for seven minutes and Binh waits for one minute. At supermarket A, the mean waiting time is five minutes and the standard deviation is two minutes. The standard deviation can be used to determine whether a data value is close to or far from the mean.\n\nRosa waits for seven minutes:\n\nSeven is two minutes longer than the average of five; two minutes is equal to one standard deviation. Rosa's wait time of seven minutes is two minutes longer than the average of five minutes. Rosa's wait time of seven minutes is one standard deviation above the average of five minutes. \n\nBinh waits for one minute.\n\nOne is four minutes less than the average of five; four minutes is equal to two standard deviations. Binh's wait time of one minute is four minutes less than the average of five minutes. Binh's wait time of one minute is two standard deviations below the average of five minutes. A data value that is two standard deviations from the average is just on the borderline for what many statisticians would consider to be far from the average. Considering data to be far from the mean if it is more than two standard deviations away is more of an approximate \"rule of thumb\" than a rigid rule. In general, the shape of the distribution of the data affects how much of the data is further away than two standard deviations. (You will learn more about this in later chapters.) \n\nThe number line may help you understand standard deviation. If we were to put five and seven on a number line, seven is to the right of five. We say, then, that seven is one standard deviation to the right of five because 5 + (1)(2) = 7.\n\nIf one were also part of the data set, then one is two standard deviations to the left of five because 5 + (\u20132)(2) = 1.\n\nIn general, a value = mean + (#ofSTDEV)(standard deviation) where #ofSTDEVs = the number of standard deviations #ofSTDEV does not need to be an integer One is two standard deviations less than the mean of five because: 1 = 5 + (\u20132)(2). \n\nThe equation value = mean + (#ofSTDEVs)(standard deviation) can be expressed for a sample and for a population.\n\nsample: $$\\(x\\text{~=~}\\overline{x}\\text{~+~}(\\# ofSTDEV)(s)\\)$$ Population: $$\\(x = \\mu + (\\# ofSTDEV)(\\sigma)\\)$$ \n\nThe lower case letter s represents the sample standard deviation and the Greek letter \u03c3 (sigma, lower case) represents the population standard deviation.The symbol $$\\(\\overline{x}\\)$$ is the sample mean and the Greek symbol$$\\(\\mu\\)$$ is the population mean.",
                    "id": "C_807245_2"
                }
            ],
            "section_title": "The standard deviation can be used to determine whether a data value is close to or far from the mean",
            "chapter_learning_objectives": [],
            "chapter_summary": "The standard deviation can help you calculate the spread of data. There are different equations to use if are calculating the standard deviation of a sample or of a population. The Standard Deviation allows us to compare individual data or classes to the data set mean numerically. s = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or s = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ is the formula for calculating the standard deviation of a sample. To calculate the standard deviation of a population, we would use the population mean, \u03bc, and the formula \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\mu)}^{2}}{N}}\\)$$ or \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\mu)}^{2}}{N}}\\)$$. ",
            "chapter_introduction": "An important characteristic of any set of data is the variation in the data. In some data sets, the data values are concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean. The most common measure of variation, or spread, is the standard deviation. The standard deviation is a number that measures how far data values are from their mean.",
            "bold_terms": [
                "standard deviation",
                "Rosa waits for seven minutes",
                "two minutes longer than the average",
                "one standard deviation above the average",
                "Binh waits for one minute",
                "four minutes less than the average",
                "two standard deviations below the average",
                "one",
                "right",
                "two",
                "left",
                "value = mean + (#ofSTDEV)(standard deviation",
                "two standard deviations less than the mean",
                "value = mean + (#ofSTDEVs)(standard deviation",
                "sample",
                "Population",
                "deviation",
                "variance",
                "average of the squares of the deviations",
                "population",
                "sample",
                "n \u2013 1",
                "n - 1",
                "sampling variability of a statistic",
                "standard error of the mean",
                "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics",
                "If you add the deviations, the sum is always zero",
                "The sample variance is an estimate of the population variance",
                "always graph your data",
                "STAT",
                "1:Edit",
                "L1",
                "L2",
                "CALC",
                "1: 1-Var Stats",
                "2nd",
                "2 Enter"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-7-measures-of-the-spread-of-the-data",
            "paragraphs": [
                {
                    "context": "If x is a number, then the difference \"x \u2013 mean\" is called its deviation. In a data set, there are as many deviations as there are items in the data set. The deviations are used to calculate the standard deviation. If the numbers belong to a population, in symbols a deviation is x \u2013 \u03bc. For sample data, in symbols a deviation is x \u2013 $$\\(\\overline{x}\\)$$.\n\nThe procedure to calculate the standard deviation depends on whether the numbers are the entire population or are data from a sample.  The calculations are similar, but not identical.  Therefore the symbol used to represent the standard deviation depends on whether it is calculated from a population or a sample. The lower case letter s represents the sample standard deviation and the Greek letter \u03c3 (sigma, lower case) represents the population standard deviation. If the sample has the same characteristics as the population, then s should be a good estimate of \u03c3.\n\nTo calculate the standard deviation, we need to calculate the variance first.  The variance is the average of the squares of the deviations (the x \u2013 $$\\(\\overline{x}\\)$$ values for a sample, or the x \u2013 \u03bc values for a population). The symbol \u03c32 represents the population variance; the population standard deviation \u03c3 is the square root of the population variance. The symbol s2 represents the sample variance; the sample standard deviation s is the square root of the sample variance. You can think of the standard deviation as a special average of the deviations.\n\nIf the numbers come from a census of the entire population and not a sample, when we calculate the average of the squared deviations to find the variance, we divide by N, the number of items in the population. If the data are from a sample rather than a population, when we calculate the average of the squared deviations, we divide by n \u2013 1, one less than the number of items in the sample.",
                    "id": "C_18844_3"
                }
            ],
            "section_title": "Calculating the Standard Deviation",
            "chapter_learning_objectives": [],
            "chapter_summary": "The standard deviation can help you calculate the spread of data. There are different equations to use if are calculating the standard deviation of a sample or of a population. The Standard Deviation allows us to compare individual data or classes to the data set mean numerically. s = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or s = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ is the formula for calculating the standard deviation of a sample. To calculate the standard deviation of a population, we would use the population mean, \u03bc, and the formula \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\mu)}^{2}}{N}}\\)$$ or \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\mu)}^{2}}{N}}\\)$$. ",
            "chapter_introduction": "An important characteristic of any set of data is the variation in the data. In some data sets, the data values are concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean. The most common measure of variation, or spread, is the standard deviation. The standard deviation is a number that measures how far data values are from their mean.",
            "bold_terms": [
                "standard deviation",
                "Rosa waits for seven minutes",
                "two minutes longer than the average",
                "one standard deviation above the average",
                "Binh waits for one minute",
                "four minutes less than the average",
                "two standard deviations below the average",
                "one",
                "right",
                "two",
                "left",
                "value = mean + (#ofSTDEV)(standard deviation",
                "two standard deviations less than the mean",
                "value = mean + (#ofSTDEVs)(standard deviation",
                "sample",
                "Population",
                "deviation",
                "variance",
                "average of the squares of the deviations",
                "population",
                "sample",
                "n \u2013 1",
                "n - 1",
                "sampling variability of a statistic",
                "standard error of the mean",
                "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics",
                "If you add the deviations, the sum is always zero",
                "The sample variance is an estimate of the population variance",
                "always graph your data",
                "STAT",
                "1:Edit",
                "L1",
                "L2",
                "CALC",
                "1: 1-Var Stats",
                "2nd",
                "2 Enter"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-7-measures-of-the-spread-of-the-data",
            "paragraphs": [
                {
                    "context": " $$\\(s = \\sqrt{\\frac{\\Sigma{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or $$\\(s = \\sqrt{\\frac{\\Sigma f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$  For the sample standard deviation, the denominator is n - 1, that is the sample size MINUS 1. ",
                    "id": "C_975231_4"
                }
            ],
            "section_title": "Formulas for the Sample Standard Deviation",
            "chapter_learning_objectives": [],
            "chapter_summary": "The standard deviation can help you calculate the spread of data. There are different equations to use if are calculating the standard deviation of a sample or of a population. The Standard Deviation allows us to compare individual data or classes to the data set mean numerically. s = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or s = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ is the formula for calculating the standard deviation of a sample. To calculate the standard deviation of a population, we would use the population mean, \u03bc, and the formula \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\mu)}^{2}}{N}}\\)$$ or \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\mu)}^{2}}{N}}\\)$$. ",
            "chapter_introduction": "An important characteristic of any set of data is the variation in the data. In some data sets, the data values are concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean. The most common measure of variation, or spread, is the standard deviation. The standard deviation is a number that measures how far data values are from their mean.",
            "bold_terms": [
                "standard deviation",
                "Rosa waits for seven minutes",
                "two minutes longer than the average",
                "one standard deviation above the average",
                "Binh waits for one minute",
                "four minutes less than the average",
                "two standard deviations below the average",
                "one",
                "right",
                "two",
                "left",
                "value = mean + (#ofSTDEV)(standard deviation",
                "two standard deviations less than the mean",
                "value = mean + (#ofSTDEVs)(standard deviation",
                "sample",
                "Population",
                "deviation",
                "variance",
                "average of the squares of the deviations",
                "population",
                "sample",
                "n \u2013 1",
                "n - 1",
                "sampling variability of a statistic",
                "standard error of the mean",
                "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics",
                "If you add the deviations, the sum is always zero",
                "The sample variance is an estimate of the population variance",
                "always graph your data",
                "STAT",
                "1:Edit",
                "L1",
                "L2",
                "CALC",
                "1: 1-Var Stats",
                "2nd",
                "2 Enter"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-7-measures-of-the-spread-of-the-data",
            "paragraphs": [
                {
                    "context": "$$\\(\\sigma~ = ~\\sqrt{\\frac{\\Sigma{(x - \\mu)}^{2}}{N}}\\)$$ or $$\\(\\sigma~ = ~\\sqrt{\\frac{\\Sigma f{(x\u2013\\mu)}^{2}}{N}}\\)$$ For the population standard deviation, the denominator is N, the number of items in the population. \n\nIn these formulas, f represents the frequency with which a value appears. For example, if a value appears once, f is one. If a value appears three times in the data set or population, f is three.",
                    "id": "C_830028_5"
                }
            ],
            "section_title": "Formulas for the Population Standard Deviation",
            "chapter_learning_objectives": [],
            "chapter_summary": "The standard deviation can help you calculate the spread of data. There are different equations to use if are calculating the standard deviation of a sample or of a population. The Standard Deviation allows us to compare individual data or classes to the data set mean numerically. s = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or s = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ is the formula for calculating the standard deviation of a sample. To calculate the standard deviation of a population, we would use the population mean, \u03bc, and the formula \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\mu)}^{2}}{N}}\\)$$ or \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\mu)}^{2}}{N}}\\)$$. ",
            "chapter_introduction": "An important characteristic of any set of data is the variation in the data. In some data sets, the data values are concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean. The most common measure of variation, or spread, is the standard deviation. The standard deviation is a number that measures how far data values are from their mean.",
            "bold_terms": [
                "standard deviation",
                "Rosa waits for seven minutes",
                "two minutes longer than the average",
                "one standard deviation above the average",
                "Binh waits for one minute",
                "four minutes less than the average",
                "two standard deviations below the average",
                "one",
                "right",
                "two",
                "left",
                "value = mean + (#ofSTDEV)(standard deviation",
                "two standard deviations less than the mean",
                "value = mean + (#ofSTDEVs)(standard deviation",
                "sample",
                "Population",
                "deviation",
                "variance",
                "average of the squares of the deviations",
                "population",
                "sample",
                "n \u2013 1",
                "n - 1",
                "sampling variability of a statistic",
                "standard error of the mean",
                "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics",
                "If you add the deviations, the sum is always zero",
                "The sample variance is an estimate of the population variance",
                "always graph your data",
                "STAT",
                "1:Edit",
                "L1",
                "L2",
                "CALC",
                "1: 1-Var Stats",
                "2nd",
                "2 Enter"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-7-measures-of-the-spread-of-the-data",
            "paragraphs": [
                {
                    "context": "The statistic of a sampling distribution was discussed in Descriptive Statistics: Measuring the Center of the Data. How much the statistic varies from one sample to another is known as the  sampling variability of a statistic. You typically measure the sampling variability of a statistic by its standard error. The standard error of the mean is an example of a standard error. It is a special standard deviation and is known as the standard deviation of the sampling distribution of the mean. You will cover the standard error of the mean in the chapter The Central Limit Theorem (not now). The notation for the standard error of the mean is $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$ where \u03c3 is the standard deviation of the population and n is the size of the sample.",
                    "id": "C_300857_6"
                }
            ],
            "section_title": "Sampling Variability of a Statistic",
            "chapter_learning_objectives": [],
            "chapter_summary": "The standard deviation can help you calculate the spread of data. There are different equations to use if are calculating the standard deviation of a sample or of a population. The Standard Deviation allows us to compare individual data or classes to the data set mean numerically. s = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or s = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ is the formula for calculating the standard deviation of a sample. To calculate the standard deviation of a population, we would use the population mean, \u03bc, and the formula \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\mu)}^{2}}{N}}\\)$$ or \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\mu)}^{2}}{N}}\\)$$. ",
            "chapter_introduction": "An important characteristic of any set of data is the variation in the data. In some data sets, the data values are concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean. The most common measure of variation, or spread, is the standard deviation. The standard deviation is a number that measures how far data values are from their mean.",
            "bold_terms": [
                "standard deviation",
                "Rosa waits for seven minutes",
                "two minutes longer than the average",
                "one standard deviation above the average",
                "Binh waits for one minute",
                "four minutes less than the average",
                "two standard deviations below the average",
                "one",
                "right",
                "two",
                "left",
                "value = mean + (#ofSTDEV)(standard deviation",
                "two standard deviations less than the mean",
                "value = mean + (#ofSTDEVs)(standard deviation",
                "sample",
                "Population",
                "deviation",
                "variance",
                "average of the squares of the deviations",
                "population",
                "sample",
                "n \u2013 1",
                "n - 1",
                "sampling variability of a statistic",
                "standard error of the mean",
                "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics",
                "If you add the deviations, the sum is always zero",
                "The sample variance is an estimate of the population variance",
                "always graph your data",
                "STAT",
                "1:Edit",
                "L1",
                "L2",
                "CALC",
                "1: 1-Var Stats",
                "2nd",
                "2 Enter"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-7-measures-of-the-spread-of-the-data",
            "paragraphs": [
                {
                    "context": "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics. We will concentrate on using and interpreting the information that the standard deviation gives us. However you should study the following step-by-step example to help you understand how the standard deviation measures variation from the mean. (The calculator instructions appear at the end of this example.)",
                    "id": "C_727828_7"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "The standard deviation can help you calculate the spread of data. There are different equations to use if are calculating the standard deviation of a sample or of a population. The Standard Deviation allows us to compare individual data or classes to the data set mean numerically. s = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or s = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ is the formula for calculating the standard deviation of a sample. To calculate the standard deviation of a population, we would use the population mean, \u03bc, and the formula \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\mu)}^{2}}{N}}\\)$$ or \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\mu)}^{2}}{N}}\\)$$. ",
            "chapter_introduction": "An important characteristic of any set of data is the variation in the data. In some data sets, the data values are concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean. The most common measure of variation, or spread, is the standard deviation. The standard deviation is a number that measures how far data values are from their mean.",
            "bold_terms": [
                "standard deviation",
                "Rosa waits for seven minutes",
                "two minutes longer than the average",
                "one standard deviation above the average",
                "Binh waits for one minute",
                "four minutes less than the average",
                "two standard deviations below the average",
                "one",
                "right",
                "two",
                "left",
                "value = mean + (#ofSTDEV)(standard deviation",
                "two standard deviations less than the mean",
                "value = mean + (#ofSTDEVs)(standard deviation",
                "sample",
                "Population",
                "deviation",
                "variance",
                "average of the squares of the deviations",
                "population",
                "sample",
                "n \u2013 1",
                "n - 1",
                "sampling variability of a statistic",
                "standard error of the mean",
                "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics",
                "If you add the deviations, the sum is always zero",
                "The sample variance is an estimate of the population variance",
                "always graph your data",
                "STAT",
                "1:Edit",
                "L1",
                "L2",
                "CALC",
                "1: 1-Var Stats",
                "2nd",
                "2 Enter"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-7-measures-of-the-spread-of-the-data",
            "paragraphs": [
                {
                    "context": "The deviations show how spread out the data are about the mean. The data value 11.5 is farther from the mean than is the data value 11 which is indicated by the deviations 0.97 and 0.47. A positive deviation occurs when the data value is greater than the mean, whereas a negative deviation occurs when the data value is less than the mean. The deviation is \u20131.525 for the data value nine. If you add the deviations, the sum is always zero. (For Example 2.32, there are n = 20 deviations.) So you cannot simply add the deviations to get the spread of the data. By squaring the deviations, you make them positive numbers, and the sum will also be positive. The variance, then, is the average squared deviation.\n\nThe variance is a squared measure and does not have the same units as the data. Taking the square root solves the problem. The standard deviation measures the spread in the same units as the data.\n\nNotice that instead of dividing by n = 20, the calculation divided by n \u2013 1 = 20 \u2013 1 = 19 because the data is a sample. For the sample variance, we divide by the sample size minus one (n \u2013 1). Why not divide by n?  The answer has to do with the population variance. The sample variance is an estimate of the population variance. Based on the theoretical mathematics that lies behind these calculations, dividing by (n \u2013 1) gives a better estimate of the population variance.",
                    "id": "C_297273_8"
                }
            ],
            "section_title": "Explanation of the standard deviation calculation shown in the table",
            "chapter_learning_objectives": [],
            "chapter_summary": "The standard deviation can help you calculate the spread of data. There are different equations to use if are calculating the standard deviation of a sample or of a population. The Standard Deviation allows us to compare individual data or classes to the data set mean numerically. s = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or s = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ is the formula for calculating the standard deviation of a sample. To calculate the standard deviation of a population, we would use the population mean, \u03bc, and the formula \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\mu)}^{2}}{N}}\\)$$ or \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\mu)}^{2}}{N}}\\)$$. ",
            "chapter_introduction": "An important characteristic of any set of data is the variation in the data. In some data sets, the data values are concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean. The most common measure of variation, or spread, is the standard deviation. The standard deviation is a number that measures how far data values are from their mean.",
            "bold_terms": [
                "standard deviation",
                "Rosa waits for seven minutes",
                "two minutes longer than the average",
                "one standard deviation above the average",
                "Binh waits for one minute",
                "four minutes less than the average",
                "two standard deviations below the average",
                "one",
                "right",
                "two",
                "left",
                "value = mean + (#ofSTDEV)(standard deviation",
                "two standard deviations less than the mean",
                "value = mean + (#ofSTDEVs)(standard deviation",
                "sample",
                "Population",
                "deviation",
                "variance",
                "average of the squares of the deviations",
                "population",
                "sample",
                "n \u2013 1",
                "n - 1",
                "sampling variability of a statistic",
                "standard error of the mean",
                "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics",
                "If you add the deviations, the sum is always zero",
                "The sample variance is an estimate of the population variance",
                "always graph your data",
                "STAT",
                "1:Edit",
                "L1",
                "L2",
                "CALC",
                "1: 1-Var Stats",
                "2nd",
                "2 Enter"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-7-measures-of-the-spread-of-the-data",
            "paragraphs": [
                {
                    "context": "Your concentration should be on what the standard deviation tells us about the data. The standard deviation is a number which measures how far the data are spread from the mean. Let a calculator or computer do the arithmetic.\n\nThe standard deviation, s or \u03c3, is either zero or larger than zero. Describing the data with reference to the spread is called \"variability\".  The variability in data depends upon the method by which the outcomes are obtained; for example, by measuring or by random sampling. When the standard deviation is zero, there is no spread; that is, the all the data values are equal to each other. The standard deviation is small when the data are all concentrated close to the mean, and is larger when the data values show more variation from the mean. When the standard deviation is a lot larger than zero, the data values are very spread out about the mean; outliers can make s or \u03c3 very large.\n\nThe standard deviation, when first presented, can seem unclear.  By graphing your data, you can get a better \"feel\" for the deviations and the standard deviation.  You will find that in symmetrical distributions, the standard deviation can be very helpful but in skewed distributions, the standard deviation may not be much help. The reason is that the two sides of a skewed distribution have different spreads. In a skewed distribution, it is better to look at the first quartile, the median, the third quartile, the smallest value, and the largest value. Because numbers can be confusing, always graph your data. Display your data in a histogram or a box plot.",
                    "id": "C_708832_9"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "The standard deviation can help you calculate the spread of data. There are different equations to use if are calculating the standard deviation of a sample or of a population. The Standard Deviation allows us to compare individual data or classes to the data set mean numerically. s = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or s = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ is the formula for calculating the standard deviation of a sample. To calculate the standard deviation of a population, we would use the population mean, \u03bc, and the formula \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\mu)}^{2}}{N}}\\)$$ or \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\mu)}^{2}}{N}}\\)$$. ",
            "chapter_introduction": "An important characteristic of any set of data is the variation in the data. In some data sets, the data values are concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean. The most common measure of variation, or spread, is the standard deviation. The standard deviation is a number that measures how far data values are from their mean.",
            "bold_terms": [
                "standard deviation",
                "Rosa waits for seven minutes",
                "two minutes longer than the average",
                "one standard deviation above the average",
                "Binh waits for one minute",
                "four minutes less than the average",
                "two standard deviations below the average",
                "one",
                "right",
                "two",
                "left",
                "value = mean + (#ofSTDEV)(standard deviation",
                "two standard deviations less than the mean",
                "value = mean + (#ofSTDEVs)(standard deviation",
                "sample",
                "Population",
                "deviation",
                "variance",
                "average of the squares of the deviations",
                "population",
                "sample",
                "n \u2013 1",
                "n - 1",
                "sampling variability of a statistic",
                "standard error of the mean",
                "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics",
                "If you add the deviations, the sum is always zero",
                "The sample variance is an estimate of the population variance",
                "always graph your data",
                "STAT",
                "1:Edit",
                "L1",
                "L2",
                "CALC",
                "1: 1-Var Stats",
                "2nd",
                "2 Enter"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-7-measures-of-the-spread-of-the-data",
            "paragraphs": [
                {
                    "context": "Recall that for grouped data we do not know individual data values, so we cannot describe the typical value of the data with precision. In other words, we cannot find the exact mean, median, or mode. We can, however, determine the best estimate of the measures of center by finding the mean of the grouped data with the formula:$$\\(Mean\\ of\\ Frequency\\ Table = \\frac{\\sum{fm}}{\\sum f}\\)$$where $$\\(f =\\)$$ interval frequencies and m = interval midpoints.\n\nJust as we could not find the exact mean, neither can we find the exact standard deviation. Remember that standard deviation describes numerically the expected deviation a data value has from the mean. In simple English, the standard deviation allows us to compare how \u201cunusual\u201d individual data is compared to the mean.",
                    "id": "C_473599_10"
                }
            ],
            "section_title": "Standard deviation of Grouped Frequency Tables",
            "chapter_learning_objectives": [],
            "chapter_summary": "The standard deviation can help you calculate the spread of data. There are different equations to use if are calculating the standard deviation of a sample or of a population. The Standard Deviation allows us to compare individual data or classes to the data set mean numerically. s = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or s = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ is the formula for calculating the standard deviation of a sample. To calculate the standard deviation of a population, we would use the population mean, \u03bc, and the formula \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\mu)}^{2}}{N}}\\)$$ or \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\mu)}^{2}}{N}}\\)$$. ",
            "chapter_introduction": "An important characteristic of any set of data is the variation in the data. In some data sets, the data values are concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean. The most common measure of variation, or spread, is the standard deviation. The standard deviation is a number that measures how far data values are from their mean.",
            "bold_terms": [
                "standard deviation",
                "Rosa waits for seven minutes",
                "two minutes longer than the average",
                "one standard deviation above the average",
                "Binh waits for one minute",
                "four minutes less than the average",
                "two standard deviations below the average",
                "one",
                "right",
                "two",
                "left",
                "value = mean + (#ofSTDEV)(standard deviation",
                "two standard deviations less than the mean",
                "value = mean + (#ofSTDEVs)(standard deviation",
                "sample",
                "Population",
                "deviation",
                "variance",
                "average of the squares of the deviations",
                "population",
                "sample",
                "n \u2013 1",
                "n - 1",
                "sampling variability of a statistic",
                "standard error of the mean",
                "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics",
                "If you add the deviations, the sum is always zero",
                "The sample variance is an estimate of the population variance",
                "always graph your data",
                "STAT",
                "1:Edit",
                "L1",
                "L2",
                "CALC",
                "1: 1-Var Stats",
                "2nd",
                "2 Enter"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-7-measures-of-the-spread-of-the-data",
            "paragraphs": [
                {
                    "context": "Find the standard deviation for the data from the previous example\n\nFirst, press the STAT key and select 1:Edit\n\nInput the midpoint values into L1 and the frequencies into L2\n\nSelect STAT, CALC, and 1: 1-Var Stats\n\nSelect 2nd then 1 then , 2nd then 2 Enter\n\nYou will see displayed both a population standard deviation, \u03c3x, and the sample standard deviation, sx.",
                    "id": "C_262675_11"
                }
            ],
            "section_title": "Try It  2.34",
            "chapter_learning_objectives": [],
            "chapter_summary": "The standard deviation can help you calculate the spread of data. There are different equations to use if are calculating the standard deviation of a sample or of a population. The Standard Deviation allows us to compare individual data or classes to the data set mean numerically. s = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or s = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ is the formula for calculating the standard deviation of a sample. To calculate the standard deviation of a population, we would use the population mean, \u03bc, and the formula \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\mu)}^{2}}{N}}\\)$$ or \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\mu)}^{2}}{N}}\\)$$. ",
            "chapter_introduction": "An important characteristic of any set of data is the variation in the data. In some data sets, the data values are concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean. The most common measure of variation, or spread, is the standard deviation. The standard deviation is a number that measures how far data values are from their mean.",
            "bold_terms": [
                "standard deviation",
                "Rosa waits for seven minutes",
                "two minutes longer than the average",
                "one standard deviation above the average",
                "Binh waits for one minute",
                "four minutes less than the average",
                "two standard deviations below the average",
                "one",
                "right",
                "two",
                "left",
                "value = mean + (#ofSTDEV)(standard deviation",
                "two standard deviations less than the mean",
                "value = mean + (#ofSTDEVs)(standard deviation",
                "sample",
                "Population",
                "deviation",
                "variance",
                "average of the squares of the deviations",
                "population",
                "sample",
                "n \u2013 1",
                "n - 1",
                "sampling variability of a statistic",
                "standard error of the mean",
                "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics",
                "If you add the deviations, the sum is always zero",
                "The sample variance is an estimate of the population variance",
                "always graph your data",
                "STAT",
                "1:Edit",
                "L1",
                "L2",
                "CALC",
                "1: 1-Var Stats",
                "2nd",
                "2 Enter"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "2-7-measures-of-the-spread-of-the-data",
            "paragraphs": [
                {
                    "context": "The standard deviation is useful when comparing data values that come from different data sets. If the data sets have different means and standard deviations, then comparing the data values directly can be misleading.\n\nFor each data value, calculate how many standard deviations away from its mean the value is. Use the formula: value = mean + (#ofSTDEVs)(standard deviation); solve for #ofSTDEVs. $$\\(\\# ofSTDEVs = \\frac{\\text{value~\u2013~mean}}{\\text{standard~deviation}}\\)$$ Compare the results of this calculation. \n\n#ofSTDEVs is often called a \"z-score\"; we can use the symbol z. In symbols, the formulas become:\n\nThe following lists give a few facts that provide a little more insight into what the standard deviation tells us about the distribution of the data.",
                    "id": "C_534243_12"
                }
            ],
            "section_title": "Comparing Values from Different Data Sets",
            "chapter_learning_objectives": [],
            "chapter_summary": "The standard deviation can help you calculate the spread of data. There are different equations to use if are calculating the standard deviation of a sample or of a population. The Standard Deviation allows us to compare individual data or classes to the data set mean numerically. s = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ or s = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\overline{x})}^{2}}{n - 1}}\\)$$ is the formula for calculating the standard deviation of a sample. To calculate the standard deviation of a population, we would use the population mean, \u03bc, and the formula \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}{(x - \\mu)}^{2}}{N}}\\)$$ or \u03c3 = $$\\(\\sqrt{\\frac{\\sum^{}f{(x - \\mu)}^{2}}{N}}\\)$$. ",
            "chapter_introduction": "An important characteristic of any set of data is the variation in the data. In some data sets, the data values are concentrated closely near the mean; in other data sets, the data values are more widely spread out from the mean. The most common measure of variation, or spread, is the standard deviation. The standard deviation is a number that measures how far data values are from their mean.",
            "bold_terms": [
                "standard deviation",
                "Rosa waits for seven minutes",
                "two minutes longer than the average",
                "one standard deviation above the average",
                "Binh waits for one minute",
                "four minutes less than the average",
                "two standard deviations below the average",
                "one",
                "right",
                "two",
                "left",
                "value = mean + (#ofSTDEV)(standard deviation",
                "two standard deviations less than the mean",
                "value = mean + (#ofSTDEVs)(standard deviation",
                "sample",
                "Population",
                "deviation",
                "variance",
                "average of the squares of the deviations",
                "population",
                "sample",
                "n \u2013 1",
                "n - 1",
                "sampling variability of a statistic",
                "standard error of the mean",
                "In practice, USE A CALCULATOR OR COMPUTER SOFTWARE TO CALCULATE THE STANDARD DEVIATION. If you are using a TI-83, 83+, 84+ calculator, you need to select the appropriate standard deviation \u03c3x or sx from the summary statistics",
                "If you add the deviations, the sum is always zero",
                "The sample variance is an estimate of the population variance",
                "always graph your data",
                "STAT",
                "1:Edit",
                "L1",
                "L2",
                "CALC",
                "1: 1-Var Stats",
                "2nd",
                "2 Enter"
            ],
            "chapter_concept": [
                {
                    "name": "Box plot",
                    "description": "a graph that gives a quick picture of the middle 50% of the data"
                },
                {
                    "name": "First Quartile",
                    "description": "the value that is the median of the of the lower half of the ordered data set"
                },
                {
                    "name": "Frequency",
                    "description": " the number of times a value of the data occurs"
                },
                {
                    "name": "Frequency Polygon",
                    "description": "looks like a line graph but uses intervals to display ranges of large amounts of data"
                },
                {
                    "name": "Frequency Table",
                    "description": " a data representation in which grouped data is displayed along with the corresponding frequencies"
                },
                {
                    "name": "Histogram",
                    "description": " a graphical representation in x-y form of the distribution of data in a data set; x represents the data and y represents the frequency, or relative frequency. The graph consists of contiguous rectangles."
                },
                {
                    "name": "Interquartile Range",
                    "description": " or IQR, is the range of the middle 50 percent of the data values; theIQR is found by subtracting the first quartile from the third quartile."
                },
                {
                    "name": "Interval",
                    "description": "also called a class interval; an interval represents a range of data and is used when displaying large data sets"
                },
                {
                    "name": "Mean",
                    "description": " a number that measures the central tendency of the data; a common name for mean is 'average.' The term 'mean' is a shortened form of 'arithmetic mean.' By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\  = \\ \\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu = \\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Median",
                    "description": " a number that separates ordered data into halves;  half the values are the same number or smaller than the median and half the values are the same number or larger than the median. The median may or may not be part of the data."
                },
                {
                    "name": "Midpoint",
                    "description": " the mean of an interval in a frequency table"
                },
                {
                    "name": "Mode",
                    "description": " the value that appears most frequently in a set of data"
                },
                {
                    "name": "Outlier",
                    "description": " an observation that does not fit the rest of the data"
                },
                {
                    "name": "Paired Data Set",
                    "description": "two data sets that have a one to one relationship so that:both data sets are the same size, andeach data point in one data set is matched with exactly one point from the other set."
                },
                {
                    "name": "Percentile",
                    "description": " a number that divides ordered data into hundredths; percentiles may or may not be part of the data. The median of the data is the second quartile and the 50th percentile. The first and third quartiles are the 25th and the 75th percentiles, respectively."
                },
                {
                    "name": "Quartiles",
                    "description": " the numbers that separate the data into quarters; quartiles may or may not be part of the data. The second quartile is the median of the data."
                },
                {
                    "name": "Relative Frequency",
                    "description": " the ratio of the number of times a value of the data occurs in the set of all outcomes to the number of all outcomes"
                },
                {
                    "name": "Skewed",
                    "description": "used to describe data that is not symmetrical; when the right side of a graph looks \u201cchopped off\u201d compared the left side, we say it is \u201cskewed to the left.\u201d When the left side of the graph looks \u201cchopped off\u201d compared to the right side, we say the data is \u201cskewed to the right.\u201d Alternatively: when the lower values of the data are more spread out, we say the data are skewed to the left. When the greater values are more spread out, the data are skewed to the right."
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variance",
                    "description": " mean of the squared deviations from the mean, or the square of the standard deviation; for a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "3-2-independent-and-mutually-exclusive-events",
            "paragraphs": [
                {
                    "context": "Two events are independent if the following are true:\n\nP(A|B) = P(A) P(B|A) = P(B) P(A AND B) = P(A)P(B) \n\nTwo events A and B are independent if the knowledge that one occurred does not affect the chance the other occurs. For example, the outcomes of two roles of a fair die are independent events. The outcome of the first roll does not change the probability for the outcome of the second roll. To show two events are independent, you must show only one of the above conditions. If two events are NOT independent, then we say that they are dependent.\n\nSampling may be done with replacement or without replacement.\n\nWith replacement: If each member of a population is replaced after it is picked, then that member has the possibility of being chosen more than once. When sampling is done with replacement, then events are considered to be independent, meaning the result of the first pick will not change the probabilities for the second pick. Without replacement: When sampling is done without replacement, each member of a population may be chosen only once. In this case, the probabilities for the second pick are affected by the result of the first pick. The events are considered to be dependent or not independent. \n\nIf it is not known whether A and B are independent or dependent, assume they are dependent until you can show otherwise.",
                    "id": "C_624990_0"
                }
            ],
            "section_title": "Independent Events",
            "chapter_learning_objectives": [],
            "chapter_summary": "Two events A and B are independent if the knowledge that one occurred does not affect the chance the other occurs. If two events are not independent, then we say that they are dependent.In sampling with replacement, each member of a population is replaced after it is picked, so that member has the possibility of being chosen more than once, and the events are considered to be independent. In sampling without replacement, each member of a population may be chosen only once, and the events are considered not to be independent. When events do not share outcomes, they are mutually exclusive of each other.",
            "chapter_introduction": "Independent and mutually exclusive do not mean the same thing.",
            "bold_terms": [
                "not",
                "independent",
                "only one",
                "dependent",
                "with",
                "replacement",
                "without replacement",
                "With replacement",
                "Without replacement",
                "assume they are dependent until you can show otherwise",
                "mutually exclusive",
                "assume they are not until you can show otherwise"
            ],
            "chapter_concept": [
                {
                    "name": "Conditional Probability",
                    "description": "the likelihood that an event will occur given that another event has already occurred"
                },
                {
                    "name": "contingency table",
                    "description": "the method of displaying a frequency distribution as a table with rows and columns to show how two variables may be dependent (contingent) upon each other; the table provides an easy way to calculate conditional probabilities."
                },
                {
                    "name": "Dependent Events",
                    "description": "If two events are NOT independent, then we say that they are dependent."
                },
                {
                    "name": "Equally Likely",
                    "description": "Each outcome of an experiment has the same probability."
                },
                {
                    "name": "Event",
                    "description": "a subset of the set of all outcomes of an experiment; the set of all outcomes of an experiment is called a sample space and is usually denoted by S. An event is an arbitrary subset in S. It can contain one outcome, two outcomes, no outcomes (empty subset), the entire sample space, and the like. Standard notations for events are capital letters such as A, B, C, and so on."
                },
                {
                    "name": "Experiment",
                    "description": "a planned activity carried out under controlled conditions"
                },
                {
                    "name": "Independent Events",
                    "description": "The occurrence of one event has no effect on the probability of the occurrence of another event. Events A and B are independent if one of the following is true:P(A|B) = P(A)P(B|A) = P(B)P(A AND B) = P(A)P(B)"
                },
                {
                    "name": "Mutually Exclusive",
                    "description": "Two events are mutually exclusive if the probability that they both happen at the same time is zero. If events A and B are mutually exclusive, then P(A AND B) = 0."
                },
                {
                    "name": "Outcome",
                    "description": "a particular result of an experiment"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur; the foundation of statistics is given by the following 3 axioms (by A.N. Kolmogorov, 1930\u2019s): Let S denote the sample space and A and B are two events in S. Then:0 \u2264 P(A) \u2264 1If A and B are any two mutually exclusive events, then P(A OR B) = P(A) + P(B).P(S) = 1"
                },
                {
                    "name": "Sample Space",
                    "description": "the set of all possible outcomes of an experiment"
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "If each member of a population is replaced after it is picked, then that member has the possibility of being chosen more than once."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "When sampling is done without replacement, each member of a population may be chosen only once."
                },
                {
                    "name": "The AND Event",
                    "description": "An outcome is in the event A AND B if the outcome is in both A AND B at the same time."
                },
                {
                    "name": "The Complement Event",
                    "description": "The complement of event A consists of all outcomes that are NOT in A."
                },
                {
                    "name": "The Or Event",
                    "description": "An outcome is in the event A OR B if the outcome is in A or is in B or is in both A and B."
                },
                {
                    "name": "Tree Diagram",
                    "description": "the useful visual representation of a sample space and events in the form of a \u201ctree\u201d with branches marked by possible outcomes together with associated probabilities (frequencies, relative frequencies)"
                },
                {
                    "name": "Venn Diagram",
                    "description": "the visual representation of a sample space and events in the form of circles or ovals showing their intersections"
                }
            ]
        },
        {
            "title": "3-2-independent-and-mutually-exclusive-events",
            "paragraphs": [
                {
                    "context": "A and B are mutually exclusive events if they cannot occur at the same time. This means that A and B do not share any outcomes and P(A AND B) = 0.\n\nFor example, suppose the sample space S = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}. Let A = {1, 2, 3, 4, 5}, B = {4, 5, 6, 7, 8}, and C = {7, 9}. A AND B = {4, 5}. P(A AND B) = $$\\(\\frac{2}{10}\\)$$ and is not equal to zero. Therefore, A and B are not mutually exclusive. A and C do not have any numbers in common so P(A AND C) = 0. Therefore, A and C are mutually exclusive.\n\nIf it is not known whether A and B are mutually exclusive, assume they are not until you can show otherwise. The following examples illustrate these definitions and terms.",
                    "id": "C_475564_1"
                }
            ],
            "section_title": "Mutually Exclusive Events",
            "chapter_learning_objectives": [],
            "chapter_summary": "Two events A and B are independent if the knowledge that one occurred does not affect the chance the other occurs. If two events are not independent, then we say that they are dependent.In sampling with replacement, each member of a population is replaced after it is picked, so that member has the possibility of being chosen more than once, and the events are considered to be independent. In sampling without replacement, each member of a population may be chosen only once, and the events are considered not to be independent. When events do not share outcomes, they are mutually exclusive of each other.",
            "chapter_introduction": "Independent and mutually exclusive do not mean the same thing.",
            "bold_terms": [
                "not",
                "independent",
                "only one",
                "dependent",
                "with",
                "replacement",
                "without replacement",
                "With replacement",
                "Without replacement",
                "assume they are dependent until you can show otherwise",
                "mutually exclusive",
                "assume they are not until you can show otherwise"
            ],
            "chapter_concept": [
                {
                    "name": "Conditional Probability",
                    "description": "the likelihood that an event will occur given that another event has already occurred"
                },
                {
                    "name": "contingency table",
                    "description": "the method of displaying a frequency distribution as a table with rows and columns to show how two variables may be dependent (contingent) upon each other; the table provides an easy way to calculate conditional probabilities."
                },
                {
                    "name": "Dependent Events",
                    "description": "If two events are NOT independent, then we say that they are dependent."
                },
                {
                    "name": "Equally Likely",
                    "description": "Each outcome of an experiment has the same probability."
                },
                {
                    "name": "Event",
                    "description": "a subset of the set of all outcomes of an experiment; the set of all outcomes of an experiment is called a sample space and is usually denoted by S. An event is an arbitrary subset in S. It can contain one outcome, two outcomes, no outcomes (empty subset), the entire sample space, and the like. Standard notations for events are capital letters such as A, B, C, and so on."
                },
                {
                    "name": "Experiment",
                    "description": "a planned activity carried out under controlled conditions"
                },
                {
                    "name": "Independent Events",
                    "description": "The occurrence of one event has no effect on the probability of the occurrence of another event. Events A and B are independent if one of the following is true:P(A|B) = P(A)P(B|A) = P(B)P(A AND B) = P(A)P(B)"
                },
                {
                    "name": "Mutually Exclusive",
                    "description": "Two events are mutually exclusive if the probability that they both happen at the same time is zero. If events A and B are mutually exclusive, then P(A AND B) = 0."
                },
                {
                    "name": "Outcome",
                    "description": "a particular result of an experiment"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur; the foundation of statistics is given by the following 3 axioms (by A.N. Kolmogorov, 1930\u2019s): Let S denote the sample space and A and B are two events in S. Then:0 \u2264 P(A) \u2264 1If A and B are any two mutually exclusive events, then P(A OR B) = P(A) + P(B).P(S) = 1"
                },
                {
                    "name": "Sample Space",
                    "description": "the set of all possible outcomes of an experiment"
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "If each member of a population is replaced after it is picked, then that member has the possibility of being chosen more than once."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "When sampling is done without replacement, each member of a population may be chosen only once."
                },
                {
                    "name": "The AND Event",
                    "description": "An outcome is in the event A AND B if the outcome is in both A AND B at the same time."
                },
                {
                    "name": "The Complement Event",
                    "description": "The complement of event A consists of all outcomes that are NOT in A."
                },
                {
                    "name": "The Or Event",
                    "description": "An outcome is in the event A OR B if the outcome is in A or is in B or is in both A and B."
                },
                {
                    "name": "Tree Diagram",
                    "description": "the useful visual representation of a sample space and events in the form of a \u201ctree\u201d with branches marked by possible outcomes together with associated probabilities (frequencies, relative frequencies)"
                },
                {
                    "name": "Venn Diagram",
                    "description": "the visual representation of a sample space and events in the form of circles or ovals showing their intersections"
                }
            ]
        },
        {
            "title": "3-3-two-basic-rules-of-probability",
            "paragraphs": [
                {
                    "context": "If A and B are two events defined on a sample space, then: P(A AND B) = P(B)P(A|B).\n\nThis rule may also be written as: P(A|B) = $$\\(\\frac{P(A\\text{~AND~}B)}{P(B)}\\)$$\n\n(The probability of A given B equals the probability of A and B divided by the probability of B.)\n\nIf A and B are independent, then P(A|B) = P(A). Then P(A AND B) = P(A|B)P(B) becomes P(A AND B) = P(A)P(B).",
                    "id": "C_780157_0"
                }
            ],
            "section_title": "The Multiplication Rule",
            "chapter_learning_objectives": [],
            "chapter_summary": "The multiplication rule and the addition rule are used for computing the probability of A and B, as well as the probability of A or B for two given events A, B defined on the sample space. In sampling with replacement each member of a population is replaced after it is picked, so that member has the possibility of being chosen more than once, and the events are considered to be independent. In sampling without replacement, each member of a population may be chosen only once, and the events are considered to be not independent. The events A and B are mutually exclusive events when they do not have any outcomes in common.",
            "chapter_introduction": "When calculating probability, there are two rules to consider when determining if two events are independent or dependent and if they are mutually exclusive or not.",
            "bold_terms": [
                "sample space",
                "independent",
                "mutually exclusive"
            ],
            "chapter_concept": [
                {
                    "name": "Conditional Probability",
                    "description": "the likelihood that an event will occur given that another event has already occurred"
                },
                {
                    "name": "contingency table",
                    "description": "the method of displaying a frequency distribution as a table with rows and columns to show how two variables may be dependent (contingent) upon each other; the table provides an easy way to calculate conditional probabilities."
                },
                {
                    "name": "Dependent Events",
                    "description": "If two events are NOT independent, then we say that they are dependent."
                },
                {
                    "name": "Equally Likely",
                    "description": "Each outcome of an experiment has the same probability."
                },
                {
                    "name": "Event",
                    "description": "a subset of the set of all outcomes of an experiment; the set of all outcomes of an experiment is called a sample space and is usually denoted by S. An event is an arbitrary subset in S. It can contain one outcome, two outcomes, no outcomes (empty subset), the entire sample space, and the like. Standard notations for events are capital letters such as A, B, C, and so on."
                },
                {
                    "name": "Experiment",
                    "description": "a planned activity carried out under controlled conditions"
                },
                {
                    "name": "Independent Events",
                    "description": "The occurrence of one event has no effect on the probability of the occurrence of another event. Events A and B are independent if one of the following is true:P(A|B) = P(A)P(B|A) = P(B)P(A AND B) = P(A)P(B)"
                },
                {
                    "name": "Mutually Exclusive",
                    "description": "Two events are mutually exclusive if the probability that they both happen at the same time is zero. If events A and B are mutually exclusive, then P(A AND B) = 0."
                },
                {
                    "name": "Outcome",
                    "description": "a particular result of an experiment"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur; the foundation of statistics is given by the following 3 axioms (by A.N. Kolmogorov, 1930\u2019s): Let S denote the sample space and A and B are two events in S. Then:0 \u2264 P(A) \u2264 1If A and B are any two mutually exclusive events, then P(A OR B) = P(A) + P(B).P(S) = 1"
                },
                {
                    "name": "Sample Space",
                    "description": "the set of all possible outcomes of an experiment"
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "If each member of a population is replaced after it is picked, then that member has the possibility of being chosen more than once."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "When sampling is done without replacement, each member of a population may be chosen only once."
                },
                {
                    "name": "The AND Event",
                    "description": "An outcome is in the event A AND B if the outcome is in both A AND B at the same time."
                },
                {
                    "name": "The Complement Event",
                    "description": "The complement of event A consists of all outcomes that are NOT in A."
                },
                {
                    "name": "The Or Event",
                    "description": "An outcome is in the event A OR B if the outcome is in A or is in B or is in both A and B."
                },
                {
                    "name": "Tree Diagram",
                    "description": "the useful visual representation of a sample space and events in the form of a \u201ctree\u201d with branches marked by possible outcomes together with associated probabilities (frequencies, relative frequencies)"
                },
                {
                    "name": "Venn Diagram",
                    "description": "the visual representation of a sample space and events in the form of circles or ovals showing their intersections"
                }
            ]
        },
        {
            "title": "3-3-two-basic-rules-of-probability",
            "paragraphs": [
                {
                    "context": "If A and B are defined on a sample space, then: P(A OR B) = P(A) + P(B) - P(A AND B).\n\nIf A and B are mutually exclusive, then P(A AND B) = 0. Then P(A OR B) = P(A) + P(B) - P(A AND B) becomes P(A OR B) = P(A) + P(B).",
                    "id": "C_955547_1"
                }
            ],
            "section_title": "The Addition Rule",
            "chapter_learning_objectives": [],
            "chapter_summary": "The multiplication rule and the addition rule are used for computing the probability of A and B, as well as the probability of A or B for two given events A, B defined on the sample space. In sampling with replacement each member of a population is replaced after it is picked, so that member has the possibility of being chosen more than once, and the events are considered to be independent. In sampling without replacement, each member of a population may be chosen only once, and the events are considered to be not independent. The events A and B are mutually exclusive events when they do not have any outcomes in common.",
            "chapter_introduction": "When calculating probability, there are two rules to consider when determining if two events are independent or dependent and if they are mutually exclusive or not.",
            "bold_terms": [
                "sample space",
                "independent",
                "mutually exclusive"
            ],
            "chapter_concept": [
                {
                    "name": "Conditional Probability",
                    "description": "the likelihood that an event will occur given that another event has already occurred"
                },
                {
                    "name": "contingency table",
                    "description": "the method of displaying a frequency distribution as a table with rows and columns to show how two variables may be dependent (contingent) upon each other; the table provides an easy way to calculate conditional probabilities."
                },
                {
                    "name": "Dependent Events",
                    "description": "If two events are NOT independent, then we say that they are dependent."
                },
                {
                    "name": "Equally Likely",
                    "description": "Each outcome of an experiment has the same probability."
                },
                {
                    "name": "Event",
                    "description": "a subset of the set of all outcomes of an experiment; the set of all outcomes of an experiment is called a sample space and is usually denoted by S. An event is an arbitrary subset in S. It can contain one outcome, two outcomes, no outcomes (empty subset), the entire sample space, and the like. Standard notations for events are capital letters such as A, B, C, and so on."
                },
                {
                    "name": "Experiment",
                    "description": "a planned activity carried out under controlled conditions"
                },
                {
                    "name": "Independent Events",
                    "description": "The occurrence of one event has no effect on the probability of the occurrence of another event. Events A and B are independent if one of the following is true:P(A|B) = P(A)P(B|A) = P(B)P(A AND B) = P(A)P(B)"
                },
                {
                    "name": "Mutually Exclusive",
                    "description": "Two events are mutually exclusive if the probability that they both happen at the same time is zero. If events A and B are mutually exclusive, then P(A AND B) = 0."
                },
                {
                    "name": "Outcome",
                    "description": "a particular result of an experiment"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur; the foundation of statistics is given by the following 3 axioms (by A.N. Kolmogorov, 1930\u2019s): Let S denote the sample space and A and B are two events in S. Then:0 \u2264 P(A) \u2264 1If A and B are any two mutually exclusive events, then P(A OR B) = P(A) + P(B).P(S) = 1"
                },
                {
                    "name": "Sample Space",
                    "description": "the set of all possible outcomes of an experiment"
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "If each member of a population is replaced after it is picked, then that member has the possibility of being chosen more than once."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "When sampling is done without replacement, each member of a population may be chosen only once."
                },
                {
                    "name": "The AND Event",
                    "description": "An outcome is in the event A AND B if the outcome is in both A AND B at the same time."
                },
                {
                    "name": "The Complement Event",
                    "description": "The complement of event A consists of all outcomes that are NOT in A."
                },
                {
                    "name": "The Or Event",
                    "description": "An outcome is in the event A OR B if the outcome is in A or is in B or is in both A and B."
                },
                {
                    "name": "Tree Diagram",
                    "description": "the useful visual representation of a sample space and events in the form of a \u201ctree\u201d with branches marked by possible outcomes together with associated probabilities (frequencies, relative frequencies)"
                },
                {
                    "name": "Venn Diagram",
                    "description": "the visual representation of a sample space and events in the form of circles or ovals showing their intersections"
                }
            ]
        },
        {
            "title": "3-5-tree-and-venn-diagrams",
            "paragraphs": [
                {
                    "context": "A tree diagram is a special type of graph used to determine the outcomes of an experiment. It consists of \"branches\" that are labeled with either frequencies or probabilities. Tree diagrams can make some probability problems easier to visualize and solve. The following example illustrates how to use a tree diagram.",
                    "id": "C_754021_0"
                }
            ],
            "section_title": "Tree Diagrams",
            "chapter_learning_objectives": [],
            "chapter_summary": "A tree diagram use branches to show the different outcomes of experiments and makes complex probability questions easy to visualize.A Venn diagram is a picture that represents the outcomes of an experiment. It generally consists of a box that represents the sample space S together with circles or ovals. The circles or ovals represent events. A Venn diagram is especially helpful for visualizing the OR event, the AND event, and the complement of an event and for understanding conditional probabilities.",
            "chapter_introduction": "Sometimes, when the probability problems are complex, it can be helpful to graph the situation. Tree diagrams and Venn diagrams are two tools that can be used to visualize and solve conditional probabilities.",
            "bold_terms": [
                "tree diagram",
                "Venn diagram"
            ],
            "chapter_concept": [
                {
                    "name": "Conditional Probability",
                    "description": "the likelihood that an event will occur given that another event has already occurred"
                },
                {
                    "name": "contingency table",
                    "description": "the method of displaying a frequency distribution as a table with rows and columns to show how two variables may be dependent (contingent) upon each other; the table provides an easy way to calculate conditional probabilities."
                },
                {
                    "name": "Dependent Events",
                    "description": "If two events are NOT independent, then we say that they are dependent."
                },
                {
                    "name": "Equally Likely",
                    "description": "Each outcome of an experiment has the same probability."
                },
                {
                    "name": "Event",
                    "description": "a subset of the set of all outcomes of an experiment; the set of all outcomes of an experiment is called a sample space and is usually denoted by S. An event is an arbitrary subset in S. It can contain one outcome, two outcomes, no outcomes (empty subset), the entire sample space, and the like. Standard notations for events are capital letters such as A, B, C, and so on."
                },
                {
                    "name": "Experiment",
                    "description": "a planned activity carried out under controlled conditions"
                },
                {
                    "name": "Independent Events",
                    "description": "The occurrence of one event has no effect on the probability of the occurrence of another event. Events A and B are independent if one of the following is true:P(A|B) = P(A)P(B|A) = P(B)P(A AND B) = P(A)P(B)"
                },
                {
                    "name": "Mutually Exclusive",
                    "description": "Two events are mutually exclusive if the probability that they both happen at the same time is zero. If events A and B are mutually exclusive, then P(A AND B) = 0."
                },
                {
                    "name": "Outcome",
                    "description": "a particular result of an experiment"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur; the foundation of statistics is given by the following 3 axioms (by A.N. Kolmogorov, 1930\u2019s): Let S denote the sample space and A and B are two events in S. Then:0 \u2264 P(A) \u2264 1If A and B are any two mutually exclusive events, then P(A OR B) = P(A) + P(B).P(S) = 1"
                },
                {
                    "name": "Sample Space",
                    "description": "the set of all possible outcomes of an experiment"
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "If each member of a population is replaced after it is picked, then that member has the possibility of being chosen more than once."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "When sampling is done without replacement, each member of a population may be chosen only once."
                },
                {
                    "name": "The AND Event",
                    "description": "An outcome is in the event A AND B if the outcome is in both A AND B at the same time."
                },
                {
                    "name": "The Complement Event",
                    "description": "The complement of event A consists of all outcomes that are NOT in A."
                },
                {
                    "name": "The Or Event",
                    "description": "An outcome is in the event A OR B if the outcome is in A or is in B or is in both A and B."
                },
                {
                    "name": "Tree Diagram",
                    "description": "the useful visual representation of a sample space and events in the form of a \u201ctree\u201d with branches marked by possible outcomes together with associated probabilities (frequencies, relative frequencies)"
                },
                {
                    "name": "Venn Diagram",
                    "description": "the visual representation of a sample space and events in the form of circles or ovals showing their intersections"
                }
            ]
        },
        {
            "title": "3-5-tree-and-venn-diagrams",
            "paragraphs": [
                {
                    "context": "A Venn diagram is a picture that represents the outcomes of an experiment. It generally consists of a box that represents the sample space S together with circles or ovals. The circles or ovals represent events.",
                    "id": "C_302745_1"
                }
            ],
            "section_title": "Venn Diagram",
            "chapter_learning_objectives": [],
            "chapter_summary": "A tree diagram use branches to show the different outcomes of experiments and makes complex probability questions easy to visualize.A Venn diagram is a picture that represents the outcomes of an experiment. It generally consists of a box that represents the sample space S together with circles or ovals. The circles or ovals represent events. A Venn diagram is especially helpful for visualizing the OR event, the AND event, and the complement of an event and for understanding conditional probabilities.",
            "chapter_introduction": "Sometimes, when the probability problems are complex, it can be helpful to graph the situation. Tree diagrams and Venn diagrams are two tools that can be used to visualize and solve conditional probabilities.",
            "bold_terms": [
                "tree diagram",
                "Venn diagram"
            ],
            "chapter_concept": [
                {
                    "name": "Conditional Probability",
                    "description": "the likelihood that an event will occur given that another event has already occurred"
                },
                {
                    "name": "contingency table",
                    "description": "the method of displaying a frequency distribution as a table with rows and columns to show how two variables may be dependent (contingent) upon each other; the table provides an easy way to calculate conditional probabilities."
                },
                {
                    "name": "Dependent Events",
                    "description": "If two events are NOT independent, then we say that they are dependent."
                },
                {
                    "name": "Equally Likely",
                    "description": "Each outcome of an experiment has the same probability."
                },
                {
                    "name": "Event",
                    "description": "a subset of the set of all outcomes of an experiment; the set of all outcomes of an experiment is called a sample space and is usually denoted by S. An event is an arbitrary subset in S. It can contain one outcome, two outcomes, no outcomes (empty subset), the entire sample space, and the like. Standard notations for events are capital letters such as A, B, C, and so on."
                },
                {
                    "name": "Experiment",
                    "description": "a planned activity carried out under controlled conditions"
                },
                {
                    "name": "Independent Events",
                    "description": "The occurrence of one event has no effect on the probability of the occurrence of another event. Events A and B are independent if one of the following is true:P(A|B) = P(A)P(B|A) = P(B)P(A AND B) = P(A)P(B)"
                },
                {
                    "name": "Mutually Exclusive",
                    "description": "Two events are mutually exclusive if the probability that they both happen at the same time is zero. If events A and B are mutually exclusive, then P(A AND B) = 0."
                },
                {
                    "name": "Outcome",
                    "description": "a particular result of an experiment"
                },
                {
                    "name": "Probability",
                    "description": "a number between zero and one, inclusive, that gives the likelihood that a specific event will occur; the foundation of statistics is given by the following 3 axioms (by A.N. Kolmogorov, 1930\u2019s): Let S denote the sample space and A and B are two events in S. Then:0 \u2264 P(A) \u2264 1If A and B are any two mutually exclusive events, then P(A OR B) = P(A) + P(B).P(S) = 1"
                },
                {
                    "name": "Sample Space",
                    "description": "the set of all possible outcomes of an experiment"
                },
                {
                    "name": "Sampling with Replacement",
                    "description": "If each member of a population is replaced after it is picked, then that member has the possibility of being chosen more than once."
                },
                {
                    "name": "Sampling without Replacement",
                    "description": "When sampling is done without replacement, each member of a population may be chosen only once."
                },
                {
                    "name": "The AND Event",
                    "description": "An outcome is in the event A AND B if the outcome is in both A AND B at the same time."
                },
                {
                    "name": "The Complement Event",
                    "description": "The complement of event A consists of all outcomes that are NOT in A."
                },
                {
                    "name": "The Or Event",
                    "description": "An outcome is in the event A OR B if the outcome is in A or is in B or is in both A and B."
                },
                {
                    "name": "Tree Diagram",
                    "description": "the useful visual representation of a sample space and events in the form of a \u201ctree\u201d with branches marked by possible outcomes together with associated probabilities (frequencies, relative frequencies)"
                },
                {
                    "name": "Venn Diagram",
                    "description": "the visual representation of a sample space and events in the form of circles or ovals showing their intersections"
                }
            ]
        },
        {
            "title": "4-2-mean-or-expected-value-and-standard-deviation",
            "paragraphs": [
                {
                    "context": "To find the expected value or long term average, \u03bc, simply multiply each value of the random variable by its probability and add the products.\n\nLike data, probability distributions have standard deviations. To calculate the standard deviation (\u03c3) of a probability distribution, find each deviation from its expected value, square it, multiply it by its probability, add the products, and take the square root. To understand how to do the calculation, look at the table for the number of days per week a men's soccer team plays soccer. To find the standard deviation, add the entries in the column labeled (x \u2013 \u03bc)2P(x) and take the square root.\n\nAdd the last column in the table. 0.242 + 0.005 + 0.243 = 0.490. The standard deviation is the square root of 0.49, or \u03c3 = $$\\(\\sqrt{0.49}\\)$$ = 0.7\n\nGenerally for probability distributions, we use a calculator or a computer to calculate \u03bc and \u03c3 to reduce roundoff error. For some probability distributions, there are short-cut formulas for calculating \u03bc and \u03c3.\n\nSome of the more common discrete probability functions are binomial, geometric, hypergeometric, and Poisson. Most elementary courses do not cover the geometric, hypergeometric, and Poisson. Your instructor will let you know if he or she wishes to cover these distributions.\n\nA probability distribution function is a pattern. You try to fit a probability problem into a pattern or distribution in order to perform the necessary calculations. These distributions are tools to make solving probability problems easier. Each distribution has its own special characteristics. Learning the characteristics enables you to distinguish among the different distributions.",
                    "id": "C_476849_0"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "The expected value, or mean, of a discrete random variable predicts the long-term results of a statistical experiment that has been repeated many times. The standard deviation of a probability distribution is used to measure the variability of possible outcomes.",
            "chapter_introduction": "The expected value is often referred to as the \"long-term\" average or mean. This means that over the long term of doing an experiment over and over, you would expect this average.\n\nYou toss a coin and record the result. What is the probability that the result is heads? If you flip a coin two times, does probability tell you that these flips will result in one heads and one tail? You might toss a fair coin ten times and record nine heads. As you learned in Chapter 3 Probability Topics, probability does not describe the short-term results of an experiment. It gives information about what can be expected in the long term. To demonstrate this, Karl Pearson once tossed a fair coin 24,000 times! He recorded the results of each toss, obtaining heads 12,012 times. In his experiment, Pearson illustrated the Law of Large Numbers.\n\nThe Law of Large Numbers states that, as the number of trials in a probability experiment increases, the difference between the theoretical probability of an event and the relative frequency approaches zero (the theoretical probability and the relative frequency get closer and closer together). When evaluating the long-term results of statistical experiments, we often want to know the \u201caverage\u201d outcome. This \u201clong-term average\u201d is known as the mean or expected value of the experiment and is denoted by the Greek letter \u03bc. In other words, after conducting many trials of an experiment, you would expect this average value.",
            "bold_terms": [
                "expected value",
                "long-term\" average or mean",
                "expect",
                "In his experiment, Pearson illustrated the Law of Large Numbers",
                "The Law of Large Numbers",
                "the theoretical probability and the relative frequency get closer and closer together",
                "mean",
                "pattern"
            ],
            "chapter_concept": [
                {
                    "name": "Bernoulli Trials",
                    "description": "an experiment with the following characteristics:There are only two possible outcomes called \u201csuccess\u201d and \u201cfailure\u201d for each trial.The probability p of a success is the same for any trial (so the probability q = 1 \u2212 p of a failure is the same for any trial)."
                },
                {
                    "name": "Binomial Experiment",
                    "description": "a statistical experiment that satisfies the following three conditions:There are a fixed number of trials, n.There are only two possible outcomes, called \"success\" and, \"failure,\" for each trial. The letter p denotes the probability of a success on one trial, and q denotes the probability of a failure on one trial.The n trials are independent and are repeated using identical conditions."
                },
                {
                    "name": "Binomial Probability Distribution",
                    "description": "a discrete random variable (RV) that arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial one) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X ~ B(n, p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is P(X = x) = $$\\(\\left( \\begin{array}{l}\nn \\\\\nx \\\\\n\\end{array} \\right)\\)$$pxqn \u2212 x."
                },
                {
                    "name": "Expected Value",
                    "description": "expected arithmetic average when an experiment is repeated many times; also called the mean. Notations: \u03bc. For a discrete random variable (RV) with probability distribution function P(x),the definition can also be written in the form \u03bc = $$\\(\\sum{}\\)$$xP(x)."
                },
                {
                    "name": "Geometric Distribution",
                    "description": "a discrete random variable (RV) that arises from the Bernoulli trials; the trials are repeated until the first success. The geometric variable X is defined as the number of trials until the first success. Notation: X ~ G(p). The mean is \u03bc = $$\\(\\frac{1}{p}\\)$$ and the standard deviation is \u03c3 = $$\\(\\sqrt{\\frac{1}{p}\\left( {\\frac{1}{p} - 1} \\right)}\\)$$. The probability of exactly x failures before the first success is given by the formula: P(X = x) = p(1 \u2013 p)x \u2013 1."
                },
                {
                    "name": "Geometric Experiment",
                    "description": "a statistical experiment with the following properties:There are one or more Bernoulli trials with all failures except the last one, which is a success.In theory, the number of trials could go on forever. There must be at least one trial.The probability, p, of a success and the probability, q, of a failure do not change from trial to trial."
                },
                {
                    "name": "Hypergeometric Experiment",
                    "description": "a statistical experiment with the following properties:You take samples from two groups.You are concerned with a group of interest, called the first group.You sample without replacement from the combined groups.Each pick is not independent, since sampling is without replacement.You are not dealing with Bernoulli Trials."
                },
                {
                    "name": "Hypergeometric Probability",
                    "description": "a discrete random variable (RV) that is characterized by:A fixed number of trials.The probability of success is not the same from trial to trial.We sample from two groups of items when we are interested in only one group. X is defined as the number of successes out of the total number of items chosen. Notation: X ~ H(r, b, n), where r = the number of items in the group of interest, b = the number of items in the group not of interest, and n = the number of items chosen."
                },
                {
                    "name": "Mean",
                    "description": "a number that measures the central tendency; a common name for mean is \u2018average.\u2019 The term \u2018mean\u2019 is a shortened form of \u2018arithmetic mean.\u2019 By definition, the mean for a sample (detonated by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x} = \\frac{{Sum}~{of}~{all}~{values}~{in}~{the}~{sample}}{{Number}~{of}~{values}~{in}~{the}~{sample}}\\)$$ and the mean for a population (denoted by \u03bc) is \u03bc = $$\\(\\frac{{Sum}~{of}~{all}~{values}~{in}~{the}~{population}}{{Number}~{of}~{values}~{in}~{the}~{population}}\\)$$."
                },
                {
                    "name": "Poisson Probability Distribution",
                    "description": "a discrete random variable (RV) that counts the number of times a certain event will occur in a specific interval; characteristics of the variable:The probability that the event occurs in a given interval is the same for all intervals.The events occur with a known mean and independently of the time since the last event.The distribution is defined by the mean \u03bc of the event in the interval. Notation: X ~ P(\u03bc). The mean is \u03bc = np. The standard deviation is $$\\(\\sigma\\text{~=~}\\sqrt{\\mu}\\)$$. The probability of having exactly x  successes in r  trials is P(X = x ) = $$\\((e^{- \\mu})\\frac{\\mu^{x}}{x!}\\)$$. The Poisson distribution is often used to approximate the binomial distribution, when n is \u201clarge\u201d and p is \u201csmall\u201d (a general rule is that n should be greater than or equal to 20 and p should be less than or equal to 0.05)."
                },
                {
                    "name": "Probability Distribution Function (PDF)",
                    "description": "a mathematical description of a discrete random variable (RV), given either in the form of an equation (formula) or in the form of a table listing all the possible outcomes of an experiment and the probability associated with each outcome."
                },
                {
                    "name": "Random Variable (RV)",
                    "description": "a characteristic of interest in a population being studied; common notation for variables are upper case Latin letters X, Y, Z,...; common notation for a specific value from the domain (set of all possible values of a variable) are lower case Latin letters x, y, and z. For example, if X is the number of children in a family, then x represents a specific integer 0, 1, 2, 3,.... Variables in statistics differ from variables in intermediate algebra in the two following ways. The domain of the random variable (RV) is not necessarily a numerical set; the domain may be expressed in words; for example, if X = hair color then the domain is {black, blond, gray, green, orange}.We can tell what specific value x the random variable X takes only after performing the experiment."
                }
            ]
        },
        {
            "title": "4-3-binomial-distribution",
            "paragraphs": [
                {
                    "context": "X ~ B(n, p)\n\nRead this as \"X is a random variable with a binomial distribution.\" The parameters are n and p; n = number of trials, p = probability of a success on each trial.",
                    "id": "C_956952_0"
                }
            ],
            "section_title": "Notation for the Binomial: B = Binomial Probability Distribution Function",
            "chapter_learning_objectives": [],
            "chapter_summary": "A statistical experiment can be classified as a binomial experiment if the following conditions are met:There are a fixed number of trials, n. There are only two possible outcomes, called \"success\" and, \"failure\" for each trial. The letter p denotes the probability of a success on one trial and q denotes the probability of a failure on one trial. The n trials are independent and are repeated using identical conditions. The outcomes of a binomial experiment fit a binomial probability distribution. The random variable X = the number of successes obtained in the n independent trials. The mean of X can be calculated using the formula \u03bc = np, and the standard deviation is given by the formula \u03c3 = $$\\(\\ \\sqrt{npq}\\)$$.",
            "chapter_introduction": "There are three characteristics of a binomial experiment.\n\nThere are a fixed number of trials. Think of trials as repetitions of an experiment. The letter n denotes the number of trials. There are only two possible outcomes, called \"success\" and \"failure,\" for each trial. The letter p denotes the probability of a success on one trial, and q denotes the probability of a failure on one trial. p + q = 1. The n trials are independent and are repeated using identical conditions. Because the n trials are independent, the outcome of one trial does not help in predicting the outcome of another trial. Another way of saying this is that for each individual trial, the probability, p, of a success and probability, q, of a failure remain the same. For example, randomly guessing at a true-false statistics question has only two outcomes. If a success is guessing correctly, then a failure is guessing incorrectly. Suppose Joe always guesses correctly on any statistics true-false question with probability p = 0.6. Then, q = 0.4. This means that for every true-false statistics question Joe answers, his probability of success (p = 0.6) and his probability of failure (q = 0.4) remain the same. \n\nThe outcomes of a binomial experiment fit a binomial probability distribution. The random variable X = the number of successes obtained in the n independent trials.\n\nThe mean, \u03bc, and variance, \u03c32, for the binomial probability distribution are \u03bc = np and \u03c32 = npq. The standard deviation, \u03c3, is then \u03c3 = $$\\(\\sqrt{npq}\\)$$.\n\nAny experiment that has characteristics two and three and where n = 1 is called a Bernoulli Trial (named after Jacob Bernoulli who, in the late 1600s, studied them extensively). A binomial experiment takes place when the number of successes is counted in one or more Bernoulli Trials.",
            "bold_terms": [
                "binomial probability distribution",
                "Bernoulli Trial"
            ],
            "chapter_concept": [
                {
                    "name": "Bernoulli Trials",
                    "description": "an experiment with the following characteristics:There are only two possible outcomes called \u201csuccess\u201d and \u201cfailure\u201d for each trial.The probability p of a success is the same for any trial (so the probability q = 1 \u2212 p of a failure is the same for any trial)."
                },
                {
                    "name": "Binomial Experiment",
                    "description": "a statistical experiment that satisfies the following three conditions:There are a fixed number of trials, n.There are only two possible outcomes, called \"success\" and, \"failure,\" for each trial. The letter p denotes the probability of a success on one trial, and q denotes the probability of a failure on one trial.The n trials are independent and are repeated using identical conditions."
                },
                {
                    "name": "Binomial Probability Distribution",
                    "description": "a discrete random variable (RV) that arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial one) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X ~ B(n, p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is P(X = x) = $$\\(\\left( \\begin{array}{l}\nn \\\\\nx \\\\\n\\end{array} \\right)\\)$$pxqn \u2212 x."
                },
                {
                    "name": "Expected Value",
                    "description": "expected arithmetic average when an experiment is repeated many times; also called the mean. Notations: \u03bc. For a discrete random variable (RV) with probability distribution function P(x),the definition can also be written in the form \u03bc = $$\\(\\sum{}\\)$$xP(x)."
                },
                {
                    "name": "Geometric Distribution",
                    "description": "a discrete random variable (RV) that arises from the Bernoulli trials; the trials are repeated until the first success. The geometric variable X is defined as the number of trials until the first success. Notation: X ~ G(p). The mean is \u03bc = $$\\(\\frac{1}{p}\\)$$ and the standard deviation is \u03c3 = $$\\(\\sqrt{\\frac{1}{p}\\left( {\\frac{1}{p} - 1} \\right)}\\)$$. The probability of exactly x failures before the first success is given by the formula: P(X = x) = p(1 \u2013 p)x \u2013 1."
                },
                {
                    "name": "Geometric Experiment",
                    "description": "a statistical experiment with the following properties:There are one or more Bernoulli trials with all failures except the last one, which is a success.In theory, the number of trials could go on forever. There must be at least one trial.The probability, p, of a success and the probability, q, of a failure do not change from trial to trial."
                },
                {
                    "name": "Hypergeometric Experiment",
                    "description": "a statistical experiment with the following properties:You take samples from two groups.You are concerned with a group of interest, called the first group.You sample without replacement from the combined groups.Each pick is not independent, since sampling is without replacement.You are not dealing with Bernoulli Trials."
                },
                {
                    "name": "Hypergeometric Probability",
                    "description": "a discrete random variable (RV) that is characterized by:A fixed number of trials.The probability of success is not the same from trial to trial.We sample from two groups of items when we are interested in only one group. X is defined as the number of successes out of the total number of items chosen. Notation: X ~ H(r, b, n), where r = the number of items in the group of interest, b = the number of items in the group not of interest, and n = the number of items chosen."
                },
                {
                    "name": "Mean",
                    "description": "a number that measures the central tendency; a common name for mean is \u2018average.\u2019 The term \u2018mean\u2019 is a shortened form of \u2018arithmetic mean.\u2019 By definition, the mean for a sample (detonated by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x} = \\frac{{Sum}~{of}~{all}~{values}~{in}~{the}~{sample}}{{Number}~{of}~{values}~{in}~{the}~{sample}}\\)$$ and the mean for a population (denoted by \u03bc) is \u03bc = $$\\(\\frac{{Sum}~{of}~{all}~{values}~{in}~{the}~{population}}{{Number}~{of}~{values}~{in}~{the}~{population}}\\)$$."
                },
                {
                    "name": "Poisson Probability Distribution",
                    "description": "a discrete random variable (RV) that counts the number of times a certain event will occur in a specific interval; characteristics of the variable:The probability that the event occurs in a given interval is the same for all intervals.The events occur with a known mean and independently of the time since the last event.The distribution is defined by the mean \u03bc of the event in the interval. Notation: X ~ P(\u03bc). The mean is \u03bc = np. The standard deviation is $$\\(\\sigma\\text{~=~}\\sqrt{\\mu}\\)$$. The probability of having exactly x  successes in r  trials is P(X = x ) = $$\\((e^{- \\mu})\\frac{\\mu^{x}}{x!}\\)$$. The Poisson distribution is often used to approximate the binomial distribution, when n is \u201clarge\u201d and p is \u201csmall\u201d (a general rule is that n should be greater than or equal to 20 and p should be less than or equal to 0.05)."
                },
                {
                    "name": "Probability Distribution Function (PDF)",
                    "description": "a mathematical description of a discrete random variable (RV), given either in the form of an equation (formula) or in the form of a table listing all the possible outcomes of an experiment and the probability associated with each outcome."
                },
                {
                    "name": "Random Variable (RV)",
                    "description": "a characteristic of interest in a population being studied; common notation for variables are upper case Latin letters X, Y, Z,...; common notation for a specific value from the domain (set of all possible values of a variable) are lower case Latin letters x, y, and z. For example, if X is the number of children in a family, then x represents a specific integer 0, 1, 2, 3,.... Variables in statistics differ from variables in intermediate algebra in the two following ways. The domain of the random variable (RV) is not necessarily a numerical set; the domain may be expressed in words; for example, if X = hair color then the domain is {black, blond, gray, green, orange}.We can tell what specific value x the random variable X takes only after performing the experiment."
                }
            ]
        },
        {
            "title": "4-4-geometric-distribution",
            "paragraphs": [
                {
                    "context": "X ~ G(p)\n\nRead this as \"X is a random variable with a geometric distribution.\" The parameter is p; p = the probability of a success for each trial.",
                    "id": "C_284282_0"
                }
            ],
            "section_title": "Notation for the Geometric: G = Geometric Probability Distribution Function",
            "chapter_learning_objectives": [],
            "chapter_summary": "There are three characteristics of a geometric experiment:There are one or more Bernoulli trials with all failures except the last one, which is a success. In theory, the number of trials could go on forever. There must be at least one trial. The probability, p, of a success and the probability, q, of a failure are the same for each trial. In a geometric experiment, define the discrete random variable X as the number of independent trials until the first success. We say that X has a geometric distribution and write X ~ G(p) where p is the probability of success in a single trial.The mean of the geometric distribution X ~ G(p) is \u03bc = $$\\(\\frac{1}{p}\\)$$ and the standard deviation is $$\\(\\sigma\\sqrt{\\frac{\\left( \\text{1} - p \\right)}{p^{2}}}\\)$$ = $$\\(\\sqrt{\\frac{1}{p}\\left( {\\frac{1}{p} - 1} \\right)}\\)$$.",
            "chapter_introduction": "There are three main characteristics of a geometric experiment.\n\nThere are one or more Bernoulli trials with all failures except the last one, which is a success. In other words, you keep repeating what you are doing until the first success. Then you stop. For example, you throw a dart at a bullseye until you hit the bullseye. The first time you hit the bullseye is a \"success\" so you stop throwing the dart. It might take six tries until you hit the bullseye. You can think of the trials as failure, failure, failure, failure, failure, success, STOP. In theory, the number of trials could go on forever. There must be at least one trial. The probability, p, of a success and the probability, q, of a failure is the same for each trial. p + q = 1 and q = 1 \u2212 p. For example, the probability of rolling a three when you throw one fair die is $$\\(\\frac{1}{6}\\)$$. This is true no matter how many times you roll the die. Suppose you want to know the probability of getting the first three on the fifth roll. On rolls one through four, you do not get a face with a three. The probability for each of the rolls is q\u00a0= $$\\(\\frac{\\text{5}}{\\text{6}}\\)$$, the probability of a failure. The probability of getting a three on the fifth roll is $$\\(\\left( \\frac{5}{6} \\right)\\left( \\frac{5}{6} \\right)\\left( \\frac{5}{6} \\right)\\left( \\frac{5}{6} \\right)\\left( \\frac{1}{6} \\right)\\)$$ = 0.0804 \n\nX = the number of independent trials until the first success.",
            "bold_terms": [
                "geometric distribution"
            ],
            "chapter_concept": [
                {
                    "name": "Bernoulli Trials",
                    "description": "an experiment with the following characteristics:There are only two possible outcomes called \u201csuccess\u201d and \u201cfailure\u201d for each trial.The probability p of a success is the same for any trial (so the probability q = 1 \u2212 p of a failure is the same for any trial)."
                },
                {
                    "name": "Binomial Experiment",
                    "description": "a statistical experiment that satisfies the following three conditions:There are a fixed number of trials, n.There are only two possible outcomes, called \"success\" and, \"failure,\" for each trial. The letter p denotes the probability of a success on one trial, and q denotes the probability of a failure on one trial.The n trials are independent and are repeated using identical conditions."
                },
                {
                    "name": "Binomial Probability Distribution",
                    "description": "a discrete random variable (RV) that arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial one) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X ~ B(n, p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is P(X = x) = $$\\(\\left( \\begin{array}{l}\nn \\\\\nx \\\\\n\\end{array} \\right)\\)$$pxqn \u2212 x."
                },
                {
                    "name": "Expected Value",
                    "description": "expected arithmetic average when an experiment is repeated many times; also called the mean. Notations: \u03bc. For a discrete random variable (RV) with probability distribution function P(x),the definition can also be written in the form \u03bc = $$\\(\\sum{}\\)$$xP(x)."
                },
                {
                    "name": "Geometric Distribution",
                    "description": "a discrete random variable (RV) that arises from the Bernoulli trials; the trials are repeated until the first success. The geometric variable X is defined as the number of trials until the first success. Notation: X ~ G(p). The mean is \u03bc = $$\\(\\frac{1}{p}\\)$$ and the standard deviation is \u03c3 = $$\\(\\sqrt{\\frac{1}{p}\\left( {\\frac{1}{p} - 1} \\right)}\\)$$. The probability of exactly x failures before the first success is given by the formula: P(X = x) = p(1 \u2013 p)x \u2013 1."
                },
                {
                    "name": "Geometric Experiment",
                    "description": "a statistical experiment with the following properties:There are one or more Bernoulli trials with all failures except the last one, which is a success.In theory, the number of trials could go on forever. There must be at least one trial.The probability, p, of a success and the probability, q, of a failure do not change from trial to trial."
                },
                {
                    "name": "Hypergeometric Experiment",
                    "description": "a statistical experiment with the following properties:You take samples from two groups.You are concerned with a group of interest, called the first group.You sample without replacement from the combined groups.Each pick is not independent, since sampling is without replacement.You are not dealing with Bernoulli Trials."
                },
                {
                    "name": "Hypergeometric Probability",
                    "description": "a discrete random variable (RV) that is characterized by:A fixed number of trials.The probability of success is not the same from trial to trial.We sample from two groups of items when we are interested in only one group. X is defined as the number of successes out of the total number of items chosen. Notation: X ~ H(r, b, n), where r = the number of items in the group of interest, b = the number of items in the group not of interest, and n = the number of items chosen."
                },
                {
                    "name": "Mean",
                    "description": "a number that measures the central tendency; a common name for mean is \u2018average.\u2019 The term \u2018mean\u2019 is a shortened form of \u2018arithmetic mean.\u2019 By definition, the mean for a sample (detonated by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x} = \\frac{{Sum}~{of}~{all}~{values}~{in}~{the}~{sample}}{{Number}~{of}~{values}~{in}~{the}~{sample}}\\)$$ and the mean for a population (denoted by \u03bc) is \u03bc = $$\\(\\frac{{Sum}~{of}~{all}~{values}~{in}~{the}~{population}}{{Number}~{of}~{values}~{in}~{the}~{population}}\\)$$."
                },
                {
                    "name": "Poisson Probability Distribution",
                    "description": "a discrete random variable (RV) that counts the number of times a certain event will occur in a specific interval; characteristics of the variable:The probability that the event occurs in a given interval is the same for all intervals.The events occur with a known mean and independently of the time since the last event.The distribution is defined by the mean \u03bc of the event in the interval. Notation: X ~ P(\u03bc). The mean is \u03bc = np. The standard deviation is $$\\(\\sigma\\text{~=~}\\sqrt{\\mu}\\)$$. The probability of having exactly x  successes in r  trials is P(X = x ) = $$\\((e^{- \\mu})\\frac{\\mu^{x}}{x!}\\)$$. The Poisson distribution is often used to approximate the binomial distribution, when n is \u201clarge\u201d and p is \u201csmall\u201d (a general rule is that n should be greater than or equal to 20 and p should be less than or equal to 0.05)."
                },
                {
                    "name": "Probability Distribution Function (PDF)",
                    "description": "a mathematical description of a discrete random variable (RV), given either in the form of an equation (formula) or in the form of a table listing all the possible outcomes of an experiment and the probability associated with each outcome."
                },
                {
                    "name": "Random Variable (RV)",
                    "description": "a characteristic of interest in a population being studied; common notation for variables are upper case Latin letters X, Y, Z,...; common notation for a specific value from the domain (set of all possible values of a variable) are lower case Latin letters x, y, and z. For example, if X is the number of children in a family, then x represents a specific integer 0, 1, 2, 3,.... Variables in statistics differ from variables in intermediate algebra in the two following ways. The domain of the random variable (RV) is not necessarily a numerical set; the domain may be expressed in words; for example, if X = hair color then the domain is {black, blond, gray, green, orange}.We can tell what specific value x the random variable X takes only after performing the experiment."
                }
            ]
        },
        {
            "title": "4-5-hypergeometric-distribution",
            "paragraphs": [
                {
                    "context": "X ~ H(r, b, n)\n\nRead this as \"X is a random variable with a hypergeometric distribution.\" The parameters are r, b, and n; r = the size of the group of interest (first group), b = the size of the second group, n = the size of the chosen sample.",
                    "id": "C_131892_0"
                }
            ],
            "section_title": "Notation for the Hypergeometric: H = Hypergeometric Probability Distribution Function",
            "chapter_learning_objectives": [],
            "chapter_summary": "A hypergeometric experiment is a statistical experiment with the following properties:You take samples from two groups. You are concerned with a group of interest, called the first group. You sample without replacement from the combined groups. Each pick is not independent, since sampling is without replacement. You are not dealing with Bernoulli Trials. The outcomes of a hypergeometric experiment fit a hypergeometric probability distribution. The random variable X = the number of items from the group of interest. The distribution of X is denoted X ~ H(r, b, n), where r = the size of the group of interest (first group), b = the size of the second group, and n = the size of the chosen sample. It follows that n \u2264 r + b. The mean of X is \u03bc = $$\\(\\frac{nr}{r\\text{~+~}b}\\)$$ and the standard deviation is \u03c3 = $$\\(\\sqrt{\\frac{rbn(r\\text{~+~}b\\text{~\u2212~}n)}{{(r\\text{~+~}b)}^{2}\\,(r\\text{~+~}b - \\text{1)}}}\\)$$.",
            "chapter_introduction": "There are five characteristics of a hypergeometric experiment.\n\nYou take samples from two groups. You are concerned with a group of interest, called the first group. You sample without replacement from the combined groups. For example, you want to choose a softball team from a combined group of 11 men and 13 women. The team consists of ten players. Each pick is not independent, since sampling is without replacement. In the softball example, the probability of picking a woman first is $$\\(\\frac{13}{24}\\)$$. The probability of picking a man second is $$\\(\\frac{11}{23}\\)$$ if a woman was picked first. It is $$\\(\\frac{10}{23}\\)$$ if a man was picked first. The probability of the second pick depends on what happened in the first pick. You are not dealing with Bernoulli Trials. \n\nThe outcomes of a hypergeometric experiment fit a hypergeometric probability distribution. The random variable X = the number of items from the group of interest.",
            "bold_terms": [
                "two",
                "without replacement",
                "not",
                "hypergeometric probability"
            ],
            "chapter_concept": [
                {
                    "name": "Bernoulli Trials",
                    "description": "an experiment with the following characteristics:There are only two possible outcomes called \u201csuccess\u201d and \u201cfailure\u201d for each trial.The probability p of a success is the same for any trial (so the probability q = 1 \u2212 p of a failure is the same for any trial)."
                },
                {
                    "name": "Binomial Experiment",
                    "description": "a statistical experiment that satisfies the following three conditions:There are a fixed number of trials, n.There are only two possible outcomes, called \"success\" and, \"failure,\" for each trial. The letter p denotes the probability of a success on one trial, and q denotes the probability of a failure on one trial.The n trials are independent and are repeated using identical conditions."
                },
                {
                    "name": "Binomial Probability Distribution",
                    "description": "a discrete random variable (RV) that arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial one) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X ~ B(n, p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is P(X = x) = $$\\(\\left( \\begin{array}{l}\nn \\\\\nx \\\\\n\\end{array} \\right)\\)$$pxqn \u2212 x."
                },
                {
                    "name": "Expected Value",
                    "description": "expected arithmetic average when an experiment is repeated many times; also called the mean. Notations: \u03bc. For a discrete random variable (RV) with probability distribution function P(x),the definition can also be written in the form \u03bc = $$\\(\\sum{}\\)$$xP(x)."
                },
                {
                    "name": "Geometric Distribution",
                    "description": "a discrete random variable (RV) that arises from the Bernoulli trials; the trials are repeated until the first success. The geometric variable X is defined as the number of trials until the first success. Notation: X ~ G(p). The mean is \u03bc = $$\\(\\frac{1}{p}\\)$$ and the standard deviation is \u03c3 = $$\\(\\sqrt{\\frac{1}{p}\\left( {\\frac{1}{p} - 1} \\right)}\\)$$. The probability of exactly x failures before the first success is given by the formula: P(X = x) = p(1 \u2013 p)x \u2013 1."
                },
                {
                    "name": "Geometric Experiment",
                    "description": "a statistical experiment with the following properties:There are one or more Bernoulli trials with all failures except the last one, which is a success.In theory, the number of trials could go on forever. There must be at least one trial.The probability, p, of a success and the probability, q, of a failure do not change from trial to trial."
                },
                {
                    "name": "Hypergeometric Experiment",
                    "description": "a statistical experiment with the following properties:You take samples from two groups.You are concerned with a group of interest, called the first group.You sample without replacement from the combined groups.Each pick is not independent, since sampling is without replacement.You are not dealing with Bernoulli Trials."
                },
                {
                    "name": "Hypergeometric Probability",
                    "description": "a discrete random variable (RV) that is characterized by:A fixed number of trials.The probability of success is not the same from trial to trial.We sample from two groups of items when we are interested in only one group. X is defined as the number of successes out of the total number of items chosen. Notation: X ~ H(r, b, n), where r = the number of items in the group of interest, b = the number of items in the group not of interest, and n = the number of items chosen."
                },
                {
                    "name": "Mean",
                    "description": "a number that measures the central tendency; a common name for mean is \u2018average.\u2019 The term \u2018mean\u2019 is a shortened form of \u2018arithmetic mean.\u2019 By definition, the mean for a sample (detonated by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x} = \\frac{{Sum}~{of}~{all}~{values}~{in}~{the}~{sample}}{{Number}~{of}~{values}~{in}~{the}~{sample}}\\)$$ and the mean for a population (denoted by \u03bc) is \u03bc = $$\\(\\frac{{Sum}~{of}~{all}~{values}~{in}~{the}~{population}}{{Number}~{of}~{values}~{in}~{the}~{population}}\\)$$."
                },
                {
                    "name": "Poisson Probability Distribution",
                    "description": "a discrete random variable (RV) that counts the number of times a certain event will occur in a specific interval; characteristics of the variable:The probability that the event occurs in a given interval is the same for all intervals.The events occur with a known mean and independently of the time since the last event.The distribution is defined by the mean \u03bc of the event in the interval. Notation: X ~ P(\u03bc). The mean is \u03bc = np. The standard deviation is $$\\(\\sigma\\text{~=~}\\sqrt{\\mu}\\)$$. The probability of having exactly x  successes in r  trials is P(X = x ) = $$\\((e^{- \\mu})\\frac{\\mu^{x}}{x!}\\)$$. The Poisson distribution is often used to approximate the binomial distribution, when n is \u201clarge\u201d and p is \u201csmall\u201d (a general rule is that n should be greater than or equal to 20 and p should be less than or equal to 0.05)."
                },
                {
                    "name": "Probability Distribution Function (PDF)",
                    "description": "a mathematical description of a discrete random variable (RV), given either in the form of an equation (formula) or in the form of a table listing all the possible outcomes of an experiment and the probability associated with each outcome."
                },
                {
                    "name": "Random Variable (RV)",
                    "description": "a characteristic of interest in a population being studied; common notation for variables are upper case Latin letters X, Y, Z,...; common notation for a specific value from the domain (set of all possible values of a variable) are lower case Latin letters x, y, and z. For example, if X is the number of children in a family, then x represents a specific integer 0, 1, 2, 3,.... Variables in statistics differ from variables in intermediate algebra in the two following ways. The domain of the random variable (RV) is not necessarily a numerical set; the domain may be expressed in words; for example, if X = hair color then the domain is {black, blond, gray, green, orange}.We can tell what specific value x the random variable X takes only after performing the experiment."
                }
            ]
        },
        {
            "title": "4-6-poisson-distribution",
            "paragraphs": [
                {
                    "context": "X ~ P(\u03bc)\n\nRead this as \"X is a random variable with a Poisson distribution.\" The parameter is \u03bc (or \u03bb); \u03bc (or \u03bb) = the mean for the interval of interest. The standard deviation of the Poisson distribution with mean \u00b5 is \u03a3=\u221a\u03bc ",
                    "id": "C_606020_0"
                }
            ],
            "section_title": "Notation for the Poisson: P = Poisson Probability Distribution Function",
            "chapter_learning_objectives": [],
            "chapter_summary": "A Poisson probability distribution of a discrete random variable gives the probability of a number of events occurring in a fixed interval of time or space, if these events happen at a known average rate and independently of the time since the last event. The Poisson distribution may be used to approximate the binomial, if the probability of success is \"small\" (less than or equal to 0.05) and the number of trials is \"large\" (greater than or equal to 20).",
            "chapter_introduction": "There are two main characteristics of a Poisson experiment.\n\nThe Poisson probability distribution gives the probability of a number of events occurring in a fixed interval of time or space if these events happen with a known average rate and independently of the time since the last event. For example, a book editor might be interested in the number of words spelled incorrectly in a particular book. It might be that, on the average, there are five words spelled incorrectly in 100 pages. The interval is the 100 pages. The Poisson distribution may be used to approximate the binomial if the probability of success is \"small\" (such as 0.01) and the number of trials is \"large\" (such as 1,000). You will verify the relationship in the homework exercises. n is the number of trials, and p is the probability of a \"success.\" \n\nThe random variable X = the number of occurrences in the interval of interest.",
            "bold_terms": [
                "Poisson probability distribution",
                "fixed interval"
            ],
            "chapter_concept": [
                {
                    "name": "Bernoulli Trials",
                    "description": "an experiment with the following characteristics:There are only two possible outcomes called \u201csuccess\u201d and \u201cfailure\u201d for each trial.The probability p of a success is the same for any trial (so the probability q = 1 \u2212 p of a failure is the same for any trial)."
                },
                {
                    "name": "Binomial Experiment",
                    "description": "a statistical experiment that satisfies the following three conditions:There are a fixed number of trials, n.There are only two possible outcomes, called \"success\" and, \"failure,\" for each trial. The letter p denotes the probability of a success on one trial, and q denotes the probability of a failure on one trial.The n trials are independent and are repeated using identical conditions."
                },
                {
                    "name": "Binomial Probability Distribution",
                    "description": "a discrete random variable (RV) that arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial one) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X ~ B(n, p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is P(X = x) = $$\\(\\left( \\begin{array}{l}\nn \\\\\nx \\\\\n\\end{array} \\right)\\)$$pxqn \u2212 x."
                },
                {
                    "name": "Expected Value",
                    "description": "expected arithmetic average when an experiment is repeated many times; also called the mean. Notations: \u03bc. For a discrete random variable (RV) with probability distribution function P(x),the definition can also be written in the form \u03bc = $$\\(\\sum{}\\)$$xP(x)."
                },
                {
                    "name": "Geometric Distribution",
                    "description": "a discrete random variable (RV) that arises from the Bernoulli trials; the trials are repeated until the first success. The geometric variable X is defined as the number of trials until the first success. Notation: X ~ G(p). The mean is \u03bc = $$\\(\\frac{1}{p}\\)$$ and the standard deviation is \u03c3 = $$\\(\\sqrt{\\frac{1}{p}\\left( {\\frac{1}{p} - 1} \\right)}\\)$$. The probability of exactly x failures before the first success is given by the formula: P(X = x) = p(1 \u2013 p)x \u2013 1."
                },
                {
                    "name": "Geometric Experiment",
                    "description": "a statistical experiment with the following properties:There are one or more Bernoulli trials with all failures except the last one, which is a success.In theory, the number of trials could go on forever. There must be at least one trial.The probability, p, of a success and the probability, q, of a failure do not change from trial to trial."
                },
                {
                    "name": "Hypergeometric Experiment",
                    "description": "a statistical experiment with the following properties:You take samples from two groups.You are concerned with a group of interest, called the first group.You sample without replacement from the combined groups.Each pick is not independent, since sampling is without replacement.You are not dealing with Bernoulli Trials."
                },
                {
                    "name": "Hypergeometric Probability",
                    "description": "a discrete random variable (RV) that is characterized by:A fixed number of trials.The probability of success is not the same from trial to trial.We sample from two groups of items when we are interested in only one group. X is defined as the number of successes out of the total number of items chosen. Notation: X ~ H(r, b, n), where r = the number of items in the group of interest, b = the number of items in the group not of interest, and n = the number of items chosen."
                },
                {
                    "name": "Mean",
                    "description": "a number that measures the central tendency; a common name for mean is \u2018average.\u2019 The term \u2018mean\u2019 is a shortened form of \u2018arithmetic mean.\u2019 By definition, the mean for a sample (detonated by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x} = \\frac{{Sum}~{of}~{all}~{values}~{in}~{the}~{sample}}{{Number}~{of}~{values}~{in}~{the}~{sample}}\\)$$ and the mean for a population (denoted by \u03bc) is \u03bc = $$\\(\\frac{{Sum}~{of}~{all}~{values}~{in}~{the}~{population}}{{Number}~{of}~{values}~{in}~{the}~{population}}\\)$$."
                },
                {
                    "name": "Poisson Probability Distribution",
                    "description": "a discrete random variable (RV) that counts the number of times a certain event will occur in a specific interval; characteristics of the variable:The probability that the event occurs in a given interval is the same for all intervals.The events occur with a known mean and independently of the time since the last event.The distribution is defined by the mean \u03bc of the event in the interval. Notation: X ~ P(\u03bc). The mean is \u03bc = np. The standard deviation is $$\\(\\sigma\\text{~=~}\\sqrt{\\mu}\\)$$. The probability of having exactly x  successes in r  trials is P(X = x ) = $$\\((e^{- \\mu})\\frac{\\mu^{x}}{x!}\\)$$. The Poisson distribution is often used to approximate the binomial distribution, when n is \u201clarge\u201d and p is \u201csmall\u201d (a general rule is that n should be greater than or equal to 20 and p should be less than or equal to 0.05)."
                },
                {
                    "name": "Probability Distribution Function (PDF)",
                    "description": "a mathematical description of a discrete random variable (RV), given either in the form of an equation (formula) or in the form of a table listing all the possible outcomes of an experiment and the probability associated with each outcome."
                },
                {
                    "name": "Random Variable (RV)",
                    "description": "a characteristic of interest in a population being studied; common notation for variables are upper case Latin letters X, Y, Z,...; common notation for a specific value from the domain (set of all possible values of a variable) are lower case Latin letters x, y, and z. For example, if X is the number of children in a family, then x represents a specific integer 0, 1, 2, 3,.... Variables in statistics differ from variables in intermediate algebra in the two following ways. The domain of the random variable (RV) is not necessarily a numerical set; the domain may be expressed in words; for example, if X = hair color then the domain is {black, blond, gray, green, orange}.We can tell what specific value x the random variable X takes only after performing the experiment."
                }
            ]
        },
        {
            "title": "5-3-the-exponential-distribution",
            "paragraphs": [
                {
                    "context": "Have each class member count the change he or she has in his or her pocket or purse. Your instructor will record the amounts in dollars and cents. Construct a histogram of the data taken by the class. Use five intervals. Draw a smooth curve through the bars. The graph should look approximately exponential. Then calculate the mean.\n\nLet X = the amount of money a student in your class has in his or her pocket or purse.\n\nThe distribution for X is approximately exponential with mean, \u03bc = _______ and m  = _______. The standard deviation, \u03c3 = ________.\n\nDraw the appropriate exponential graph. You should label the x\u2013 and y\u2013axes, the decay rate, and the mean. Shade the area that represents the probability that one student has less than $.40 in his or her pocket or purse. (Shade P(x < 0.40)).",
                    "id": "C_570564_0"
                }
            ],
            "section_title": "Collaborative Exercise",
            "chapter_learning_objectives": [],
            "chapter_summary": "If X has an exponential distribution with mean \u03bc, then the decay parameter is m = $$\\(\\frac{1}{\\mu}\\)$$, and we write X \u223c Exp(m) where x \u2265 0 and m > 0 . The probability density function of X is f(x) = me-mx (or equivalently $$\\(f(x) = \\frac{1}{\\mu}e^{- x/\\mu}\\)$$. The cumulative distribution function of X is P(X \u2264 x) = 1 \u2013 e\u2013mx.The exponential distribution has the memoryless property, which says that future probabilities do not depend on any past information. Mathematically, it says that P(X > x + k|X > x) = P(X > k).If T represents the waiting time between events, and if T \u223c Exp(\u03bb), then the number of events X per unit time follows the Poisson distribution with mean \u03bb. The probability density function of X is $$\\(P{(X = k) = \\frac{\\lambda^{k}e^{- k}}{k!}}\\)$$. This may be computed using a TI-83, 83+, 84, 84+ calculator with the command poissonpdf(\u03bb, k). The cumulative distribution function P(X \u2264 k) may be computed using the TI-83, 83+,84, 84+ calculator with the command poissoncdf(\u03bb, k).",
            "chapter_introduction": "The exponential distribution is often concerned with the amount of time until some specific event occurs. For example, the amount of time (beginning now) until an earthquake occurs has an exponential distribution. Other examples include the length, in minutes, of long distance business telephone calls, and the amount of time, in months, a car battery lasts. It can be shown, too, that the value of the change that you have in your pocket or purse approximately follows an exponential distribution.\n\nValues for an exponential random variable occur in the following way. There are fewer large values and more small values. For example, the amount of money customers spend in one trip to the supermarket follows an exponential distribution. There are more people who spend small amounts of money and fewer people who spend large amounts of money.\n\nExponential distributions are commonly used in calculations of product reliability, or the length of time a product lasts.",
            "bold_terms": [
                "exponential distribution",
                "memoryless property"
            ],
            "chapter_concept": [
                {
                    "name": "Conditional Probability",
                    "description": "the likelihood that an event will occur given that another event has already occurred."
                },
                {
                    "name": "decay parameter",
                    "description": "The decay parameter describes the rate at which probabilities decay to zero for increasing values of x. It is the value m in the probability density function f(x) = me(-mx) of an exponential random variable. It is also equal to m = $$\\(\\frac{1}{\\mu}\\)$$, where \u03bc is the mean of the random variable."
                },
                {
                    "name": "Exponential Distribution",
                    "description": "a continuous random variable (RV) that appears when we are interested in the intervals of time between some random events, for example, the length of time between emergency arrivals at a hospital; the notation is X ~ Exp(m). The mean is \u03bc = $$\\(\\frac{1}{m}\\)$$ and the standard deviation is \u03c3 = $$\\(\\frac{1}{m}\\)$$. The probability density function is f(x) = me\u2212mx, x \u2265 0 and the cumulative distribution function is P(X \u2264 x) = 1 \u2212 e\u2212mx."
                },
                {
                    "name": "memoryless property",
                    "description": "For an exponential random variable X, the memoryless property is the statement that knowledge of what has occurred in the past has no effect on future probabilities. This means that the probability that X exceeds x + k, given that it has exceeded x, is the same as the probability that X would exceed k if we had no knowledge about it. In symbols we say that P(X > x + k|X > x) = P(X > k)."
                },
                {
                    "name": "Poisson distribution",
                    "description": "If there is a known average of \u03bb events occurring per unit time, and these events are independent of each other, then the number of events X occurring in one unit of time has the Poisson distribution. The probability of k events occurring in one unit time is equal to $$\\(P(X = k) = \\frac{\\lambda^{k}e^{- \\lambda}}{k!}\\)$$."
                },
                {
                    "name": "Uniform Distribution",
                    "description": "a continuous random variable (RV) that has equally likely outcomes over the domain, a < x < b. Notation: X ~ U(a,b). The mean is \u03bc = $$\\(\\frac{a + b}{2}\\)$$and the standard deviation is $$\\(\\sigma = \\sqrt{\\frac{\\left( {b - a} \\right)^{2}}{12}}\\)$$. The probability density function is f(x) = $$\\(\\frac{1}{b - a}\\)$$ for a < x < b or a \u2264 x \u2264 b. The  cumulative distribution is P(X \u2264 x) = $$\\(\\frac{x - a}{b - a}\\)$$."
                }
            ]
        },
        {
            "title": "5-3-the-exponential-distribution",
            "paragraphs": [
                {
                    "context": "In Example 5.7 recall that the amount of time between customers is exponentially distributed with a mean of two minutes (X ~ Exp (0.5)). Suppose that five minutes have elapsed since the last customer arrived. Since an unusually long amount of time has now elapsed, it would seem to be more likely for a customer to arrive within the next minute. With the exponential distribution, this is not the case\u2013the additional time spent waiting for the next customer does not depend on how much time has already elapsed since the last customer. This is referred to as the memoryless property. Specifically, the memoryless property says that\n\nP (X > r + t | X > r) = P (X > t) for all r \u2265 0 and t \u2265 0\n\nFor example, if five minutes have elapsed since the last customer arrived, then the probability that more than one minute will elapse before the next customer arrives is computed by using r = 5 and t = 1 in the foregoing equation.\n\nP(X > 5 + 1 | X > 5) = P(X > 1) = $$\\(e^{{({\u20130.5})}{(1)}}\\)$$ \u2248 0.6065.\n\nThis is the same probability as that of waiting more than one minute for a customer to arrive after the previous arrival.\n\nThe exponential distribution is often used to model the longevity of an electrical or mechanical device. In Example 5.9, the lifetime of a certain computer part has the exponential distribution with a mean of ten years (X ~ Exp(0.1)). The memoryless property says that knowledge of what has occurred in the past has no effect on future probabilities. In this case it means that an old part is not any more likely to break down at any particular time than a brand new part. In other words, the part stays as good as new until it suddenly breaks. For example, if the part has already lasted ten years, then the probability that it lasts another seven years is P(X > 17|X > 10) = P(X > 7) = 0.4966.",
                    "id": "C_567378_1"
                }
            ],
            "section_title": "Memorylessness of the Exponential Distribution",
            "chapter_learning_objectives": [],
            "chapter_summary": "If X has an exponential distribution with mean \u03bc, then the decay parameter is m = $$\\(\\frac{1}{\\mu}\\)$$, and we write X \u223c Exp(m) where x \u2265 0 and m > 0 . The probability density function of X is f(x) = me-mx (or equivalently $$\\(f(x) = \\frac{1}{\\mu}e^{- x/\\mu}\\)$$. The cumulative distribution function of X is P(X \u2264 x) = 1 \u2013 e\u2013mx.The exponential distribution has the memoryless property, which says that future probabilities do not depend on any past information. Mathematically, it says that P(X > x + k|X > x) = P(X > k).If T represents the waiting time between events, and if T \u223c Exp(\u03bb), then the number of events X per unit time follows the Poisson distribution with mean \u03bb. The probability density function of X is $$\\(P{(X = k) = \\frac{\\lambda^{k}e^{- k}}{k!}}\\)$$. This may be computed using a TI-83, 83+, 84, 84+ calculator with the command poissonpdf(\u03bb, k). The cumulative distribution function P(X \u2264 k) may be computed using the TI-83, 83+,84, 84+ calculator with the command poissoncdf(\u03bb, k).",
            "chapter_introduction": "The exponential distribution is often concerned with the amount of time until some specific event occurs. For example, the amount of time (beginning now) until an earthquake occurs has an exponential distribution. Other examples include the length, in minutes, of long distance business telephone calls, and the amount of time, in months, a car battery lasts. It can be shown, too, that the value of the change that you have in your pocket or purse approximately follows an exponential distribution.\n\nValues for an exponential random variable occur in the following way. There are fewer large values and more small values. For example, the amount of money customers spend in one trip to the supermarket follows an exponential distribution. There are more people who spend small amounts of money and fewer people who spend large amounts of money.\n\nExponential distributions are commonly used in calculations of product reliability, or the length of time a product lasts.",
            "bold_terms": [
                "exponential distribution",
                "memoryless property"
            ],
            "chapter_concept": [
                {
                    "name": "Conditional Probability",
                    "description": "the likelihood that an event will occur given that another event has already occurred."
                },
                {
                    "name": "decay parameter",
                    "description": "The decay parameter describes the rate at which probabilities decay to zero for increasing values of x. It is the value m in the probability density function f(x) = me(-mx) of an exponential random variable. It is also equal to m = $$\\(\\frac{1}{\\mu}\\)$$, where \u03bc is the mean of the random variable."
                },
                {
                    "name": "Exponential Distribution",
                    "description": "a continuous random variable (RV) that appears when we are interested in the intervals of time between some random events, for example, the length of time between emergency arrivals at a hospital; the notation is X ~ Exp(m). The mean is \u03bc = $$\\(\\frac{1}{m}\\)$$ and the standard deviation is \u03c3 = $$\\(\\frac{1}{m}\\)$$. The probability density function is f(x) = me\u2212mx, x \u2265 0 and the cumulative distribution function is P(X \u2264 x) = 1 \u2212 e\u2212mx."
                },
                {
                    "name": "memoryless property",
                    "description": "For an exponential random variable X, the memoryless property is the statement that knowledge of what has occurred in the past has no effect on future probabilities. This means that the probability that X exceeds x + k, given that it has exceeded x, is the same as the probability that X would exceed k if we had no knowledge about it. In symbols we say that P(X > x + k|X > x) = P(X > k)."
                },
                {
                    "name": "Poisson distribution",
                    "description": "If there is a known average of \u03bb events occurring per unit time, and these events are independent of each other, then the number of events X occurring in one unit of time has the Poisson distribution. The probability of k events occurring in one unit time is equal to $$\\(P(X = k) = \\frac{\\lambda^{k}e^{- \\lambda}}{k!}\\)$$."
                },
                {
                    "name": "Uniform Distribution",
                    "description": "a continuous random variable (RV) that has equally likely outcomes over the domain, a < x < b. Notation: X ~ U(a,b). The mean is \u03bc = $$\\(\\frac{a + b}{2}\\)$$and the standard deviation is $$\\(\\sigma = \\sqrt{\\frac{\\left( {b - a} \\right)^{2}}{12}}\\)$$. The probability density function is f(x) = $$\\(\\frac{1}{b - a}\\)$$ for a < x < b or a \u2264 x \u2264 b. The  cumulative distribution is P(X \u2264 x) = $$\\(\\frac{x - a}{b - a}\\)$$."
                }
            ]
        },
        {
            "title": "5-3-the-exponential-distribution",
            "paragraphs": [
                {
                    "context": "There is an interesting relationship between the exponential distribution and the Poisson distribution. Suppose that the time that elapses between two successive events follows the exponential distribution with a mean of \u03bc units of time. Also assume that these times are independent, meaning that the time between events is not affected by the times between previous events. If these assumptions hold, then the number of events per unit time follows a Poisson distribution with mean \u03bb = 1/\u03bc. Recall from the chapter on Discrete Random Variables that if X has the Poisson distribution with mean \u03bb, then $$\\(P(X = k) = \\frac{\\lambda^{k}e^{- \\lambda}}{k!}\\)$$. Conversely, if the number of events per unit time follows a Poisson distribution, then the amount of time between events follows the exponential distribution. (k! = k*(k\u20131*)(k\u20132)*(k\u20133)*\u20263*2*1)",
                    "id": "C_779566_2"
                }
            ],
            "section_title": "Relationship between the Poisson and the Exponential Distribution",
            "chapter_learning_objectives": [],
            "chapter_summary": "If X has an exponential distribution with mean \u03bc, then the decay parameter is m = $$\\(\\frac{1}{\\mu}\\)$$, and we write X \u223c Exp(m) where x \u2265 0 and m > 0 . The probability density function of X is f(x) = me-mx (or equivalently $$\\(f(x) = \\frac{1}{\\mu}e^{- x/\\mu}\\)$$. The cumulative distribution function of X is P(X \u2264 x) = 1 \u2013 e\u2013mx.The exponential distribution has the memoryless property, which says that future probabilities do not depend on any past information. Mathematically, it says that P(X > x + k|X > x) = P(X > k).If T represents the waiting time between events, and if T \u223c Exp(\u03bb), then the number of events X per unit time follows the Poisson distribution with mean \u03bb. The probability density function of X is $$\\(P{(X = k) = \\frac{\\lambda^{k}e^{- k}}{k!}}\\)$$. This may be computed using a TI-83, 83+, 84, 84+ calculator with the command poissonpdf(\u03bb, k). The cumulative distribution function P(X \u2264 k) may be computed using the TI-83, 83+,84, 84+ calculator with the command poissoncdf(\u03bb, k).",
            "chapter_introduction": "The exponential distribution is often concerned with the amount of time until some specific event occurs. For example, the amount of time (beginning now) until an earthquake occurs has an exponential distribution. Other examples include the length, in minutes, of long distance business telephone calls, and the amount of time, in months, a car battery lasts. It can be shown, too, that the value of the change that you have in your pocket or purse approximately follows an exponential distribution.\n\nValues for an exponential random variable occur in the following way. There are fewer large values and more small values. For example, the amount of money customers spend in one trip to the supermarket follows an exponential distribution. There are more people who spend small amounts of money and fewer people who spend large amounts of money.\n\nExponential distributions are commonly used in calculations of product reliability, or the length of time a product lasts.",
            "bold_terms": [
                "exponential distribution",
                "memoryless property"
            ],
            "chapter_concept": [
                {
                    "name": "Conditional Probability",
                    "description": "the likelihood that an event will occur given that another event has already occurred."
                },
                {
                    "name": "decay parameter",
                    "description": "The decay parameter describes the rate at which probabilities decay to zero for increasing values of x. It is the value m in the probability density function f(x) = me(-mx) of an exponential random variable. It is also equal to m = $$\\(\\frac{1}{\\mu}\\)$$, where \u03bc is the mean of the random variable."
                },
                {
                    "name": "Exponential Distribution",
                    "description": "a continuous random variable (RV) that appears when we are interested in the intervals of time between some random events, for example, the length of time between emergency arrivals at a hospital; the notation is X ~ Exp(m). The mean is \u03bc = $$\\(\\frac{1}{m}\\)$$ and the standard deviation is \u03c3 = $$\\(\\frac{1}{m}\\)$$. The probability density function is f(x) = me\u2212mx, x \u2265 0 and the cumulative distribution function is P(X \u2264 x) = 1 \u2212 e\u2212mx."
                },
                {
                    "name": "memoryless property",
                    "description": "For an exponential random variable X, the memoryless property is the statement that knowledge of what has occurred in the past has no effect on future probabilities. This means that the probability that X exceeds x + k, given that it has exceeded x, is the same as the probability that X would exceed k if we had no knowledge about it. In symbols we say that P(X > x + k|X > x) = P(X > k)."
                },
                {
                    "name": "Poisson distribution",
                    "description": "If there is a known average of \u03bb events occurring per unit time, and these events are independent of each other, then the number of events X occurring in one unit of time has the Poisson distribution. The probability of k events occurring in one unit time is equal to $$\\(P(X = k) = \\frac{\\lambda^{k}e^{- \\lambda}}{k!}\\)$$."
                },
                {
                    "name": "Uniform Distribution",
                    "description": "a continuous random variable (RV) that has equally likely outcomes over the domain, a < x < b. Notation: X ~ U(a,b). The mean is \u03bc = $$\\(\\frac{a + b}{2}\\)$$and the standard deviation is $$\\(\\sigma = \\sqrt{\\frac{\\left( {b - a} \\right)^{2}}{12}}\\)$$. The probability density function is f(x) = $$\\(\\frac{1}{b - a}\\)$$ for a < x < b or a \u2264 x \u2264 b. The  cumulative distribution is P(X \u2264 x) = $$\\(\\frac{x - a}{b - a}\\)$$."
                }
            ]
        },
        {
            "title": "5-3-the-exponential-distribution",
            "paragraphs": [
                {
                    "context": "Suppose X has the Poisson distribution with mean \u03bb. Compute P(X = k) by entering 2nd, VARS(DISTR), C: poissonpdf(\u03bb, k). To compute P(X \u2264 k), enter 2nd, VARS (DISTR), D:poissoncdf(\u03bb, k).",
                    "id": "C_595931_3"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "If X has an exponential distribution with mean \u03bc, then the decay parameter is m = $$\\(\\frac{1}{\\mu}\\)$$, and we write X \u223c Exp(m) where x \u2265 0 and m > 0 . The probability density function of X is f(x) = me-mx (or equivalently $$\\(f(x) = \\frac{1}{\\mu}e^{- x/\\mu}\\)$$. The cumulative distribution function of X is P(X \u2264 x) = 1 \u2013 e\u2013mx.The exponential distribution has the memoryless property, which says that future probabilities do not depend on any past information. Mathematically, it says that P(X > x + k|X > x) = P(X > k).If T represents the waiting time between events, and if T \u223c Exp(\u03bb), then the number of events X per unit time follows the Poisson distribution with mean \u03bb. The probability density function of X is $$\\(P{(X = k) = \\frac{\\lambda^{k}e^{- k}}{k!}}\\)$$. This may be computed using a TI-83, 83+, 84, 84+ calculator with the command poissonpdf(\u03bb, k). The cumulative distribution function P(X \u2264 k) may be computed using the TI-83, 83+,84, 84+ calculator with the command poissoncdf(\u03bb, k).",
            "chapter_introduction": "The exponential distribution is often concerned with the amount of time until some specific event occurs. For example, the amount of time (beginning now) until an earthquake occurs has an exponential distribution. Other examples include the length, in minutes, of long distance business telephone calls, and the amount of time, in months, a car battery lasts. It can be shown, too, that the value of the change that you have in your pocket or purse approximately follows an exponential distribution.\n\nValues for an exponential random variable occur in the following way. There are fewer large values and more small values. For example, the amount of money customers spend in one trip to the supermarket follows an exponential distribution. There are more people who spend small amounts of money and fewer people who spend large amounts of money.\n\nExponential distributions are commonly used in calculations of product reliability, or the length of time a product lasts.",
            "bold_terms": [
                "exponential distribution",
                "memoryless property"
            ],
            "chapter_concept": [
                {
                    "name": "Conditional Probability",
                    "description": "the likelihood that an event will occur given that another event has already occurred."
                },
                {
                    "name": "decay parameter",
                    "description": "The decay parameter describes the rate at which probabilities decay to zero for increasing values of x. It is the value m in the probability density function f(x) = me(-mx) of an exponential random variable. It is also equal to m = $$\\(\\frac{1}{\\mu}\\)$$, where \u03bc is the mean of the random variable."
                },
                {
                    "name": "Exponential Distribution",
                    "description": "a continuous random variable (RV) that appears when we are interested in the intervals of time between some random events, for example, the length of time between emergency arrivals at a hospital; the notation is X ~ Exp(m). The mean is \u03bc = $$\\(\\frac{1}{m}\\)$$ and the standard deviation is \u03c3 = $$\\(\\frac{1}{m}\\)$$. The probability density function is f(x) = me\u2212mx, x \u2265 0 and the cumulative distribution function is P(X \u2264 x) = 1 \u2212 e\u2212mx."
                },
                {
                    "name": "memoryless property",
                    "description": "For an exponential random variable X, the memoryless property is the statement that knowledge of what has occurred in the past has no effect on future probabilities. This means that the probability that X exceeds x + k, given that it has exceeded x, is the same as the probability that X would exceed k if we had no knowledge about it. In symbols we say that P(X > x + k|X > x) = P(X > k)."
                },
                {
                    "name": "Poisson distribution",
                    "description": "If there is a known average of \u03bb events occurring per unit time, and these events are independent of each other, then the number of events X occurring in one unit of time has the Poisson distribution. The probability of k events occurring in one unit time is equal to $$\\(P(X = k) = \\frac{\\lambda^{k}e^{- \\lambda}}{k!}\\)$$."
                },
                {
                    "name": "Uniform Distribution",
                    "description": "a continuous random variable (RV) that has equally likely outcomes over the domain, a < x < b. Notation: X ~ U(a,b). The mean is \u03bc = $$\\(\\frac{a + b}{2}\\)$$and the standard deviation is $$\\(\\sigma = \\sqrt{\\frac{\\left( {b - a} \\right)^{2}}{12}}\\)$$. The probability density function is f(x) = $$\\(\\frac{1}{b - a}\\)$$ for a < x < b or a \u2264 x \u2264 b. The  cumulative distribution is P(X \u2264 x) = $$\\(\\frac{x - a}{b - a}\\)$$."
                }
            ]
        },
        {
            "title": "6-1-the-standard-normal-distribution",
            "paragraphs": [
                {
                    "context": "If X is a normally distributed random variable and X ~ N(\u03bc, \u03c3), then the z-score is:\n\n$$\\[z = \\frac{x\\ \u2013\\ \\mu}{\\sigma}\\]$$\n\nThe z-score tells you how many standard deviations the value x is above (to the right of) or below (to the left of) the mean, \u03bc. Values of x that are larger than the mean have positive z-scores, and values of x that are smaller than the mean have negative z-scores. If x equals the mean, then x has a z-score of zero.\n\nThe Empirical RuleIf X is a random variable and has a normal distribution with mean \u00b5 and standard deviation \u03c3, then the Empirical Rule states the following:\n\nAbout 68% of the x values lie between \u20131\u03c3 and +1\u03c3 of the mean \u00b5 (within one standard deviation of the mean). About  95% of the x values lie between \u20132\u03c3 and +2\u03c3 of the mean \u00b5 (within two standard deviations of the mean). About 99.7% of the x values lie between \u20133\u03c3 and +3\u03c3 of the mean \u00b5 (within three standard deviations of the mean). Notice that almost all the x values lie within three standard deviations of the mean. The z-scores for +1\u03c3 and \u20131\u03c3 are +1 and \u20131, respectively. The z-scores for +2\u03c3  and \u20132\u03c3 are +2 and \u20132, respectively. The z-scores for +3\u03c3  and \u20133\u03c3 are +3 and \u20133 respectively. \n\nThe empirical rule is also known as the 68-95-99.7 rule.",
                    "id": "C_95044_0"
                }
            ],
            "section_title": "Z-Scores",
            "chapter_learning_objectives": [],
            "chapter_summary": "A z-score is a standardized value. Its distribution is the standard normal, Z ~ N(0, 1). The mean of the z-scores is zero and the standard deviation is one. If z is the z-score for a value x from the normal distribution N(\u00b5, \u03c3) then z tells you how many standard deviations x is above (greater than) or below (less than) \u00b5.",
            "chapter_introduction": "The standard normal distribution is a normal distribution of standardized values called z-scores. A z-score is measured in units of the standard deviation. For example, if the mean of a normal distribution is five and the standard deviation is two, the value 11 is three standard deviations above (or to the right of) the mean. The calculation is as follows:\n\nx = \u03bc + (z)(\u03c3) = 5 + (3)(2) = 11\n\nThe z-score is three.\n\nThe mean for the standard normal distribution is zero, and the standard deviation is one. The transformation z = $$\\(\\frac{x - \\mu}{\\sigma}\\)$$ produces the distribution Z ~ N(0, 1). The value x in the given equation comes from a normal distribution with mean \u03bc and standard deviation \u03c3.",
            "bold_terms": [
                "standard normal distribution",
                "standardized values called",
                "z-scores",
                "A z-score is measured in units of the standard deviation",
                "The z-score tells you how many standard deviations the value x is above (to the right of) or below (to the left of) the mean, \u03bc",
                "Empirical Rule"
            ],
            "chapter_concept": [
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf f(x) = $$\\(\\frac{1}{\\sigma\\sqrt{2\\pi}}\\text{~e}^{\\frac{\u2013(x\\ \u2013\\ \\mu)}{2\\sigma^{2}}^{2}}\\)$$, where \u03bc  is the mean of the distribution and \u03c3 is the standard deviation; notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "Standard Normal Distribution",
                    "description": "a continuous random variable (RV) X ~ N(0, 1); when X follows the standard normal distribution, it is often noted as Z ~ N(0, 1)."
                },
                {
                    "name": "z-score",
                    "description": "the linear transformation of the form z = $$\\(\\frac{x\\ \u2013\\ \\mu}{\\sigma}\\)$$; if this transformation is applied to any normal distribution X ~ N(\u03bc, \u03c3) the result is the standard normal distribution Z ~ N(0,1). If this transformation is applied to any specific value x of the RV with mean \u03bc and standard deviation \u03c3, the result is called the  z-score of x. The z-score allows us to compare data that are normally distributed but scaled differently."
                }
            ]
        },
        {
            "title": "6-2-using-the-normal-distribution",
            "paragraphs": [
                {
                    "context": "Probabilities are calculated using technology. There are instructions given as necessary for the TI-83+ and TI-84 calculators.",
                    "id": "C_249826_0"
                }
            ],
            "section_title": "Calculations of Probabilities",
            "chapter_learning_objectives": [],
            "chapter_summary": "The normal distribution, which is continuous, is the most important of all the probability distributions. Its graph is bell-shaped. This bell-shaped curve is used in almost all disciplines. Since it is a continuous distribution, the total area under the curve is one.  The parameters of the normal are the mean \u00b5 and the standard deviation \u03c3. A special normal distribution, called the standard normal distribution is the distribution of z-scores. Its mean is zero, and its standard deviation is one.",
            "chapter_introduction": "The shaded area in the following graph indicates the area to the left of x. This area is represented by the probability P(X < x). Normal tables, computers, and calculators provide or calculate the probability P(X < x).\n\nThe area to the right is thenP(X >x) = 1 \u2013P(X <x). Remember,P(X <x) =Area to the left of the vertical line throughx.P(X >x) = 1 \u2013P(X <x) =Area to the right of the vertical line throughx.P(X <x) is the same asP(X \u2264x) andP(X >x) is the same asP(X \u2265x) for continuous distributions.",
            "bold_terms": [
                "Area to the left",
                "Area to the right"
            ],
            "chapter_concept": [
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf f(x) = $$\\(\\frac{1}{\\sigma\\sqrt{2\\pi}}\\text{~e}^{\\frac{\u2013(x\\ \u2013\\ \\mu)}{2\\sigma^{2}}^{2}}\\)$$, where \u03bc  is the mean of the distribution and \u03c3 is the standard deviation; notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "Standard Normal Distribution",
                    "description": "a continuous random variable (RV) X ~ N(0, 1); when X follows the standard normal distribution, it is often noted as Z ~ N(0, 1)."
                },
                {
                    "name": "z-score",
                    "description": "the linear transformation of the form z = $$\\(\\frac{x\\ \u2013\\ \\mu}{\\sigma}\\)$$; if this transformation is applied to any normal distribution X ~ N(\u03bc, \u03c3) the result is the standard normal distribution Z ~ N(0,1). If this transformation is applied to any specific value x of the RV with mean \u03bc and standard deviation \u03c3, the result is called the  z-score of x. The z-score allows us to compare data that are normally distributed but scaled differently."
                }
            ]
        },
        {
            "title": "6-2-using-the-normal-distribution",
            "paragraphs": [
                {
                    "context": "To calculate the probability, use the probability tables provided in Appendix H Tables  without the use of technology. The tables include instructions for how to use them.",
                    "id": "C_448271_1"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "The normal distribution, which is continuous, is the most important of all the probability distributions. Its graph is bell-shaped. This bell-shaped curve is used in almost all disciplines. Since it is a continuous distribution, the total area under the curve is one.  The parameters of the normal are the mean \u00b5 and the standard deviation \u03c3. A special normal distribution, called the standard normal distribution is the distribution of z-scores. Its mean is zero, and its standard deviation is one.",
            "chapter_introduction": "The shaded area in the following graph indicates the area to the left of x. This area is represented by the probability P(X < x). Normal tables, computers, and calculators provide or calculate the probability P(X < x).\n\nThe area to the right is thenP(X >x) = 1 \u2013P(X <x). Remember,P(X <x) =Area to the left of the vertical line throughx.P(X >x) = 1 \u2013P(X <x) =Area to the right of the vertical line throughx.P(X <x) is the same asP(X \u2264x) andP(X >x) is the same asP(X \u2265x) for continuous distributions.",
            "bold_terms": [
                "Area to the left",
                "Area to the right"
            ],
            "chapter_concept": [
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf f(x) = $$\\(\\frac{1}{\\sigma\\sqrt{2\\pi}}\\text{~e}^{\\frac{\u2013(x\\ \u2013\\ \\mu)}{2\\sigma^{2}}^{2}}\\)$$, where \u03bc  is the mean of the distribution and \u03c3 is the standard deviation; notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "Standard Normal Distribution",
                    "description": "a continuous random variable (RV) X ~ N(0, 1); when X follows the standard normal distribution, it is often noted as Z ~ N(0, 1)."
                },
                {
                    "name": "z-score",
                    "description": "the linear transformation of the form z = $$\\(\\frac{x\\ \u2013\\ \\mu}{\\sigma}\\)$$; if this transformation is applied to any normal distribution X ~ N(\u03bc, \u03c3) the result is the standard normal distribution Z ~ N(0,1). If this transformation is applied to any specific value x of the RV with mean \u03bc and standard deviation \u03c3, the result is called the  z-score of x. The z-score allows us to compare data that are normally distributed but scaled differently."
                }
            ]
        },
        {
            "title": "7-1-the-central-limit-theorem-for-sample-means-averages",
            "paragraphs": [
                {
                    "context": "To find probabilities for means on the calculator, follow these steps.\n\n2nd DISTR2:normalcdf\n\n$$\\(normalcdf\\left( {lower\\ value\\ of\\ the\\ area,\\ upper\\ value\\ of\\ the\\ area,\\ mean,\\ \\frac{standard~deviation}{\\sqrt{sample~size}}} \\right)\\)$$\n\nwhere:\n\nmean is the mean of the original distribution standard deviation is the standard deviation of the original distribution sample size = n ",
                    "id": "C_647636_0"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "In a population whose distribution may be known or unknown, if the size (n) of samples is sufficiently large, the distribution of the sample means will be approximately normal. The mean of the sample means will equal the population mean. The standard deviation of the distribution of the sample means, called the standard error of the mean, is equal to the population standard deviation divided by the square root of the sample size (n).",
            "chapter_introduction": "Suppose X is a random variable with a distribution that may be known or unknown (it can be any distribution). Using a subscript that matches the random variable, suppose:\n\n\u03bcX = the mean of X \u03c3X = the standard deviation of X \n\nIf you draw random samples of size n, then as n increases, the random variable $$\\(\\overline{x}\\)$$ which consists of sample means, tends to be normally distributed and\n\n$$\\(\\overline{x}\\)$$ ~ N$$\\(\\left( {\\mu_{x}\\text{,~}\\frac{\\sigma X}{\\sqrt{n}}} \\right)\\)$$.\n\nThe central limit theorem for sample means says that if you repeatedly draw samples of a given size (such as repeatedly rolling ten dice) and calculate their means, those means tend to follow a normal distribution (the sampling distribution). As sample sizes increase, the distribution of means more closely follows the normal distribution. The normal distribution has the same mean as the original distribution and a variance that equals the original variance divided by the sample size. Standard deviation is the square root of variance, so the standard deviation of the sampling distribution is the standard deviation of the original distribution divided by the square root of n. The variable n is the number of values that are averaged together, not the number of times the experiment is done.\n\nTo put it more formally, if you draw random samples of size n, the distribution of the random variable $$\\(\\overline{x}\\)$$, which consists of sample means, is called the sampling distribution of the mean. The sampling distribution of the mean approaches a normal distribution as n, the sample size, increases. \n\nThe random variable $$\\(\\overline{x}\\)$$ has a different z-score associated with it from that of the random variable X. The mean $$\\(\\overline{x}\\)$$ is the value of $$\\(\\overline{x}\\)$$ in one sample.\n\n$$\\[z = \\frac{\\overline{x} - \\mu_{x}}{\\left( \\frac{\\sigma_{X}}{\\sqrt{n}} \\right)}\\]$$\n\n\u03bcX is the average of both X and $$\\(\\overline{x}\\)$$.\n\n$$\\(\\sigma\\overline{x}\\text{~=~}\\frac{\\sigma X}{\\sqrt{n}}\\)$$ = standard deviation of $$\\(\\overline{x}\\)$$ and is called the standard error of the mean.",
            "bold_terms": [
                "normally distributed",
                "central limit theorem",
                "sampling distribution of the mean",
                "sample size",
                "standard error of the mean"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "a number that describes the central tendency of the data; there are a number of specialized averages, including the arithmetic mean, weighted mean, median, mode, and geometric mean."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "Given a random variable (RV) with known mean \u03bc and known standard deviation, \u03c3, we are sampling with size n, and we are interested in two new RVs: the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, \u03a3\u03a7. If the size (n) of the sample is sufficiently large, then $$\\(\\overline{X}\\)$$ ~ N(\u03bc, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$) and \u03a3\u03a7 ~ N(n\u03bc, ($$\\(\\sqrt{n}\\)$$)(\u03c3)). If the size (n) of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distributions regardless of the shape of the population. The mean of the sample  means will equal the population mean, and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Exponential Distribution",
                    "description": "a continuous random variable (RV) that appears when we are interested in the intervals of time between some random events, for example, the length of time between emergency arrivals at a hospital, notation: X ~ Exp(m). The mean is \u03bc = $$\\(\\frac{1}{m}\\)$$ and the standard deviation is \u03c3 = $$\\(\\frac{1}{m}\\)$$. The probability density function is f(x) = me\u2013mx, x \u2265 0 and the cumulative distribution function is P(X \u2264 x) = 1 \u2013 e\u2013mx."
                },
                {
                    "name": "Mean",
                    "description": "a number that measures the central tendency; a common name for mean is \"average.\" The term \"mean\" is a shortened form of \"arithmetic mean.\" By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation; notation: \u03a7 ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called a  standard normal distribution."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation.; notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "Sampling Distribution",
                    "description": "Given simple random samples of size n from a given population with a measured characteristic such as mean, proportion, or standard deviation for each sample, the probability distribution of all the measured characteristics is called a sampling distribution."
                },
                {
                    "name": "Uniform Distribution",
                    "description": "a continuous random variable (RV) that has equally likely outcomes over the domain, a < x < b; often referred as the  Rectangular Distribution because the graph of the pdf has the form of a rectangle. Notation: X ~ U(a, b). The mean is $$\\(\\mu\\text{~=~}\\frac{a\\text{~+~}b}{2}\\)$$ and the standard deviation is $$\\(\\sigma\\text{~=~}\\sqrt{\\frac{{(b\u2013\\text{a)}}^{2}}{12}}\\)$$. The probability density function is $$\\(f(x)\\text{~=~}\\frac{1}{b\u2013a}\\)$$ for a < x < b or a \u2264 x \u2264 b. The cumulative distribution is P(X \u2264 x) = $$\\(\\frac{x\u2013\\text{a}}{b\u2013\\text{a}}\\)$$."
                }
            ]
        },
        {
            "title": "7-1-the-central-limit-theorem-for-sample-means-averages",
            "paragraphs": [
                {
                    "context": "To find percentiles for means on the calculator, follow these steps.\n\n2nd DIStR3:invNorm\n\nk = invNorm$$\\(\\left( {\\text{area~to~the~left~of~}k\\text{,~mean,}~\\frac{standard~deviation}{\\sqrt{sample~size}}} \\right)\\)$$\n\nwhere:\n\nk = the kth percentile mean is the mean of the original distribution standard deviation is the standard deviation of the original distribution sample size = n ",
                    "id": "C_4110_1"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "In a population whose distribution may be known or unknown, if the size (n) of samples is sufficiently large, the distribution of the sample means will be approximately normal. The mean of the sample means will equal the population mean. The standard deviation of the distribution of the sample means, called the standard error of the mean, is equal to the population standard deviation divided by the square root of the sample size (n).",
            "chapter_introduction": "Suppose X is a random variable with a distribution that may be known or unknown (it can be any distribution). Using a subscript that matches the random variable, suppose:\n\n\u03bcX = the mean of X \u03c3X = the standard deviation of X \n\nIf you draw random samples of size n, then as n increases, the random variable $$\\(\\overline{x}\\)$$ which consists of sample means, tends to be normally distributed and\n\n$$\\(\\overline{x}\\)$$ ~ N$$\\(\\left( {\\mu_{x}\\text{,~}\\frac{\\sigma X}{\\sqrt{n}}} \\right)\\)$$.\n\nThe central limit theorem for sample means says that if you repeatedly draw samples of a given size (such as repeatedly rolling ten dice) and calculate their means, those means tend to follow a normal distribution (the sampling distribution). As sample sizes increase, the distribution of means more closely follows the normal distribution. The normal distribution has the same mean as the original distribution and a variance that equals the original variance divided by the sample size. Standard deviation is the square root of variance, so the standard deviation of the sampling distribution is the standard deviation of the original distribution divided by the square root of n. The variable n is the number of values that are averaged together, not the number of times the experiment is done.\n\nTo put it more formally, if you draw random samples of size n, the distribution of the random variable $$\\(\\overline{x}\\)$$, which consists of sample means, is called the sampling distribution of the mean. The sampling distribution of the mean approaches a normal distribution as n, the sample size, increases. \n\nThe random variable $$\\(\\overline{x}\\)$$ has a different z-score associated with it from that of the random variable X. The mean $$\\(\\overline{x}\\)$$ is the value of $$\\(\\overline{x}\\)$$ in one sample.\n\n$$\\[z = \\frac{\\overline{x} - \\mu_{x}}{\\left( \\frac{\\sigma_{X}}{\\sqrt{n}} \\right)}\\]$$\n\n\u03bcX is the average of both X and $$\\(\\overline{x}\\)$$.\n\n$$\\(\\sigma\\overline{x}\\text{~=~}\\frac{\\sigma X}{\\sqrt{n}}\\)$$ = standard deviation of $$\\(\\overline{x}\\)$$ and is called the standard error of the mean.",
            "bold_terms": [
                "normally distributed",
                "central limit theorem",
                "sampling distribution of the mean",
                "sample size",
                "standard error of the mean"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "a number that describes the central tendency of the data; there are a number of specialized averages, including the arithmetic mean, weighted mean, median, mode, and geometric mean."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "Given a random variable (RV) with known mean \u03bc and known standard deviation, \u03c3, we are sampling with size n, and we are interested in two new RVs: the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, \u03a3\u03a7. If the size (n) of the sample is sufficiently large, then $$\\(\\overline{X}\\)$$ ~ N(\u03bc, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$) and \u03a3\u03a7 ~ N(n\u03bc, ($$\\(\\sqrt{n}\\)$$)(\u03c3)). If the size (n) of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distributions regardless of the shape of the population. The mean of the sample  means will equal the population mean, and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Exponential Distribution",
                    "description": "a continuous random variable (RV) that appears when we are interested in the intervals of time between some random events, for example, the length of time between emergency arrivals at a hospital, notation: X ~ Exp(m). The mean is \u03bc = $$\\(\\frac{1}{m}\\)$$ and the standard deviation is \u03c3 = $$\\(\\frac{1}{m}\\)$$. The probability density function is f(x) = me\u2013mx, x \u2265 0 and the cumulative distribution function is P(X \u2264 x) = 1 \u2013 e\u2013mx."
                },
                {
                    "name": "Mean",
                    "description": "a number that measures the central tendency; a common name for mean is \"average.\" The term \"mean\" is a shortened form of \"arithmetic mean.\" By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation; notation: \u03a7 ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called a  standard normal distribution."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation.; notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "Sampling Distribution",
                    "description": "Given simple random samples of size n from a given population with a measured characteristic such as mean, proportion, or standard deviation for each sample, the probability distribution of all the measured characteristics is called a sampling distribution."
                },
                {
                    "name": "Uniform Distribution",
                    "description": "a continuous random variable (RV) that has equally likely outcomes over the domain, a < x < b; often referred as the  Rectangular Distribution because the graph of the pdf has the form of a rectangle. Notation: X ~ U(a, b). The mean is $$\\(\\mu\\text{~=~}\\frac{a\\text{~+~}b}{2}\\)$$ and the standard deviation is $$\\(\\sigma\\text{~=~}\\sqrt{\\frac{{(b\u2013\\text{a)}}^{2}}{12}}\\)$$. The probability density function is $$\\(f(x)\\text{~=~}\\frac{1}{b\u2013a}\\)$$ for a < x < b or a \u2264 x \u2264 b. The cumulative distribution is P(X \u2264 x) = $$\\(\\frac{x\u2013\\text{a}}{b\u2013\\text{a}}\\)$$."
                }
            ]
        },
        {
            "title": "7-2-the-central-limit-theorem-for-sums",
            "paragraphs": [
                {
                    "context": "To find probabilities for sums on the calculator, follow these steps.\n\n2nd DISTR2:normalcdfnormalcdf(lower value of the area, upper value of the area, (n)(mean), ($$\\(\\sqrt{n}\\)$$)(standard deviation))\n\nwhere:\n\nmean is the mean of the original distribution standard deviation is the standard deviation of the original distribution sample size = n ",
                    "id": "C_23079_0"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "The central limit theorem tells us that for a population with any distribution, the distribution of the sums for the sample means approaches a normal distribution as the sample size increases. In other words, if the sample size is large enough, the distribution of the sums can be approximated by a normal distribution even if the original population is not normally distributed. Additionally, if the original population has a mean of \u03bcX and a standard deviation of \u03c3x, the mean of the sums is n\u03bcx and the standard deviation is $$\\((\\sqrt{n})\\)$$(\u03c3x) where n is the sample size.",
            "chapter_introduction": "Suppose X is a random variable with a distribution that may be known or unknown (it can be any distribution) and suppose:\n\n\u03bcX = the mean of \u03a7 \u03c3\u03a7 = the standard deviation of X \n\nIf you draw random samples of size n, then as n increases, the random variable \u03a3X consisting of sums tends to be normally distributed and \u03a3\u03a7 ~ N((n)(\u03bc\u03a7), ($$\\(\\sqrt{n}\\)$$)(\u03c3\u03a7)).\n\nThe central limit theorem for sums says that if you repeatedly draw samples of a given size (such as repeatedly rolling ten dice) and calculate the sum of each sample, these sums tend to follow a normal distribution. As sample sizes increase, the distribution of means more closely follows the normal distribution. The normal distribution has a mean equal to the original mean multiplied by the sample size and a standard deviation equal to the original standard deviation multiplied by the square root of the sample size.\n\nThe random variable \u03a3X has the following z-score associated with it:\n\n\u03a3x is one sum. $$\\(z\\text{~=~}\\frac{\\Sigma x\u2013(n)(\\mu_{X})}{(\\sqrt{n})(\\sigma_{X})}\\)$$(n)(\u03bcX) = the mean of \u03a3X(n\u2212\u2212\u221a)(\u03c3X)(n)(\u03c3X)(n)(\u03c3X) = standard deviation of \u03a3X\u03a3X\u03a3X ",
            "bold_terms": [
                "known or unknown",
                "normally distributed",
                "The",
                "central limit theorem for sums",
                "The normal distribution has a mean equal to the original mean multiplied by the sample size and a standard deviation equal to the original standard deviation multiplied by the square root of the sample size",
                "sample size",
                "percentile"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "a number that describes the central tendency of the data; there are a number of specialized averages, including the arithmetic mean, weighted mean, median, mode, and geometric mean."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "Given a random variable (RV) with known mean \u03bc and known standard deviation, \u03c3, we are sampling with size n, and we are interested in two new RVs: the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, \u03a3\u03a7. If the size (n) of the sample is sufficiently large, then $$\\(\\overline{X}\\)$$ ~ N(\u03bc, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$) and \u03a3\u03a7 ~ N(n\u03bc, ($$\\(\\sqrt{n}\\)$$)(\u03c3)). If the size (n) of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distributions regardless of the shape of the population. The mean of the sample  means will equal the population mean, and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Exponential Distribution",
                    "description": "a continuous random variable (RV) that appears when we are interested in the intervals of time between some random events, for example, the length of time between emergency arrivals at a hospital, notation: X ~ Exp(m). The mean is \u03bc = $$\\(\\frac{1}{m}\\)$$ and the standard deviation is \u03c3 = $$\\(\\frac{1}{m}\\)$$. The probability density function is f(x) = me\u2013mx, x \u2265 0 and the cumulative distribution function is P(X \u2264 x) = 1 \u2013 e\u2013mx."
                },
                {
                    "name": "Mean",
                    "description": "a number that measures the central tendency; a common name for mean is \"average.\" The term \"mean\" is a shortened form of \"arithmetic mean.\" By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation; notation: \u03a7 ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called a  standard normal distribution."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation.; notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "Sampling Distribution",
                    "description": "Given simple random samples of size n from a given population with a measured characteristic such as mean, proportion, or standard deviation for each sample, the probability distribution of all the measured characteristics is called a sampling distribution."
                },
                {
                    "name": "Uniform Distribution",
                    "description": "a continuous random variable (RV) that has equally likely outcomes over the domain, a < x < b; often referred as the  Rectangular Distribution because the graph of the pdf has the form of a rectangle. Notation: X ~ U(a, b). The mean is $$\\(\\mu\\text{~=~}\\frac{a\\text{~+~}b}{2}\\)$$ and the standard deviation is $$\\(\\sigma\\text{~=~}\\sqrt{\\frac{{(b\u2013\\text{a)}}^{2}}{12}}\\)$$. The probability density function is $$\\(f(x)\\text{~=~}\\frac{1}{b\u2013a}\\)$$ for a < x < b or a \u2264 x \u2264 b. The cumulative distribution is P(X \u2264 x) = $$\\(\\frac{x\u2013\\text{a}}{b\u2013\\text{a}}\\)$$."
                }
            ]
        },
        {
            "title": "7-2-the-central-limit-theorem-for-sums",
            "paragraphs": [
                {
                    "context": "To find percentiles for sums on the calculator, follow these steps.\n\n2nd DIStR3:invNormk = invNorm (area to the left of k, (n)(mean), $$\\(\\text{(}\\sqrt{n})\\)$$(standard deviation))\n\nwhere:\n\nk is the kth percentile mean is the mean of the original distribution standard deviation is the standard deviation of the original distribution sample size = n ",
                    "id": "C_108302_1"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "The central limit theorem tells us that for a population with any distribution, the distribution of the sums for the sample means approaches a normal distribution as the sample size increases. In other words, if the sample size is large enough, the distribution of the sums can be approximated by a normal distribution even if the original population is not normally distributed. Additionally, if the original population has a mean of \u03bcX and a standard deviation of \u03c3x, the mean of the sums is n\u03bcx and the standard deviation is $$\\((\\sqrt{n})\\)$$(\u03c3x) where n is the sample size.",
            "chapter_introduction": "Suppose X is a random variable with a distribution that may be known or unknown (it can be any distribution) and suppose:\n\n\u03bcX = the mean of \u03a7 \u03c3\u03a7 = the standard deviation of X \n\nIf you draw random samples of size n, then as n increases, the random variable \u03a3X consisting of sums tends to be normally distributed and \u03a3\u03a7 ~ N((n)(\u03bc\u03a7), ($$\\(\\sqrt{n}\\)$$)(\u03c3\u03a7)).\n\nThe central limit theorem for sums says that if you repeatedly draw samples of a given size (such as repeatedly rolling ten dice) and calculate the sum of each sample, these sums tend to follow a normal distribution. As sample sizes increase, the distribution of means more closely follows the normal distribution. The normal distribution has a mean equal to the original mean multiplied by the sample size and a standard deviation equal to the original standard deviation multiplied by the square root of the sample size.\n\nThe random variable \u03a3X has the following z-score associated with it:\n\n\u03a3x is one sum. $$\\(z\\text{~=~}\\frac{\\Sigma x\u2013(n)(\\mu_{X})}{(\\sqrt{n})(\\sigma_{X})}\\)$$(n)(\u03bcX) = the mean of \u03a3X(n\u2212\u2212\u221a)(\u03c3X)(n)(\u03c3X)(n)(\u03c3X) = standard deviation of \u03a3X\u03a3X\u03a3X ",
            "bold_terms": [
                "known or unknown",
                "normally distributed",
                "The",
                "central limit theorem for sums",
                "The normal distribution has a mean equal to the original mean multiplied by the sample size and a standard deviation equal to the original standard deviation multiplied by the square root of the sample size",
                "sample size",
                "percentile"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "a number that describes the central tendency of the data; there are a number of specialized averages, including the arithmetic mean, weighted mean, median, mode, and geometric mean."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "Given a random variable (RV) with known mean \u03bc and known standard deviation, \u03c3, we are sampling with size n, and we are interested in two new RVs: the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, \u03a3\u03a7. If the size (n) of the sample is sufficiently large, then $$\\(\\overline{X}\\)$$ ~ N(\u03bc, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$) and \u03a3\u03a7 ~ N(n\u03bc, ($$\\(\\sqrt{n}\\)$$)(\u03c3)). If the size (n) of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distributions regardless of the shape of the population. The mean of the sample  means will equal the population mean, and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Exponential Distribution",
                    "description": "a continuous random variable (RV) that appears when we are interested in the intervals of time between some random events, for example, the length of time between emergency arrivals at a hospital, notation: X ~ Exp(m). The mean is \u03bc = $$\\(\\frac{1}{m}\\)$$ and the standard deviation is \u03c3 = $$\\(\\frac{1}{m}\\)$$. The probability density function is f(x) = me\u2013mx, x \u2265 0 and the cumulative distribution function is P(X \u2264 x) = 1 \u2013 e\u2013mx."
                },
                {
                    "name": "Mean",
                    "description": "a number that measures the central tendency; a common name for mean is \"average.\" The term \"mean\" is a shortened form of \"arithmetic mean.\" By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation; notation: \u03a7 ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called a  standard normal distribution."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation.; notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "Sampling Distribution",
                    "description": "Given simple random samples of size n from a given population with a measured characteristic such as mean, proportion, or standard deviation for each sample, the probability distribution of all the measured characteristics is called a sampling distribution."
                },
                {
                    "name": "Uniform Distribution",
                    "description": "a continuous random variable (RV) that has equally likely outcomes over the domain, a < x < b; often referred as the  Rectangular Distribution because the graph of the pdf has the form of a rectangle. Notation: X ~ U(a, b). The mean is $$\\(\\mu\\text{~=~}\\frac{a\\text{~+~}b}{2}\\)$$ and the standard deviation is $$\\(\\sigma\\text{~=~}\\sqrt{\\frac{{(b\u2013\\text{a)}}^{2}}{12}}\\)$$. The probability density function is $$\\(f(x)\\text{~=~}\\frac{1}{b\u2013a}\\)$$ for a < x < b or a \u2264 x \u2264 b. The cumulative distribution is P(X \u2264 x) = $$\\(\\frac{x\u2013\\text{a}}{b\u2013\\text{a}}\\)$$."
                }
            ]
        },
        {
            "title": "7-3-using-the-central-limit-theorem",
            "paragraphs": [
                {
                    "context": "If you are being asked to find the probability of an individual value, do not use the clt. Use the distribution of its random variable.",
                    "id": "C_956486_0"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "The central limit theorem can be used to illustrate the law of large numbers. The law of large numbers states that the larger the sample size you take from a population, the closer the sample mean $$\\(\\overline{x}\\)$$ gets to \u03bc.",
            "chapter_introduction": "It is important for you to understand when to use the central limit theorem. If you are being asked to find the probability of the mean, use the clt for the mean. If you are being asked to find the probability of a sum or total, use the clt for sums. This also applies to percentiles for means and sums.",
            "bold_terms": [
                "central limit theorem",
                "individual",
                "not",
                "Use the distribution of its random variable",
                "law of large numbers",
                " Normal Approximation to the Binomial",
                "normal approximation to the binomial",
                "binomial distribution",
                "continuity correction factor"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "a number that describes the central tendency of the data; there are a number of specialized averages, including the arithmetic mean, weighted mean, median, mode, and geometric mean."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "Given a random variable (RV) with known mean \u03bc and known standard deviation, \u03c3, we are sampling with size n, and we are interested in two new RVs: the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, \u03a3\u03a7. If the size (n) of the sample is sufficiently large, then $$\\(\\overline{X}\\)$$ ~ N(\u03bc, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$) and \u03a3\u03a7 ~ N(n\u03bc, ($$\\(\\sqrt{n}\\)$$)(\u03c3)). If the size (n) of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distributions regardless of the shape of the population. The mean of the sample  means will equal the population mean, and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Exponential Distribution",
                    "description": "a continuous random variable (RV) that appears when we are interested in the intervals of time between some random events, for example, the length of time between emergency arrivals at a hospital, notation: X ~ Exp(m). The mean is \u03bc = $$\\(\\frac{1}{m}\\)$$ and the standard deviation is \u03c3 = $$\\(\\frac{1}{m}\\)$$. The probability density function is f(x) = me\u2013mx, x \u2265 0 and the cumulative distribution function is P(X \u2264 x) = 1 \u2013 e\u2013mx."
                },
                {
                    "name": "Mean",
                    "description": "a number that measures the central tendency; a common name for mean is \"average.\" The term \"mean\" is a shortened form of \"arithmetic mean.\" By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation; notation: \u03a7 ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called a  standard normal distribution."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation.; notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "Sampling Distribution",
                    "description": "Given simple random samples of size n from a given population with a measured characteristic such as mean, proportion, or standard deviation for each sample, the probability distribution of all the measured characteristics is called a sampling distribution."
                },
                {
                    "name": "Uniform Distribution",
                    "description": "a continuous random variable (RV) that has equally likely outcomes over the domain, a < x < b; often referred as the  Rectangular Distribution because the graph of the pdf has the form of a rectangle. Notation: X ~ U(a, b). The mean is $$\\(\\mu\\text{~=~}\\frac{a\\text{~+~}b}{2}\\)$$ and the standard deviation is $$\\(\\sigma\\text{~=~}\\sqrt{\\frac{{(b\u2013\\text{a)}}^{2}}{12}}\\)$$. The probability density function is $$\\(f(x)\\text{~=~}\\frac{1}{b\u2013a}\\)$$ for a < x < b or a \u2264 x \u2264 b. The cumulative distribution is P(X \u2264 x) = $$\\(\\frac{x\u2013\\text{a}}{b\u2013\\text{a}}\\)$$."
                }
            ]
        },
        {
            "title": "7-3-using-the-central-limit-theorem",
            "paragraphs": [
                {
                    "context": "The law of large numbers says that if you take samples of larger and larger size from any population, then the mean $$\\(\\overline{x}\\)$$ of the sample tends to get closer and closer to \u03bc. From the central limit theorem, we know that as n gets larger and larger, the sample means follow a normal distribution. The larger n gets, the smaller the standard deviation gets. (Remember that the standard deviation for $$\\(\\overline{X}\\)$$ is $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$.) This means that the sample mean $$\\(\\overline{x}\\)$$ must be close to the population mean \u03bc. We can say that \u03bc is the value that the sample means approach as n gets larger. The central limit theorem illustrates the law of large numbers.",
                    "id": "C_384987_2"
                }
            ],
            "section_title": "Law of Large Numbers",
            "chapter_learning_objectives": [],
            "chapter_summary": "The central limit theorem can be used to illustrate the law of large numbers. The law of large numbers states that the larger the sample size you take from a population, the closer the sample mean $$\\(\\overline{x}\\)$$ gets to \u03bc.",
            "chapter_introduction": "It is important for you to understand when to use the central limit theorem. If you are being asked to find the probability of the mean, use the clt for the mean. If you are being asked to find the probability of a sum or total, use the clt for sums. This also applies to percentiles for means and sums.",
            "bold_terms": [
                "central limit theorem",
                "individual",
                "not",
                "Use the distribution of its random variable",
                "law of large numbers",
                " Normal Approximation to the Binomial",
                "normal approximation to the binomial",
                "binomial distribution",
                "continuity correction factor"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "a number that describes the central tendency of the data; there are a number of specialized averages, including the arithmetic mean, weighted mean, median, mode, and geometric mean."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "Given a random variable (RV) with known mean \u03bc and known standard deviation, \u03c3, we are sampling with size n, and we are interested in two new RVs: the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, \u03a3\u03a7. If the size (n) of the sample is sufficiently large, then $$\\(\\overline{X}\\)$$ ~ N(\u03bc, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$) and \u03a3\u03a7 ~ N(n\u03bc, ($$\\(\\sqrt{n}\\)$$)(\u03c3)). If the size (n) of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distributions regardless of the shape of the population. The mean of the sample  means will equal the population mean, and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Exponential Distribution",
                    "description": "a continuous random variable (RV) that appears when we are interested in the intervals of time between some random events, for example, the length of time between emergency arrivals at a hospital, notation: X ~ Exp(m). The mean is \u03bc = $$\\(\\frac{1}{m}\\)$$ and the standard deviation is \u03c3 = $$\\(\\frac{1}{m}\\)$$. The probability density function is f(x) = me\u2013mx, x \u2265 0 and the cumulative distribution function is P(X \u2264 x) = 1 \u2013 e\u2013mx."
                },
                {
                    "name": "Mean",
                    "description": "a number that measures the central tendency; a common name for mean is \"average.\" The term \"mean\" is a shortened form of \"arithmetic mean.\" By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation; notation: \u03a7 ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called a  standard normal distribution."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation.; notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "Sampling Distribution",
                    "description": "Given simple random samples of size n from a given population with a measured characteristic such as mean, proportion, or standard deviation for each sample, the probability distribution of all the measured characteristics is called a sampling distribution."
                },
                {
                    "name": "Uniform Distribution",
                    "description": "a continuous random variable (RV) that has equally likely outcomes over the domain, a < x < b; often referred as the  Rectangular Distribution because the graph of the pdf has the form of a rectangle. Notation: X ~ U(a, b). The mean is $$\\(\\mu\\text{~=~}\\frac{a\\text{~+~}b}{2}\\)$$ and the standard deviation is $$\\(\\sigma\\text{~=~}\\sqrt{\\frac{{(b\u2013\\text{a)}}^{2}}{12}}\\)$$. The probability density function is $$\\(f(x)\\text{~=~}\\frac{1}{b\u2013a}\\)$$ for a < x < b or a \u2264 x \u2264 b. The cumulative distribution is P(X \u2264 x) = $$\\(\\frac{x\u2013\\text{a}}{b\u2013\\text{a}}\\)$$."
                }
            ]
        },
        {
            "title": "7-3-using-the-central-limit-theorem",
            "paragraphs": [
                {
                    "context": ": Normal Approximation to the Binomial\n\nHistorically, being able to compute binomial probabilities was one of the most important applications of the central limit theorem. Binomial probabilities with a small value for n(say, 20) were displayed in a table in a book. To calculate the probabilities with large values of n,  you had to use the binomial formula, which could be very complicated. Using the normal approximation to the binomial distribution simplified the process. To compute the normal approximation to the binomial distribution, take a simple random sample from a population. You must meet the conditions for a binomial distribution:\n\nthere are a certain number n of independent trials the outcomes of any trial are success or failure each trial has the same probability of a success p \n\nRecall that if X is the binomial random variable, then X ~ B(n, p). The shape of the binomial distribution needs to besimilar to the shape of the normal distribution. To ensure this, the quantities npand nq must both be greater than five (np > 5 and nq > 5;  the approximation is better if they are both greater than or equal to 10). Then the binomial can be approximated by the normal distribution with mean \u03bc = np and standard deviation \u03c3 = $$\\(\\sqrt{npq}\\)$$. Remember that q = 1 \u2013 p. In order to get the best approximation, add 0.5 to x or subtract 0.5 from x (use x + 0.5 or x \u2013 0.5). The number 0.5 is called the continuity correction factor and is used in the following example.",
                    "id": "C_324958_4"
                }
            ],
            "section_title": "HISTORICAL NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "The central limit theorem can be used to illustrate the law of large numbers. The law of large numbers states that the larger the sample size you take from a population, the closer the sample mean $$\\(\\overline{x}\\)$$ gets to \u03bc.",
            "chapter_introduction": "It is important for you to understand when to use the central limit theorem. If you are being asked to find the probability of the mean, use the clt for the mean. If you are being asked to find the probability of a sum or total, use the clt for sums. This also applies to percentiles for means and sums.",
            "bold_terms": [
                "central limit theorem",
                "individual",
                "not",
                "Use the distribution of its random variable",
                "law of large numbers",
                " Normal Approximation to the Binomial",
                "normal approximation to the binomial",
                "binomial distribution",
                "continuity correction factor"
            ],
            "chapter_concept": [
                {
                    "name": "Average",
                    "description": "a number that describes the central tendency of the data; there are a number of specialized averages, including the arithmetic mean, weighted mean, median, mode, and geometric mean."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "Given a random variable (RV) with known mean \u03bc and known standard deviation, \u03c3, we are sampling with size n, and we are interested in two new RVs: the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, \u03a3\u03a7. If the size (n) of the sample is sufficiently large, then $$\\(\\overline{X}\\)$$ ~ N(\u03bc, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$) and \u03a3\u03a7 ~ N(n\u03bc, ($$\\(\\sqrt{n}\\)$$)(\u03c3)). If the size (n) of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distributions regardless of the shape of the population. The mean of the sample  means will equal the population mean, and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Exponential Distribution",
                    "description": "a continuous random variable (RV) that appears when we are interested in the intervals of time between some random events, for example, the length of time between emergency arrivals at a hospital, notation: X ~ Exp(m). The mean is \u03bc = $$\\(\\frac{1}{m}\\)$$ and the standard deviation is \u03c3 = $$\\(\\frac{1}{m}\\)$$. The probability density function is f(x) = me\u2013mx, x \u2265 0 and the cumulative distribution function is P(X \u2264 x) = 1 \u2013 e\u2013mx."
                },
                {
                    "name": "Mean",
                    "description": "a number that measures the central tendency; a common name for mean is \"average.\" The term \"mean\" is a shortened form of \"arithmetic mean.\" By definition, the mean for a sample (denoted by $$\\(\\overline{x}\\)$$) is $$\\(\\overline{x}\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~sample}}{\\text{Number~of~values~in~the~sample}}\\)$$, and the mean for a population (denoted by \u03bc) is $$\\(\\mu\\text{~=~}\\frac{\\text{Sum~of~all~values~in~the~population}}{\\text{Number~of~values~in~the~population}}\\)$$."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation; notation: \u03a7 ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called a  standard normal distribution."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x)\\text{~=~}\\frac{1}{\\sigma\\sqrt{2\\pi}}~e^{\\frac{\u2013{\\text{(}x\\ \u2013\\ \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation.; notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "Sampling Distribution",
                    "description": "Given simple random samples of size n from a given population with a measured characteristic such as mean, proportion, or standard deviation for each sample, the probability distribution of all the measured characteristics is called a sampling distribution."
                },
                {
                    "name": "Uniform Distribution",
                    "description": "a continuous random variable (RV) that has equally likely outcomes over the domain, a < x < b; often referred as the  Rectangular Distribution because the graph of the pdf has the form of a rectangle. Notation: X ~ U(a, b). The mean is $$\\(\\mu\\text{~=~}\\frac{a\\text{~+~}b}{2}\\)$$ and the standard deviation is $$\\(\\sigma\\text{~=~}\\sqrt{\\frac{{(b\u2013\\text{a)}}^{2}}{12}}\\)$$. The probability density function is $$\\(f(x)\\text{~=~}\\frac{1}{b\u2013a}\\)$$ for a < x < b or a \u2264 x \u2264 b. The cumulative distribution is P(X \u2264 x) = $$\\(\\frac{x\u2013\\text{a}}{b\u2013\\text{a}}\\)$$."
                }
            ]
        },
        {
            "title": "8-1-a-single-population-mean-using-the-normal-distribution",
            "paragraphs": [
                {
                    "context": "To construct a confidence interval for a single unknown population mean \u03bc, where the population standard deviation is known, we need $$\\(\\overline{x}\\)$$ as an estimate for \u03bc and we need the margin of error. Here, the margin of error (EBM) is called the error bound for a population mean (abbreviated EBM). The sample mean $$\\(\\overline{x}\\)$$ is the point estimate of the unknown population mean \u03bc.\n\nThe confidence interval estimate will have the form:\n\n(point estimate - error bound, point estimate + error bound) or, in symbols,($$\\(\\overline{x}\u2013EBM,\\overline{x}\\text{+}EBM\\)$$)\n\nThe margin of error (EBM) depends on the confidence level (abbreviated CL). The confidence level is often considered the probability that the calculated confidence interval estimate will contain the true population parameter. However, it is more accurate to state that the confidence level is the percent of confidence intervals that contain the true population parameter when repeated samples are taken. Most often, it is the choice of the person constructing the confidence interval to choose a confidence level of 90% or higher because that person wants to be reasonably certain of his or her conclusions.\n\nThere is another probability called alpha (\u03b1). \u03b1 is related to the confidence level, CL. \u03b1 is the probability that the interval does not contain the unknown population parameter.    Mathematically, \u03b1 + CL = 1.\n\nA confidence interval for a population mean with a known standard deviation is based on the fact that the sample means follow an approximately normal distribution. Suppose that our sample has a mean of $$\\(\\overline{x}\\)$$ = 10, and we have constructed the 90% confidence interval (5, 15) where EBM = 5.\n\nTo get a 90% confidence interval, we must include the central 90% of the probability of the normal distribution. If we include the central 90%, we leave out a total of \u03b1 = 10% in both tails, or 5% in each tail, of the normal distribution.\n\nTo capture the central 90%, we must go out 1.645 \"standard deviations\" on either side of the calculated sample mean. The value 1.645 is the z-score from a standard normal probability distribution that puts an area of 0.90 in the center, an area of 0.05 in the far left tail, and an area of 0.05 in the far right tail.\n\nIt is important that the \"standard deviation\" used must be appropriate for the parameter we are estimating, so in this section we need to use the standard deviation that applies to sample means, which is $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$. The fraction $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is commonly called the \"standard error of the mean\" in order to distinguish clearly the standard deviation for a mean from the population standard deviation \u03c3.",
                    "id": "C_524482_0"
                }
            ],
            "section_title": "Calculating the Confidence Interval",
            "chapter_learning_objectives": [],
            "chapter_summary": "In this module, we learned how to calculate the confidence interval for a single population mean where the population standard deviation is known. When estimating a population mean, the margin of error is called the error bound for a population mean (EBM). A confidence interval has the general form:(lower bound, upper bound) = (point estimate \u2013 EBM, point estimate + EBM)The calculation of EBM depends on the size of the sample and the level of confidence desired. The confidence level is the percent of all possible samples that can be expected to include the true population parameter. As the confidence level increases, the corresponding EBM increases as well. As the sample size increases, the EBM decreases. By the central limit theorem,$$\\(EBM = z\\frac{\\sigma}{\\sqrt{n}}\\)$$Given a confidence interval, you can work backwards to find the error bound (EBM) or the sample mean. To find the error bound, find the difference of the upper bound of the interval and the mean. If you do not know the sample mean, you can find the error bound by calculating half the difference of the upper and lower bounds.  To find the sample mean given a confidence interval, find the difference of the upper bound and the error bound. If the error bound is unknown, then average the upper and lower bounds of the confidence interval to find the sample mean.Sometimes researchers know in advance that they want to estimate a population mean within a specific margin of error for a given level of confidence. In that case, solve the EBM formula for n to discover the size of the sample that is needed to achieve this goal:$$\\(n = ~\\frac{z^{2}\\sigma^{2}}{EBM^{2}}\\)$$",
            "chapter_introduction": "A confidence interval for a population mean, when the population standard deviation is known, is based on the conclusion of the Central Limit Theorem that the sampling distribution of the sample means follow an approximately normal distribution. Suppose that our sample has a mean of $$\\(\\overline{x}\\text{~=~10}\\)$$ and we have constructed the 90% confidence interval (5, 15) where EBM = 5. ",
            "bold_terms": [
                "where the population standard deviation is known",
                "error bound for a population mean",
                "EBM",
                "point estimate",
                "The confidence interval estimate will have the form",
                "confidence level",
                "CL",
                "population mean"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "8-1-a-single-population-mean-using-the-normal-distribution",
            "paragraphs": [
                {
                    "context": "To construct a confidence interval estimate for an unknown population mean, we need data from a random sample.  The steps to construct and interpret the confidence interval are:\n\n Calculate the sample mean $$\\(\\overline{x}\\)$$ from the sample data. Remember, in this section we already know the population standard deviation  \u03c3. Find the z-score that corresponds to the confidence level. Calculate the error bound EBM. Construct the confidence interval. Write a sentence that interprets the estimate in the context of the situation in the problem. (Explain what the confidence interval means, in the words of the problem.) \n\nWe will first examine each step in more detail, and then illustrate the process with some examples.",
                    "id": "C_696832_1"
                }
            ],
            "section_title": "Calculating the Confidence Interval",
            "chapter_learning_objectives": [],
            "chapter_summary": "In this module, we learned how to calculate the confidence interval for a single population mean where the population standard deviation is known. When estimating a population mean, the margin of error is called the error bound for a population mean (EBM). A confidence interval has the general form:(lower bound, upper bound) = (point estimate \u2013 EBM, point estimate + EBM)The calculation of EBM depends on the size of the sample and the level of confidence desired. The confidence level is the percent of all possible samples that can be expected to include the true population parameter. As the confidence level increases, the corresponding EBM increases as well. As the sample size increases, the EBM decreases. By the central limit theorem,$$\\(EBM = z\\frac{\\sigma}{\\sqrt{n}}\\)$$Given a confidence interval, you can work backwards to find the error bound (EBM) or the sample mean. To find the error bound, find the difference of the upper bound of the interval and the mean. If you do not know the sample mean, you can find the error bound by calculating half the difference of the upper and lower bounds.  To find the sample mean given a confidence interval, find the difference of the upper bound and the error bound. If the error bound is unknown, then average the upper and lower bounds of the confidence interval to find the sample mean.Sometimes researchers know in advance that they want to estimate a population mean within a specific margin of error for a given level of confidence. In that case, solve the EBM formula for n to discover the size of the sample that is needed to achieve this goal:$$\\(n = ~\\frac{z^{2}\\sigma^{2}}{EBM^{2}}\\)$$",
            "chapter_introduction": "A confidence interval for a population mean, when the population standard deviation is known, is based on the conclusion of the Central Limit Theorem that the sampling distribution of the sample means follow an approximately normal distribution. Suppose that our sample has a mean of $$\\(\\overline{x}\\text{~=~10}\\)$$ and we have constructed the 90% confidence interval (5, 15) where EBM = 5. ",
            "bold_terms": [
                "where the population standard deviation is known",
                "error bound for a population mean",
                "EBM",
                "point estimate",
                "The confidence interval estimate will have the form",
                "confidence level",
                "CL",
                "population mean"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "8-1-a-single-population-mean-using-the-normal-distribution",
            "paragraphs": [
                {
                    "context": "When we know the population standard deviation \u03c3, we use a standard normal distribution to calculate the error bound EBM and construct the confidence interval. We need to find the value of z that puts an area equal to the confidence level (in decimal form) in the middle of the standard normal distribution Z ~ N(0, 1).\n\nThe confidence level, CL, is the area in the middle of the standard normal distribution. CL = 1 \u2013 \u03b1, so \u03b1 is the area that is split equally between the two tails. Each of the tails contains an area equal to $$\\(\\frac{\\alpha}{2}\\)$$.\n\nThe z-score that has an area to the right of $$\\(\\frac{\\alpha}{2}\\)$$ is denoted by $$\\(z_{\\frac{\\alpha}{2}}\\)$$.\n\nFor example, when CL = 0.95, \u03b1 = 0.05 and $$\\(\\frac{\\alpha}{2}\\)$$ = 0.025; we write $$\\(z_{\\frac{\\alpha}{2}}\\)$$ = z0.025.\n\nThe area to the right of z0.025 is 0.025 and the area to the left of z0.025 is 1 \u2013 0.025 = 0.975.\n\n$$\\(z_{\\frac{\\alpha}{2}}\\text{~=~}z_{0.\\text{025}}\\text{~=~1}\\text{.96}\\)$$, using a calculator, computer or a standard normal probability table.",
                    "id": "C_954607_2"
                }
            ],
            "section_title": "Finding the z-score for the Stated Confidence Level",
            "chapter_learning_objectives": [],
            "chapter_summary": "In this module, we learned how to calculate the confidence interval for a single population mean where the population standard deviation is known. When estimating a population mean, the margin of error is called the error bound for a population mean (EBM). A confidence interval has the general form:(lower bound, upper bound) = (point estimate \u2013 EBM, point estimate + EBM)The calculation of EBM depends on the size of the sample and the level of confidence desired. The confidence level is the percent of all possible samples that can be expected to include the true population parameter. As the confidence level increases, the corresponding EBM increases as well. As the sample size increases, the EBM decreases. By the central limit theorem,$$\\(EBM = z\\frac{\\sigma}{\\sqrt{n}}\\)$$Given a confidence interval, you can work backwards to find the error bound (EBM) or the sample mean. To find the error bound, find the difference of the upper bound of the interval and the mean. If you do not know the sample mean, you can find the error bound by calculating half the difference of the upper and lower bounds.  To find the sample mean given a confidence interval, find the difference of the upper bound and the error bound. If the error bound is unknown, then average the upper and lower bounds of the confidence interval to find the sample mean.Sometimes researchers know in advance that they want to estimate a population mean within a specific margin of error for a given level of confidence. In that case, solve the EBM formula for n to discover the size of the sample that is needed to achieve this goal:$$\\(n = ~\\frac{z^{2}\\sigma^{2}}{EBM^{2}}\\)$$",
            "chapter_introduction": "A confidence interval for a population mean, when the population standard deviation is known, is based on the conclusion of the Central Limit Theorem that the sampling distribution of the sample means follow an approximately normal distribution. Suppose that our sample has a mean of $$\\(\\overline{x}\\text{~=~10}\\)$$ and we have constructed the 90% confidence interval (5, 15) where EBM = 5. ",
            "bold_terms": [
                "where the population standard deviation is known",
                "error bound for a population mean",
                "EBM",
                "point estimate",
                "The confidence interval estimate will have the form",
                "confidence level",
                "CL",
                "population mean"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "8-1-a-single-population-mean-using-the-normal-distribution",
            "paragraphs": [
                {
                    "context": "invNorm(0.975, 0, 1) = 1.96",
                    "id": "C_425641_3"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "In this module, we learned how to calculate the confidence interval for a single population mean where the population standard deviation is known. When estimating a population mean, the margin of error is called the error bound for a population mean (EBM). A confidence interval has the general form:(lower bound, upper bound) = (point estimate \u2013 EBM, point estimate + EBM)The calculation of EBM depends on the size of the sample and the level of confidence desired. The confidence level is the percent of all possible samples that can be expected to include the true population parameter. As the confidence level increases, the corresponding EBM increases as well. As the sample size increases, the EBM decreases. By the central limit theorem,$$\\(EBM = z\\frac{\\sigma}{\\sqrt{n}}\\)$$Given a confidence interval, you can work backwards to find the error bound (EBM) or the sample mean. To find the error bound, find the difference of the upper bound of the interval and the mean. If you do not know the sample mean, you can find the error bound by calculating half the difference of the upper and lower bounds.  To find the sample mean given a confidence interval, find the difference of the upper bound and the error bound. If the error bound is unknown, then average the upper and lower bounds of the confidence interval to find the sample mean.Sometimes researchers know in advance that they want to estimate a population mean within a specific margin of error for a given level of confidence. In that case, solve the EBM formula for n to discover the size of the sample that is needed to achieve this goal:$$\\(n = ~\\frac{z^{2}\\sigma^{2}}{EBM^{2}}\\)$$",
            "chapter_introduction": "A confidence interval for a population mean, when the population standard deviation is known, is based on the conclusion of the Central Limit Theorem that the sampling distribution of the sample means follow an approximately normal distribution. Suppose that our sample has a mean of $$\\(\\overline{x}\\text{~=~10}\\)$$ and we have constructed the 90% confidence interval (5, 15) where EBM = 5. ",
            "bold_terms": [
                "where the population standard deviation is known",
                "error bound for a population mean",
                "EBM",
                "point estimate",
                "The confidence interval estimate will have the form",
                "confidence level",
                "CL",
                "population mean"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "8-1-a-single-population-mean-using-the-normal-distribution",
            "paragraphs": [
                {
                    "context": "Remember to use the area to the LEFT of $$\\(z_{\\frac{\\alpha}{2}}\\)$$; in this chapter the last two inputs in the invNorm command are 0, 1, because you are using a standard normal distribution Z ~ N(0, 1).",
                    "id": "C_399335_4"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "In this module, we learned how to calculate the confidence interval for a single population mean where the population standard deviation is known. When estimating a population mean, the margin of error is called the error bound for a population mean (EBM). A confidence interval has the general form:(lower bound, upper bound) = (point estimate \u2013 EBM, point estimate + EBM)The calculation of EBM depends on the size of the sample and the level of confidence desired. The confidence level is the percent of all possible samples that can be expected to include the true population parameter. As the confidence level increases, the corresponding EBM increases as well. As the sample size increases, the EBM decreases. By the central limit theorem,$$\\(EBM = z\\frac{\\sigma}{\\sqrt{n}}\\)$$Given a confidence interval, you can work backwards to find the error bound (EBM) or the sample mean. To find the error bound, find the difference of the upper bound of the interval and the mean. If you do not know the sample mean, you can find the error bound by calculating half the difference of the upper and lower bounds.  To find the sample mean given a confidence interval, find the difference of the upper bound and the error bound. If the error bound is unknown, then average the upper and lower bounds of the confidence interval to find the sample mean.Sometimes researchers know in advance that they want to estimate a population mean within a specific margin of error for a given level of confidence. In that case, solve the EBM formula for n to discover the size of the sample that is needed to achieve this goal:$$\\(n = ~\\frac{z^{2}\\sigma^{2}}{EBM^{2}}\\)$$",
            "chapter_introduction": "A confidence interval for a population mean, when the population standard deviation is known, is based on the conclusion of the Central Limit Theorem that the sampling distribution of the sample means follow an approximately normal distribution. Suppose that our sample has a mean of $$\\(\\overline{x}\\text{~=~10}\\)$$ and we have constructed the 90% confidence interval (5, 15) where EBM = 5. ",
            "bold_terms": [
                "where the population standard deviation is known",
                "error bound for a population mean",
                "EBM",
                "point estimate",
                "The confidence interval estimate will have the form",
                "confidence level",
                "CL",
                "population mean"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "8-1-a-single-population-mean-using-the-normal-distribution",
            "paragraphs": [
                {
                    "context": "The error bound formula for an unknown population mean \u03bc when the population standard deviation \u03c3 is known is\n\nEBM = $$\\(\\left( z_{\\frac{\\alpha}{2}} \\right)\\left( \\frac{\\sigma}{\\sqrt{n}} \\right)\\)$$ ",
                    "id": "C_700601_5"
                }
            ],
            "section_title": "Calculating the Error Bound (EBM",
            "chapter_learning_objectives": [],
            "chapter_summary": "In this module, we learned how to calculate the confidence interval for a single population mean where the population standard deviation is known. When estimating a population mean, the margin of error is called the error bound for a population mean (EBM). A confidence interval has the general form:(lower bound, upper bound) = (point estimate \u2013 EBM, point estimate + EBM)The calculation of EBM depends on the size of the sample and the level of confidence desired. The confidence level is the percent of all possible samples that can be expected to include the true population parameter. As the confidence level increases, the corresponding EBM increases as well. As the sample size increases, the EBM decreases. By the central limit theorem,$$\\(EBM = z\\frac{\\sigma}{\\sqrt{n}}\\)$$Given a confidence interval, you can work backwards to find the error bound (EBM) or the sample mean. To find the error bound, find the difference of the upper bound of the interval and the mean. If you do not know the sample mean, you can find the error bound by calculating half the difference of the upper and lower bounds.  To find the sample mean given a confidence interval, find the difference of the upper bound and the error bound. If the error bound is unknown, then average the upper and lower bounds of the confidence interval to find the sample mean.Sometimes researchers know in advance that they want to estimate a population mean within a specific margin of error for a given level of confidence. In that case, solve the EBM formula for n to discover the size of the sample that is needed to achieve this goal:$$\\(n = ~\\frac{z^{2}\\sigma^{2}}{EBM^{2}}\\)$$",
            "chapter_introduction": "A confidence interval for a population mean, when the population standard deviation is known, is based on the conclusion of the Central Limit Theorem that the sampling distribution of the sample means follow an approximately normal distribution. Suppose that our sample has a mean of $$\\(\\overline{x}\\text{~=~10}\\)$$ and we have constructed the 90% confidence interval (5, 15) where EBM = 5. ",
            "bold_terms": [
                "where the population standard deviation is known",
                "error bound for a population mean",
                "EBM",
                "point estimate",
                "The confidence interval estimate will have the form",
                "confidence level",
                "CL",
                "population mean"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "8-1-a-single-population-mean-using-the-normal-distribution",
            "paragraphs": [
                {
                    "context": "The confidence interval estimate has the format    $$\\((\\overline{x}\u2013EBM,\\overline{x} + EBM)\\)$$. \n\nThe graph gives a picture of the entire situation.\n\nCL + $$\\(\\frac{\\alpha}{2}\\)$$ + $$\\(\\frac{\\alpha}{2}\\)$$ = CL + \u03b1 = 1.",
                    "id": "C_681618_6"
                }
            ],
            "section_title": "Constructing the Confidence Interval",
            "chapter_learning_objectives": [],
            "chapter_summary": "In this module, we learned how to calculate the confidence interval for a single population mean where the population standard deviation is known. When estimating a population mean, the margin of error is called the error bound for a population mean (EBM). A confidence interval has the general form:(lower bound, upper bound) = (point estimate \u2013 EBM, point estimate + EBM)The calculation of EBM depends on the size of the sample and the level of confidence desired. The confidence level is the percent of all possible samples that can be expected to include the true population parameter. As the confidence level increases, the corresponding EBM increases as well. As the sample size increases, the EBM decreases. By the central limit theorem,$$\\(EBM = z\\frac{\\sigma}{\\sqrt{n}}\\)$$Given a confidence interval, you can work backwards to find the error bound (EBM) or the sample mean. To find the error bound, find the difference of the upper bound of the interval and the mean. If you do not know the sample mean, you can find the error bound by calculating half the difference of the upper and lower bounds.  To find the sample mean given a confidence interval, find the difference of the upper bound and the error bound. If the error bound is unknown, then average the upper and lower bounds of the confidence interval to find the sample mean.Sometimes researchers know in advance that they want to estimate a population mean within a specific margin of error for a given level of confidence. In that case, solve the EBM formula for n to discover the size of the sample that is needed to achieve this goal:$$\\(n = ~\\frac{z^{2}\\sigma^{2}}{EBM^{2}}\\)$$",
            "chapter_introduction": "A confidence interval for a population mean, when the population standard deviation is known, is based on the conclusion of the Central Limit Theorem that the sampling distribution of the sample means follow an approximately normal distribution. Suppose that our sample has a mean of $$\\(\\overline{x}\\text{~=~10}\\)$$ and we have constructed the 90% confidence interval (5, 15) where EBM = 5. ",
            "bold_terms": [
                "where the population standard deviation is known",
                "error bound for a population mean",
                "EBM",
                "point estimate",
                "The confidence interval estimate will have the form",
                "confidence level",
                "CL",
                "population mean"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "8-1-a-single-population-mean-using-the-normal-distribution",
            "paragraphs": [
                {
                    "context": "The interpretation should clearly state the confidence level (CL), explain what population parameter is being estimated (here, a population mean), and state the confidence interval (both endpoints). \"We estimate with ___% confidence that the true population mean (include the context of the problem) is between ___ and ___ (include appropriate units).\"\n\nNotice the difference in the confidence intervals calculated in Example 8.3 and the following Try It exercise. These intervals are different for several reasons: they were calculated from different samples, the samples were different sizes, and the intervals were calculated for different levels of confidence. Even though the intervals are different, they do not yield conflicting information. The effects of these kinds of changes are the subject of the next section in this chapter.",
                    "id": "C_715595_7"
                }
            ],
            "section_title": "Writing the Interpretation",
            "chapter_learning_objectives": [],
            "chapter_summary": "In this module, we learned how to calculate the confidence interval for a single population mean where the population standard deviation is known. When estimating a population mean, the margin of error is called the error bound for a population mean (EBM). A confidence interval has the general form:(lower bound, upper bound) = (point estimate \u2013 EBM, point estimate + EBM)The calculation of EBM depends on the size of the sample and the level of confidence desired. The confidence level is the percent of all possible samples that can be expected to include the true population parameter. As the confidence level increases, the corresponding EBM increases as well. As the sample size increases, the EBM decreases. By the central limit theorem,$$\\(EBM = z\\frac{\\sigma}{\\sqrt{n}}\\)$$Given a confidence interval, you can work backwards to find the error bound (EBM) or the sample mean. To find the error bound, find the difference of the upper bound of the interval and the mean. If you do not know the sample mean, you can find the error bound by calculating half the difference of the upper and lower bounds.  To find the sample mean given a confidence interval, find the difference of the upper bound and the error bound. If the error bound is unknown, then average the upper and lower bounds of the confidence interval to find the sample mean.Sometimes researchers know in advance that they want to estimate a population mean within a specific margin of error for a given level of confidence. In that case, solve the EBM formula for n to discover the size of the sample that is needed to achieve this goal:$$\\(n = ~\\frac{z^{2}\\sigma^{2}}{EBM^{2}}\\)$$",
            "chapter_introduction": "A confidence interval for a population mean, when the population standard deviation is known, is based on the conclusion of the Central Limit Theorem that the sampling distribution of the sample means follow an approximately normal distribution. Suppose that our sample has a mean of $$\\(\\overline{x}\\text{~=~10}\\)$$ and we have constructed the 90% confidence interval (5, 15) where EBM = 5. ",
            "bold_terms": [
                "where the population standard deviation is known",
                "error bound for a population mean",
                "EBM",
                "point estimate",
                "The confidence interval estimate will have the form",
                "confidence level",
                "CL",
                "population mean"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "8-1-a-single-population-mean-using-the-normal-distribution",
            "paragraphs": [
                {
                    "context": "When we calculate a confidence interval, we find the sample mean, calculate the error bound, and use them to calculate the confidence interval. However, sometimes when we read statistical studies, the study may state the confidence interval only. If we know the confidence interval, we can work backwards to find both the error bound and the sample mean.\n\nNotice that there are two methods to perform each calculation. You can choose the method that is easier to use with the information you know.",
                    "id": "C_448929_9"
                }
            ],
            "section_title": "Working Backwards to Find the Error Bound or Sample Mean",
            "chapter_learning_objectives": [],
            "chapter_summary": "In this module, we learned how to calculate the confidence interval for a single population mean where the population standard deviation is known. When estimating a population mean, the margin of error is called the error bound for a population mean (EBM). A confidence interval has the general form:(lower bound, upper bound) = (point estimate \u2013 EBM, point estimate + EBM)The calculation of EBM depends on the size of the sample and the level of confidence desired. The confidence level is the percent of all possible samples that can be expected to include the true population parameter. As the confidence level increases, the corresponding EBM increases as well. As the sample size increases, the EBM decreases. By the central limit theorem,$$\\(EBM = z\\frac{\\sigma}{\\sqrt{n}}\\)$$Given a confidence interval, you can work backwards to find the error bound (EBM) or the sample mean. To find the error bound, find the difference of the upper bound of the interval and the mean. If you do not know the sample mean, you can find the error bound by calculating half the difference of the upper and lower bounds.  To find the sample mean given a confidence interval, find the difference of the upper bound and the error bound. If the error bound is unknown, then average the upper and lower bounds of the confidence interval to find the sample mean.Sometimes researchers know in advance that they want to estimate a population mean within a specific margin of error for a given level of confidence. In that case, solve the EBM formula for n to discover the size of the sample that is needed to achieve this goal:$$\\(n = ~\\frac{z^{2}\\sigma^{2}}{EBM^{2}}\\)$$",
            "chapter_introduction": "A confidence interval for a population mean, when the population standard deviation is known, is based on the conclusion of the Central Limit Theorem that the sampling distribution of the sample means follow an approximately normal distribution. Suppose that our sample has a mean of $$\\(\\overline{x}\\text{~=~10}\\)$$ and we have constructed the 90% confidence interval (5, 15) where EBM = 5. ",
            "bold_terms": [
                "where the population standard deviation is known",
                "error bound for a population mean",
                "EBM",
                "point estimate",
                "The confidence interval estimate will have the form",
                "confidence level",
                "CL",
                "population mean"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "8-1-a-single-population-mean-using-the-normal-distribution",
            "paragraphs": [
                {
                    "context": "If researchers desire a specific margin of error, then they can use the error bound formula to calculate the required sample size.\n\nThe error bound formula for a population mean when the population standard deviation is known is EBM = $$\\(\\left( z_{\\frac{\\alpha}{2}} \\right)\\left( \\frac{\\sigma}{\\sqrt{n}} \\right)\\)$$.\n\nThe formula for sample size is n = $$\\(\\frac{z^{2}\\sigma^{2}}{EBM^{2}}\\)$$, found by solving the error bound formula for n.\n\nIn this formula, z is $$\\(z_{\\frac{\\alpha}{2}}\\)$$, corresponding to the desired confidence level. A researcher planning a study who wants a specified confidence level and error bound can use this formula to calculate the size of the sample needed for the study.",
                    "id": "C_251761_10"
                }
            ],
            "section_title": "Calculating the Sample Size n",
            "chapter_learning_objectives": [],
            "chapter_summary": "In this module, we learned how to calculate the confidence interval for a single population mean where the population standard deviation is known. When estimating a population mean, the margin of error is called the error bound for a population mean (EBM). A confidence interval has the general form:(lower bound, upper bound) = (point estimate \u2013 EBM, point estimate + EBM)The calculation of EBM depends on the size of the sample and the level of confidence desired. The confidence level is the percent of all possible samples that can be expected to include the true population parameter. As the confidence level increases, the corresponding EBM increases as well. As the sample size increases, the EBM decreases. By the central limit theorem,$$\\(EBM = z\\frac{\\sigma}{\\sqrt{n}}\\)$$Given a confidence interval, you can work backwards to find the error bound (EBM) or the sample mean. To find the error bound, find the difference of the upper bound of the interval and the mean. If you do not know the sample mean, you can find the error bound by calculating half the difference of the upper and lower bounds.  To find the sample mean given a confidence interval, find the difference of the upper bound and the error bound. If the error bound is unknown, then average the upper and lower bounds of the confidence interval to find the sample mean.Sometimes researchers know in advance that they want to estimate a population mean within a specific margin of error for a given level of confidence. In that case, solve the EBM formula for n to discover the size of the sample that is needed to achieve this goal:$$\\(n = ~\\frac{z^{2}\\sigma^{2}}{EBM^{2}}\\)$$",
            "chapter_introduction": "A confidence interval for a population mean, when the population standard deviation is known, is based on the conclusion of the Central Limit Theorem that the sampling distribution of the sample means follow an approximately normal distribution. Suppose that our sample has a mean of $$\\(\\overline{x}\\text{~=~10}\\)$$ and we have constructed the 90% confidence interval (5, 15) where EBM = 5. ",
            "bold_terms": [
                "where the population standard deviation is known",
                "error bound for a population mean",
                "EBM",
                "point estimate",
                "The confidence interval estimate will have the form",
                "confidence level",
                "CL",
                "population mean"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "8-2-a-single-population-mean-using-the-student-t-distribution",
            "paragraphs": [
                {
                    "context": "To calculate the confidence interval directly:Press STAT.Arrow over to TESTS.Arrow down to 8:TInterval and press ENTER (or just press 8).",
                    "id": "C_897801_0"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "In many cases, the researcher does not know the population standard deviation, \u03c3, of the measure being studied. In these cases, it is common to use the sample standard deviation, s, as an estimate of \u03c3. The normal distribution creates accurate confidence intervals when \u03c3 is known, but it is not as accurate when s is used as an estimate. In this case, the Student\u2019s t-distribution is much better. Define a t-score using the following formula:$$\\(t = ~\\frac{\\overline{x} - ~\\mu}{\\frac{s}{\\sqrt{n}}}\\)$$The t-score follows the Student\u2019s t-distribution with n \u2013 1 degrees of freedom. The confidence interval under this distribution is calculated with EBM = $$\\(\\left( t_{\\frac{\\alpha}{2}} \\right)\\frac{s}{\\sqrt{n}}\\)$$ where $$\\(t_{\\frac{\\alpha}{2}}\\)$$ is the t-score with area to the right equal to $$\\(\\frac{\\alpha}{2}\\)$$, s is the sample standard deviation, and n is the sample size. Use a table, calculator, or computer to find $$\\(t_{\\frac{\\alpha}{2}}\\)$$ for a given \u03b1.",
            "chapter_introduction": "In practice, we rarely know the population standard deviation. In the past, when the sample size was large, this did not present a problem to statisticians. They used the sample standard deviation s as an estimate for \u03c3 and proceeded as before to calculate a confidence interval with close enough results. However, statisticians ran into problems when the sample size was small. A small sample size caused inaccuracies in the confidence interval. \n\nWilliam S. Gosset (1876\u20131937) of the Guinness brewery in Dublin, Ireland ran into this  problem. His experiments with hops and barley produced very few samples. Just replacing \u03c3 with s did not produce accurate results when he tried to calculate a confidence interval. He realized that he could not use a normal distribution for the calculation; he found that the actual distribution depends on the sample size. This problem led him to \"discover\" what is called the Student's t-distribution. The name comes from the fact that Gosset wrote under the pen name \"Student.\"\n\nUp until the mid-1970s, some statisticians used the normal distribution approximation for large sample sizes and used the Student's t-distribution only for sample sizes of at most 30. With graphing calculators and computers, the practice now is to use the Student's t-distribution whenever s is used as an estimate for \u03c3.\n\nIf you draw a simple random sample of size n from a population that has an approximately normal distribution with mean \u03bc and unknown population standard deviation \u03c3 and calculate the t-score t = $$\\(\\frac{\\overline{x}\u2013\\mu}{\\left( \\frac{s}{\\sqrt{n}} \\right)}\\)$$, then the t-scores follow a Student's t-distribution with n \u2013 1 degrees of freedom. The t-score has the same interpretation as the z-score. It measures how far $$\\(\\overline{x}\\)$$ is from its mean \u03bc. For each sample size n, there is a different Student's t-distribution.\n\nThe degrees of freedom, n \u2013 1, come from the calculation of the sample standard deviation s. In Appendix H Tables, we used n deviations $$\\((x\u2013\\overline{x}\\text{values})\\)$$ to calculate s. Because the sum of the deviations is zero, we can find the last deviation once we know the other n \u2013 1 deviations. The other n \u2013 1 deviations can change or vary freely. We call the number n \u2013 1 the degrees of freedom (df).\n\nCalculators and computers can easily calculate any Student's t-probabilities. The TI-83,83+, and 84+ have a tcdf function to find the probability for given values of t. The grammar for the tcdf command is tcdf(lower bound, upper bound, degrees of freedom). However for confidence intervals, we need to use inverse probability to find the value of t when we know the probability.\n\nFor the TI-84+ you can use the invT command on the DISTRibution menu. The invT command works similarly to the invnorm. The invT command requires two inputs:  invT(area to the left, degrees of freedom) The output is the t-score that corresponds to the area we specified.  The TI-83 and 83+ do not have the invT command. (The TI-89 has an inverse T command.)\n\nA probability table for the Student's t-distribution can also be used.  The table gives t-scores that correspond to the confidence level (column) and degrees of freedom (row). (The TI-86 does not have an invT program or command, so if you are using that calculator, you need to use a probability table for the Student's t-Distribution.) When using a t-table, note that some tables are formatted to show the confidence level in the column headings, while the column headings in some tables may show only corresponding area in one or both tails.A Student's t table (See Appendix H Tables) gives t-scores given the degrees of freedom and the right-tailed probability. The table is very limited. Calculators and computers can easily calculate any Student's  t-probabilities.\n\nIf the population standard deviation is  not known,  the error bound for a population mean is:\n\n$$\\(EBM = \\left( t_{\\frac{\\alpha}{2}} \\right)\\left( \\frac{s}{\\sqrt{n}} \\right)\\)$$, $$\\(t_{\\frac{\\sigma}{2}}\\)$$ is the t-score with area to the right equal to $$\\(\\frac{\\alpha}{2}\\)$$, use df = n \u2013 1 degrees of freedom, and s = sample standard deviation. \n\nThe format for the confidence interval is:$$\\((\\overline{x} - EBM,\\overline{x} + EBM)\\)$$.",
            "bold_terms": [
                "standard deviation",
                "confidence interval",
                "Student's t-distribution",
                "normal distribution",
                "Student's t-distribution with n \u2013 1 degrees of freedom",
                "z-score",
                "degrees of freedom",
                "n \u2013 1",
                "We call the number n \u2013 1 the degrees of freedom (df",
                "inverse",
                "invT(area to the left, degrees of freedom",
                "Calculators and computers can easily calculate any Student's  t-probabilities",
                "If the population standard deviation is  not known",
                "error bound for a population mean",
                "The format for the confidence interval is"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "8-3-a-population-proportion",
            "paragraphs": [
                {
                    "context": "For the normal distribution of proportions, the z-score formula is as follows.\n\nIf $$\\(P^{\\prime}\\text{\\textasciitilde}N\\left( {p,\\sqrt{\\frac{pq}{n}}} \\right)\\)$$ then the z-score formula is $$\\(z = \\frac{p^{\\prime} - p}{\\sqrt{\\frac{pq}{n}}}\\)$$",
                    "id": "C_494794_0"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "Some statistical measures, like many survey questions, measure qualitative rather than quantitative data. In this case, the population parameter being estimated is a proportion. It is possible to create a confidence interval for the true population proportion following procedures similar to those used in creating confidence intervals for population means. The formulas are slightly different, but they follow the same reasoning.Let p\u2032 represent the sample proportion, x/n, where x represents the number of successes and n represents the sample size. Let q\u2032 = 1 \u2013 p\u2032. Then the confidence interval for a population proportion is given by the following formula:(lower bound, upper bound) $$\\(= (p^{\\prime}\u2013EBP,p^{\\prime}~ + EBP) = ~\\left( {p^{\\prime}\u2013z\\sqrt{\\frac{p^{\\prime}q^{\\prime}}{n}},p^{\\prime} + z\\sqrt{\\frac{p^{\\prime}q^{\\prime}}{n}}} \\right)\\)$$The \u201cplus four\u201d method for calculating confidence intervals is an attempt to balance the error introduced by using estimates of the population proportion when calculating the standard deviation of the sampling distribution. Simply imagine four additional trials in the study; two are successes and two are failures. Calculate $$\\(p^{\\prime} = \\frac{x + 2}{n + 4}\\)$$, and proceed to find the confidence interval. When sample sizes are small, this method has been demonstrated to provide more accurate confidence intervals than the standard formula used for larger samples.",
            "chapter_introduction": "During an election year, we see articles in the newspaper that state confidence intervals in terms of proportions or percentages. For example, a poll for a particular candidate running for president might show that the candidate has 40% of the vote within three percentage points  (if the sample is large enough). Often, election polls are calculated with 95% confidence, so, the pollsters would be 95% confident that the true proportion of voters who favored the candidate would be between 0.37 and 0.43: (0.40 \u2013 0.03,0.40 + 0.03).\n\nInvestors in the stock market are interested in the true proportion of stocks that go up and down each week. Businesses that sell personal computers are interested in the proportion of households in the United States that own personal computers. Confidence intervals can be calculated for the true proportion of stocks that go up or down each week and for the true proportion of households in the United States that own personal computers.\n\nThe procedure to find the confidence interval, the sample size, the error bound, and the confidence level for a proportion is similar to that for the population mean, but the formulas are different.\n\nHow do you know you are dealing with a proportion problem? First, the underlying distribution is a binomial distribution. (There is no mention of a mean or average.) If X is a binomial random variable, then X ~ B(n, p)  where n is the number of trials and p is the probability of a success. To form a proportion, take X, the random variable for the number of successes and divide it by n, the number of trials (or the sample size). The random variable P\u2032 (read \"P prime\") is that proportion,  \n\n$$\\(P^{\\prime} = \\frac{X}{n}\\)$$\n\n(Sometimes the random variable is denoted as $$\\(\\hat{P}\\)$$, read \"P hat\".)\n\nWhen n is large and p is not close to zero or one, we can use the normal distribution to approximate the binomial.\n\n$$\\(\\left. X \\right.\\sim N(np,\\sqrt{npq})\\)$$\n\nIf we divide the random variable, the mean, and the standarddeviation by n, we get a normal distribution of proportions with P\u2032, called theestimated proportion, as the random variable. (Recall that a proportion as thenumber of successes divided by n.)\n\n$$\\(\\frac{X}{n} = P^{\\prime}\\text{\\textasciitilde~}N\\left( {\\frac{np}{n},\\frac{\\sqrt{npq}}{n}} \\right)\\)$$\n\nUsing algebra to simplify : $$\\(\\frac{\\sqrt{npq}}{n} = \\sqrt{\\frac{pq}{n}}\\)$$\n\nP\u2032 follows a normal distribution for proportions:  $$\\(\\frac{X}{n} = P^{\\prime}\\text{\\textasciitilde~}N\\left( {\\frac{np}{n},\\frac{\\sqrt{npq}}{n}} \\right)\\)$$\n\nThe confidence interval has the form (p\u2032 \u2013 EBP, p\u2032 + EBP). EBP is error bound for the proportion.\n\np\u2032 = $$\\(\\frac{x}{n}\\)$$\n\np\u2032 = the estimated proportion of successes (p\u2032 is a point estimate for p, the true proportion.)\n\nx = the number of successes\n\nn = the size of the sample\n\nThe error bound for a proportion is\n\n$$\\(EBP = \\left( z_{\\frac{\\alpha}{2}} \\right)\\left( \\sqrt{\\frac{p^{\\prime}q^{\\prime}}{n}} \\right)\\)$$ where q\u2032 = 1 \u2013 p\u2032\n\nThis formula is similar to the error bound formula for a mean, except that the \"appropriate standard deviation\" is different. For a mean, when the population standard deviation is known, the appropriate standard deviation that we use is $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$. For a proportion, the appropriate standard deviation is $$\\(\\sqrt{\\frac{pq}{n}}\\)$$.\n\nHowever, in the error bound formula, we use  $$\\(\\sqrt{\\frac{p^{\\prime}q^{\\prime}}{n}}\\)$$ as the standard deviation, instead of $$\\(\\sqrt{\\frac{pq}{n}}\\)$$.\n\nIn the error bound formula, the  sample proportions p\u2032 and q\u2032 are estimates of the unknown population proportions p and q. The estimated proportions p\u2032 and q\u2032 are used because p and q are not known. The sample proportions p\u2032 and q\u2032 are calculated from the data: p\u2032 is the estimated proportion of successes, and q\u2032 is the estimated proportion of failures.\n\nThe confidence interval can be used only if the number of successes np\u2032 and the number of failures nq\u2032 are both greater than five.",
            "bold_terms": [
                "confidence intervals",
                "error bound",
                "confidence level",
                "How do you know you are dealing with a proportion problem",
                "distribution is a",
                "binomial distribution",
                "normal distribution",
                "P\u2032 follows a normal distribution for proportions",
                "estimated proportion",
                "point estimate",
                "number",
                "The error bound for a proportion is",
                "sample proportions p\u2032 and q\u2032 are estimates of the unknown population proportions p and q"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "8-3-a-population-proportion",
            "paragraphs": [
                {
                    "context": "There is a certain amount of error introduced into the process of calculating a confidence interval for a proportion. Because we do not know the true proportion for the population, we are forced to use point estimates to calculate the appropriate standard deviation of the sampling distribution. Studies have shown that the resulting estimation of the standard deviation can be flawed.\n\nFortunately, there is a simple adjustment that allows us to produce more accurate confidence intervals. We simply pretend that we have four additional observations. Two of these observations are successes and two are failures. The new sample size, then, is n + 4, and the new count of successes is x + 2. \n\nComputer studies have demonstrated the effectiveness of this method. It should be used when the confidence level desired is at least 90% and the sample size is at least ten.",
                    "id": "C_671117_1"
                }
            ],
            "section_title": "\u201cPlus Four\u201d Confidence Interval for p",
            "chapter_learning_objectives": [],
            "chapter_summary": "Some statistical measures, like many survey questions, measure qualitative rather than quantitative data. In this case, the population parameter being estimated is a proportion. It is possible to create a confidence interval for the true population proportion following procedures similar to those used in creating confidence intervals for population means. The formulas are slightly different, but they follow the same reasoning.Let p\u2032 represent the sample proportion, x/n, where x represents the number of successes and n represents the sample size. Let q\u2032 = 1 \u2013 p\u2032. Then the confidence interval for a population proportion is given by the following formula:(lower bound, upper bound) $$\\(= (p^{\\prime}\u2013EBP,p^{\\prime}~ + EBP) = ~\\left( {p^{\\prime}\u2013z\\sqrt{\\frac{p^{\\prime}q^{\\prime}}{n}},p^{\\prime} + z\\sqrt{\\frac{p^{\\prime}q^{\\prime}}{n}}} \\right)\\)$$The \u201cplus four\u201d method for calculating confidence intervals is an attempt to balance the error introduced by using estimates of the population proportion when calculating the standard deviation of the sampling distribution. Simply imagine four additional trials in the study; two are successes and two are failures. Calculate $$\\(p^{\\prime} = \\frac{x + 2}{n + 4}\\)$$, and proceed to find the confidence interval. When sample sizes are small, this method has been demonstrated to provide more accurate confidence intervals than the standard formula used for larger samples.",
            "chapter_introduction": "During an election year, we see articles in the newspaper that state confidence intervals in terms of proportions or percentages. For example, a poll for a particular candidate running for president might show that the candidate has 40% of the vote within three percentage points  (if the sample is large enough). Often, election polls are calculated with 95% confidence, so, the pollsters would be 95% confident that the true proportion of voters who favored the candidate would be between 0.37 and 0.43: (0.40 \u2013 0.03,0.40 + 0.03).\n\nInvestors in the stock market are interested in the true proportion of stocks that go up and down each week. Businesses that sell personal computers are interested in the proportion of households in the United States that own personal computers. Confidence intervals can be calculated for the true proportion of stocks that go up or down each week and for the true proportion of households in the United States that own personal computers.\n\nThe procedure to find the confidence interval, the sample size, the error bound, and the confidence level for a proportion is similar to that for the population mean, but the formulas are different.\n\nHow do you know you are dealing with a proportion problem? First, the underlying distribution is a binomial distribution. (There is no mention of a mean or average.) If X is a binomial random variable, then X ~ B(n, p)  where n is the number of trials and p is the probability of a success. To form a proportion, take X, the random variable for the number of successes and divide it by n, the number of trials (or the sample size). The random variable P\u2032 (read \"P prime\") is that proportion,  \n\n$$\\(P^{\\prime} = \\frac{X}{n}\\)$$\n\n(Sometimes the random variable is denoted as $$\\(\\hat{P}\\)$$, read \"P hat\".)\n\nWhen n is large and p is not close to zero or one, we can use the normal distribution to approximate the binomial.\n\n$$\\(\\left. X \\right.\\sim N(np,\\sqrt{npq})\\)$$\n\nIf we divide the random variable, the mean, and the standarddeviation by n, we get a normal distribution of proportions with P\u2032, called theestimated proportion, as the random variable. (Recall that a proportion as thenumber of successes divided by n.)\n\n$$\\(\\frac{X}{n} = P^{\\prime}\\text{\\textasciitilde~}N\\left( {\\frac{np}{n},\\frac{\\sqrt{npq}}{n}} \\right)\\)$$\n\nUsing algebra to simplify : $$\\(\\frac{\\sqrt{npq}}{n} = \\sqrt{\\frac{pq}{n}}\\)$$\n\nP\u2032 follows a normal distribution for proportions:  $$\\(\\frac{X}{n} = P^{\\prime}\\text{\\textasciitilde~}N\\left( {\\frac{np}{n},\\frac{\\sqrt{npq}}{n}} \\right)\\)$$\n\nThe confidence interval has the form (p\u2032 \u2013 EBP, p\u2032 + EBP). EBP is error bound for the proportion.\n\np\u2032 = $$\\(\\frac{x}{n}\\)$$\n\np\u2032 = the estimated proportion of successes (p\u2032 is a point estimate for p, the true proportion.)\n\nx = the number of successes\n\nn = the size of the sample\n\nThe error bound for a proportion is\n\n$$\\(EBP = \\left( z_{\\frac{\\alpha}{2}} \\right)\\left( \\sqrt{\\frac{p^{\\prime}q^{\\prime}}{n}} \\right)\\)$$ where q\u2032 = 1 \u2013 p\u2032\n\nThis formula is similar to the error bound formula for a mean, except that the \"appropriate standard deviation\" is different. For a mean, when the population standard deviation is known, the appropriate standard deviation that we use is $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$. For a proportion, the appropriate standard deviation is $$\\(\\sqrt{\\frac{pq}{n}}\\)$$.\n\nHowever, in the error bound formula, we use  $$\\(\\sqrt{\\frac{p^{\\prime}q^{\\prime}}{n}}\\)$$ as the standard deviation, instead of $$\\(\\sqrt{\\frac{pq}{n}}\\)$$.\n\nIn the error bound formula, the  sample proportions p\u2032 and q\u2032 are estimates of the unknown population proportions p and q. The estimated proportions p\u2032 and q\u2032 are used because p and q are not known. The sample proportions p\u2032 and q\u2032 are calculated from the data: p\u2032 is the estimated proportion of successes, and q\u2032 is the estimated proportion of failures.\n\nThe confidence interval can be used only if the number of successes np\u2032 and the number of failures nq\u2032 are both greater than five.",
            "bold_terms": [
                "confidence intervals",
                "error bound",
                "confidence level",
                "How do you know you are dealing with a proportion problem",
                "distribution is a",
                "binomial distribution",
                "normal distribution",
                "P\u2032 follows a normal distribution for proportions",
                "estimated proportion",
                "point estimate",
                "number",
                "The error bound for a proportion is",
                "sample proportions p\u2032 and q\u2032 are estimates of the unknown population proportions p and q"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "8-3-a-population-proportion",
            "paragraphs": [
                {
                    "context": "If researchers desire a specific margin of error, then they can use the error bound formula to calculate the required sample size.\n\nThe error bound formula for a population proportion is\n\n$$\\(EBP = \\left( z_{\\frac{\\alpha}{2}} \\right)\\left( \\sqrt{\\frac{p^{\\prime}q^{\\prime}}{n}} \\right)\\)$$ Solving for n gives you an equation for the sample size. $$\\(n = \\frac{\\left( z_{\\frac{\\alpha}{2}} \\right)^{2}(p^{\\prime}q^{\\prime})}{EBP^{2}}\\)$$ ",
                    "id": "C_857455_2"
                }
            ],
            "section_title": "Calculating the Sample Size n",
            "chapter_learning_objectives": [],
            "chapter_summary": "Some statistical measures, like many survey questions, measure qualitative rather than quantitative data. In this case, the population parameter being estimated is a proportion. It is possible to create a confidence interval for the true population proportion following procedures similar to those used in creating confidence intervals for population means. The formulas are slightly different, but they follow the same reasoning.Let p\u2032 represent the sample proportion, x/n, where x represents the number of successes and n represents the sample size. Let q\u2032 = 1 \u2013 p\u2032. Then the confidence interval for a population proportion is given by the following formula:(lower bound, upper bound) $$\\(= (p^{\\prime}\u2013EBP,p^{\\prime}~ + EBP) = ~\\left( {p^{\\prime}\u2013z\\sqrt{\\frac{p^{\\prime}q^{\\prime}}{n}},p^{\\prime} + z\\sqrt{\\frac{p^{\\prime}q^{\\prime}}{n}}} \\right)\\)$$The \u201cplus four\u201d method for calculating confidence intervals is an attempt to balance the error introduced by using estimates of the population proportion when calculating the standard deviation of the sampling distribution. Simply imagine four additional trials in the study; two are successes and two are failures. Calculate $$\\(p^{\\prime} = \\frac{x + 2}{n + 4}\\)$$, and proceed to find the confidence interval. When sample sizes are small, this method has been demonstrated to provide more accurate confidence intervals than the standard formula used for larger samples.",
            "chapter_introduction": "During an election year, we see articles in the newspaper that state confidence intervals in terms of proportions or percentages. For example, a poll for a particular candidate running for president might show that the candidate has 40% of the vote within three percentage points  (if the sample is large enough). Often, election polls are calculated with 95% confidence, so, the pollsters would be 95% confident that the true proportion of voters who favored the candidate would be between 0.37 and 0.43: (0.40 \u2013 0.03,0.40 + 0.03).\n\nInvestors in the stock market are interested in the true proportion of stocks that go up and down each week. Businesses that sell personal computers are interested in the proportion of households in the United States that own personal computers. Confidence intervals can be calculated for the true proportion of stocks that go up or down each week and for the true proportion of households in the United States that own personal computers.\n\nThe procedure to find the confidence interval, the sample size, the error bound, and the confidence level for a proportion is similar to that for the population mean, but the formulas are different.\n\nHow do you know you are dealing with a proportion problem? First, the underlying distribution is a binomial distribution. (There is no mention of a mean or average.) If X is a binomial random variable, then X ~ B(n, p)  where n is the number of trials and p is the probability of a success. To form a proportion, take X, the random variable for the number of successes and divide it by n, the number of trials (or the sample size). The random variable P\u2032 (read \"P prime\") is that proportion,  \n\n$$\\(P^{\\prime} = \\frac{X}{n}\\)$$\n\n(Sometimes the random variable is denoted as $$\\(\\hat{P}\\)$$, read \"P hat\".)\n\nWhen n is large and p is not close to zero or one, we can use the normal distribution to approximate the binomial.\n\n$$\\(\\left. X \\right.\\sim N(np,\\sqrt{npq})\\)$$\n\nIf we divide the random variable, the mean, and the standarddeviation by n, we get a normal distribution of proportions with P\u2032, called theestimated proportion, as the random variable. (Recall that a proportion as thenumber of successes divided by n.)\n\n$$\\(\\frac{X}{n} = P^{\\prime}\\text{\\textasciitilde~}N\\left( {\\frac{np}{n},\\frac{\\sqrt{npq}}{n}} \\right)\\)$$\n\nUsing algebra to simplify : $$\\(\\frac{\\sqrt{npq}}{n} = \\sqrt{\\frac{pq}{n}}\\)$$\n\nP\u2032 follows a normal distribution for proportions:  $$\\(\\frac{X}{n} = P^{\\prime}\\text{\\textasciitilde~}N\\left( {\\frac{np}{n},\\frac{\\sqrt{npq}}{n}} \\right)\\)$$\n\nThe confidence interval has the form (p\u2032 \u2013 EBP, p\u2032 + EBP). EBP is error bound for the proportion.\n\np\u2032 = $$\\(\\frac{x}{n}\\)$$\n\np\u2032 = the estimated proportion of successes (p\u2032 is a point estimate for p, the true proportion.)\n\nx = the number of successes\n\nn = the size of the sample\n\nThe error bound for a proportion is\n\n$$\\(EBP = \\left( z_{\\frac{\\alpha}{2}} \\right)\\left( \\sqrt{\\frac{p^{\\prime}q^{\\prime}}{n}} \\right)\\)$$ where q\u2032 = 1 \u2013 p\u2032\n\nThis formula is similar to the error bound formula for a mean, except that the \"appropriate standard deviation\" is different. For a mean, when the population standard deviation is known, the appropriate standard deviation that we use is $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$. For a proportion, the appropriate standard deviation is $$\\(\\sqrt{\\frac{pq}{n}}\\)$$.\n\nHowever, in the error bound formula, we use  $$\\(\\sqrt{\\frac{p^{\\prime}q^{\\prime}}{n}}\\)$$ as the standard deviation, instead of $$\\(\\sqrt{\\frac{pq}{n}}\\)$$.\n\nIn the error bound formula, the  sample proportions p\u2032 and q\u2032 are estimates of the unknown population proportions p and q. The estimated proportions p\u2032 and q\u2032 are used because p and q are not known. The sample proportions p\u2032 and q\u2032 are calculated from the data: p\u2032 is the estimated proportion of successes, and q\u2032 is the estimated proportion of failures.\n\nThe confidence interval can be used only if the number of successes np\u2032 and the number of failures nq\u2032 are both greater than five.",
            "bold_terms": [
                "confidence intervals",
                "error bound",
                "confidence level",
                "How do you know you are dealing with a proportion problem",
                "distribution is a",
                "binomial distribution",
                "normal distribution",
                "P\u2032 follows a normal distribution for proportions",
                "estimated proportion",
                "point estimate",
                "number",
                "The error bound for a proportion is",
                "sample proportions p\u2032 and q\u2032 are estimates of the unknown population proportions p and q"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) which arises from Bernoulli trials; there are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV X is defined as the number of successes in n trials. The notation is: X~B(n,p). The mean is \u03bc = np and the standard deviation is \u03c3 = $$\\(\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\left( \\frac{n}{x} \\right)p^{x}q^{n - x}\\)$$.    "
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:the desired confidence level,information that is known about the  distribution (for example, known standard deviation),the sample and its size."
                },
                {
                    "name": "Confidence Level (CL)",
                    "description": "the percent expression for the probability that the confidence interval contains the true population parameter; for example, if the CL = 90%, then in 90 out of 100 samples the interval estimate will enclose the true population parameter."
                },
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary"
                },
                {
                    "name": "Inferential Statistics",
                    "description": "also called statistical inference or inductive statistics; this facet of statistics deals with estimating a population parameter based on a sample statistic. For example, if four out of the 100 calculators sampled are defective we might infer that four percent of the production is defective."
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f\\text{(}x\\text{)} = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\u2013{(x\u2013\\mu)}^{2}/2\\sigma^{2}}\\)$$, where \u03bc is the mean of the distribution and \u03c3 is the standard deviation, notation: X ~ N(\u03bc,\u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution.    "
                },
                {
                    "name": "Parameter",
                    "description": "a numerical characteristic of a population"
                },
                {
                    "name": "Point Estimate",
                    "description": "a single number computed from a sample and used to estimate a population parameter"
                },
                {
                    "name": "Standard Deviation",
                    "description": " a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation"
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student; the major characteristics of the random variable (RV) are:    It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n get larger.There is a \"family\" of t\u2013distributions: each representative of the family is completely defined by the number of degrees of freedom, which is one less than the number of data."
                }
            ]
        },
        {
            "title": "9-1-null-and-alternative-hypotheses",
            "paragraphs": [
                {
                    "context": "H0 always has a symbol with an equal in it. Ha never has a symbol with an equal in it. The choice of symbol depends on the wording of the hypothesis test. However, be aware that many researchers (including one of the co-authors in research work) use = in the null hypothesis, even with > or < as the symbol in the alternative hypothesis. This practice is acceptable because we only make the decision to reject or not reject the null hypothesis.",
                    "id": "C_475046_0"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "In a hypothesis test, sample data is evaluated in order to arrive at a decision about some type of claim. If certain conditions about the sample are satisfied, then the claim can be evaluated for a population. In a hypothesis test, we:Evaluate the null hypothesis, typically denoted with H0. The null is not rejected unless the hypothesis test shows otherwise. The null statement must always contain some form of equality (=, \u2264 or \u2265) Always write the alternative hypothesis, typically denoted with Ha or H1, using less than, greater than, or not equals symbols, i.e., (\u2260, >, or <). If we reject the null hypothesis, then we can assume there is enough evidence to support the alternative hypothesis. Never state that a claim is proven true or false. Keep in mind the underlying fact that hypothesis testing is based on probability laws; therefore, we can talk only in terms of non-absolute certainties. ",
            "chapter_introduction": "The actual test begins by considering two hypotheses. They are called the null hypothesis and the alternative hypothesis. These hypotheses contain opposing viewpoints.\n\nH0: The null hypothesis: It is a statement of no difference between the variables\u2014they are not related. This can often be considered the status quo and as a result if you cannot accept the null it requires some action.\n\nHa: The alternative hypothesis: It is a claim about the population that iscontradictory to H0 and what we conclude when we reject H0. This is usually what the researcher is trying to prove.\n\nSince the null and alternative hypotheses are contradictory, you must examine evidence to decide if you have enough evidence to reject the null hypothesis or not. The evidence is in the form of sample data.\n\nAfter you have determined which hypothesis the sample supports, you make a decision.There are two options for a decision. They are \"reject H0\" if the sample information favors the alternative hypothesis or \"do not reject H0\" or \"decline to reject H0\" if the sample information is insufficient to reject the null hypothesis.\n\nMathematical Symbols Used in H0 and Ha:",
            "bold_terms": [
                "hypotheses",
                "null hypothesis",
                "alternative hypothesis",
                "The null hypothesis",
                "The alternative hypothesis",
                "decision"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) that arises from Bernoulli trials. There are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV \u03a7 is defined as the number of successes in n trials. The notation is: X ~ B(n, p) \u03bc = np  and the standard deviation is $$\\(\\sigma = ~\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\begin{pmatrix}\nn \\\\\nx \\\\\n\\end{pmatrix}p^{x}q^{n - x}\\)$$."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "     Given a random variable (RV) with known mean $$\\(\\mu\\)$$ and known standard deviation \u03c3. We are sampling with size n and we are interested in two new RVs - the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, $$\\(\\Sigma X\\)$$.If the size n of the sample is sufficiently large, then $$\\(\\left. \\overline{X} \\right.\\sim N\\left( {\\mu\\text{,}\\frac{\\sigma}{\\sqrt{n}}} \\right)\\)$$ and $$\\(\\left. \\Sigma X \\right.\\sim N(n\\mu,\\sqrt{n}\\sigma)\\)$$. If the size n of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distribution regardless of the shape of the population. The mean of the sample  means will equal the population mean and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:The desired confidence level.Information that is known about the  distribution (for example, known standard deviation).The sample and its size."
                },
                {
                    "name": "Hypothesis",
                    "description": "a statement about the value of a population parameter, in case of two hypotheses, the statement assumed to be true is called the null hypothesis (notation H0) and the contradictory statement is called the alternative hypothesis (notation Ha)."
                },
                {
                    "name": "Hypothesis Testing",
                    "description": "Based on sample evidence, a procedure for determining whether the hypothesis stated is a reasonable statement and should not be rejected, or is unreasonable and should be rejected.    "
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x) = ~\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\\frac{- {(x - \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution, and \u03c3 is the standard deviation, notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "p-value",
                    "description": "the probability that an event will happen purely by chance assuming the null hypothesis is true. The smaller the p-value, the stronger the evidence is against the null hypothesis."
                },
                {
                    "name": "Standard Deviation",
                    "description": "a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student. The major characteristics of the random variable (RV) are:It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n gets larger.There is a \"family\" of t distributions: every representative of the family is completely defined by the number of degrees of freedom which is one less than the number of data items."
                },
                {
                    "name": "Type 1 Error",
                    "description": "The decision is to reject the null hypothesis when, in fact, the null hypothesis is true.    "
                },
                {
                    "name": "Type 2 Error",
                    "description": "The decision is not to reject the null hypothesis when, in fact, the null hypothesis is false.    "
                }
            ]
        },
        {
            "title": "9-1-null-and-alternative-hypotheses",
            "paragraphs": [
                {
                    "context": "Bring to class a newspaper, some news magazines, and some Internet articles . In groups, find articles from which your group can write null and alternative hypotheses. Discuss your hypotheses with the rest of the class.",
                    "id": "C_531443_1"
                }
            ],
            "section_title": "Collaborative Exercise",
            "chapter_learning_objectives": [],
            "chapter_summary": "In a hypothesis test, sample data is evaluated in order to arrive at a decision about some type of claim. If certain conditions about the sample are satisfied, then the claim can be evaluated for a population. In a hypothesis test, we:Evaluate the null hypothesis, typically denoted with H0. The null is not rejected unless the hypothesis test shows otherwise. The null statement must always contain some form of equality (=, \u2264 or \u2265) Always write the alternative hypothesis, typically denoted with Ha or H1, using less than, greater than, or not equals symbols, i.e., (\u2260, >, or <). If we reject the null hypothesis, then we can assume there is enough evidence to support the alternative hypothesis. Never state that a claim is proven true or false. Keep in mind the underlying fact that hypothesis testing is based on probability laws; therefore, we can talk only in terms of non-absolute certainties. ",
            "chapter_introduction": "The actual test begins by considering two hypotheses. They are called the null hypothesis and the alternative hypothesis. These hypotheses contain opposing viewpoints.\n\nH0: The null hypothesis: It is a statement of no difference between the variables\u2014they are not related. This can often be considered the status quo and as a result if you cannot accept the null it requires some action.\n\nHa: The alternative hypothesis: It is a claim about the population that iscontradictory to H0 and what we conclude when we reject H0. This is usually what the researcher is trying to prove.\n\nSince the null and alternative hypotheses are contradictory, you must examine evidence to decide if you have enough evidence to reject the null hypothesis or not. The evidence is in the form of sample data.\n\nAfter you have determined which hypothesis the sample supports, you make a decision.There are two options for a decision. They are \"reject H0\" if the sample information favors the alternative hypothesis or \"do not reject H0\" or \"decline to reject H0\" if the sample information is insufficient to reject the null hypothesis.\n\nMathematical Symbols Used in H0 and Ha:",
            "bold_terms": [
                "hypotheses",
                "null hypothesis",
                "alternative hypothesis",
                "The null hypothesis",
                "The alternative hypothesis",
                "decision"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) that arises from Bernoulli trials. There are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV \u03a7 is defined as the number of successes in n trials. The notation is: X ~ B(n, p) \u03bc = np  and the standard deviation is $$\\(\\sigma = ~\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\begin{pmatrix}\nn \\\\\nx \\\\\n\\end{pmatrix}p^{x}q^{n - x}\\)$$."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "     Given a random variable (RV) with known mean $$\\(\\mu\\)$$ and known standard deviation \u03c3. We are sampling with size n and we are interested in two new RVs - the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, $$\\(\\Sigma X\\)$$.If the size n of the sample is sufficiently large, then $$\\(\\left. \\overline{X} \\right.\\sim N\\left( {\\mu\\text{,}\\frac{\\sigma}{\\sqrt{n}}} \\right)\\)$$ and $$\\(\\left. \\Sigma X \\right.\\sim N(n\\mu,\\sqrt{n}\\sigma)\\)$$. If the size n of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distribution regardless of the shape of the population. The mean of the sample  means will equal the population mean and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:The desired confidence level.Information that is known about the  distribution (for example, known standard deviation).The sample and its size."
                },
                {
                    "name": "Hypothesis",
                    "description": "a statement about the value of a population parameter, in case of two hypotheses, the statement assumed to be true is called the null hypothesis (notation H0) and the contradictory statement is called the alternative hypothesis (notation Ha)."
                },
                {
                    "name": "Hypothesis Testing",
                    "description": "Based on sample evidence, a procedure for determining whether the hypothesis stated is a reasonable statement and should not be rejected, or is unreasonable and should be rejected.    "
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x) = ~\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\\frac{- {(x - \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution, and \u03c3 is the standard deviation, notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "p-value",
                    "description": "the probability that an event will happen purely by chance assuming the null hypothesis is true. The smaller the p-value, the stronger the evidence is against the null hypothesis."
                },
                {
                    "name": "Standard Deviation",
                    "description": "a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student. The major characteristics of the random variable (RV) are:It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n gets larger.There is a \"family\" of t distributions: every representative of the family is completely defined by the number of degrees of freedom which is one less than the number of data items."
                },
                {
                    "name": "Type 1 Error",
                    "description": "The decision is to reject the null hypothesis when, in fact, the null hypothesis is true.    "
                },
                {
                    "name": "Type 2 Error",
                    "description": "The decision is not to reject the null hypothesis when, in fact, the null hypothesis is false.    "
                }
            ]
        },
        {
            "title": "9-3-distribution-needed-for-hypothesis-testing",
            "paragraphs": [
                {
                    "context": "When you perform a hypothesis test of a single population mean \u03bc using aStudent's t-distribution (often called a t-test), there are fundamental assumptions that need to be met in order for the test to work properly. Your data should be a simple random sample that comes from a population that is approximately normally distributed. You use the sample standard deviation to approximate the population standard deviation. (Note that if the sample size is sufficiently large, a t-test will work even if the population is not approximately normally distributed).\n\nWhen you perform a hypothesis test of a single population mean \u03bc using anormal distribution (often called a z-test), you take a simple random sample from the population. The population you are testing is normally distributed or your sample size is sufficiently large. You know the value of the population standard deviation which, in reality, is rarely known.\n\nWhen you perform a hypothesis test of a single population proportion p, you  take a simple random sample from the population. You must meet the conditions for a binomial distribution which are: there are a certain number n of independent trials, the outcomes of any trial are success or failure, and each trial has the same probability of a success p. The shape of the binomial distribution needs to be similar to the shape of the normal distribution. To ensure this, the quantities np and nq must both be greater than five (np > 5 and nq > 5). Then the binomial distribution of a sample (estimated) proportion can be approximated by the normal distribution with \u03bc = p and $$\\(\\sigma = \\sqrt{\\frac{pq}{n}}\\)$$.Remember that q = 1 \u2013 p.",
                    "id": "C_704308_0"
                }
            ],
            "section_title": "Assumptions",
            "chapter_learning_objectives": [],
            "chapter_summary": "In order for a hypothesis test\u2019s results to be generalized to a population, certain requirements must be satisfied. When testing for a single population mean:A Student's t-test should be used if the data come from a simple, random sample and the population is approximately normally distributed, or the sample size is large, with an unknown standard deviation. The normal test will work if the data come from a simple, random sample and the population      is approximately normally distributed, or the sample size is large, with a known standard      deviation. When testing a single population proportion use a normal test for a single population proportion if the data comes from a simple, random sample, fill the requirements for a binomial distribution, and the mean number of successes and the mean number of failures satisfy the conditions: np > 5 and nq > 5 where n is the sample size, p is the probability of a success, and q is the probability of a failure.",
            "chapter_introduction": "Earlier in the course, we discussed sampling distributions. Particular distributions are associated with hypothesis testing. Perform tests of a population mean using a normal distribution or a Student's t-distribution. (Remember, use a Student's t-distribution when the population standard deviation is unknown and the distribution of the sample mean is approximately normal.) We perform tests of a population proportion using a normal distribution (usually n is large).\n\nIf you are testing a single population mean, the distribution for the test is for means:\n\n$$\\(\\left. \\overline{X} \\right.\\sim N\\left( {\\mu_{X},\\frac{\\sigma_{X}}{\\sqrt{n}}} \\right)\\)$$ or $$\\(t_{df}\\)$$\n\nThe population parameter is \u03bc. The estimated value (point estimate) for \u03bc is $$\\(\\overline{x}\\)$$, the sample mean.\n\nIf you are testing a single population proportion, the distribution for the test is for  proportions or percentages:\n\n$$\\(\\left. P^{\\prime} \\right.\\sim N\\left( {p,\\sqrt{\\frac{p \\cdot q}{n}}} \\right)\\)$$\n\nThe population parameter is p. The estimated value (point estimate) for p is p\u2032. p\u2032 = $$\\(\\frac{x}{n}\\)$$ where x is the number of successes and n is the sample size.",
            "bold_terms": [
                "Particular distributions are associated with hypothesis testing",
                "normal distribution",
                "Student's t-distribution",
                "standard deviation",
                "single population mean",
                "means",
                "single population proportion",
                "hypothesis test",
                "of a single population mean \u03bc",
                "simple random sample",
                "normally distributed",
                "hypothesis test of a single population mean \u03bc",
                "hypothesis test of a single population proportion p",
                "binomial distribution"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) that arises from Bernoulli trials. There are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV \u03a7 is defined as the number of successes in n trials. The notation is: X ~ B(n, p) \u03bc = np  and the standard deviation is $$\\(\\sigma = ~\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\begin{pmatrix}\nn \\\\\nx \\\\\n\\end{pmatrix}p^{x}q^{n - x}\\)$$."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "     Given a random variable (RV) with known mean $$\\(\\mu\\)$$ and known standard deviation \u03c3. We are sampling with size n and we are interested in two new RVs - the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, $$\\(\\Sigma X\\)$$.If the size n of the sample is sufficiently large, then $$\\(\\left. \\overline{X} \\right.\\sim N\\left( {\\mu\\text{,}\\frac{\\sigma}{\\sqrt{n}}} \\right)\\)$$ and $$\\(\\left. \\Sigma X \\right.\\sim N(n\\mu,\\sqrt{n}\\sigma)\\)$$. If the size n of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distribution regardless of the shape of the population. The mean of the sample  means will equal the population mean and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:The desired confidence level.Information that is known about the  distribution (for example, known standard deviation).The sample and its size."
                },
                {
                    "name": "Hypothesis",
                    "description": "a statement about the value of a population parameter, in case of two hypotheses, the statement assumed to be true is called the null hypothesis (notation H0) and the contradictory statement is called the alternative hypothesis (notation Ha)."
                },
                {
                    "name": "Hypothesis Testing",
                    "description": "Based on sample evidence, a procedure for determining whether the hypothesis stated is a reasonable statement and should not be rejected, or is unreasonable and should be rejected.    "
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x) = ~\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\\frac{- {(x - \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution, and \u03c3 is the standard deviation, notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "p-value",
                    "description": "the probability that an event will happen purely by chance assuming the null hypothesis is true. The smaller the p-value, the stronger the evidence is against the null hypothesis."
                },
                {
                    "name": "Standard Deviation",
                    "description": "a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student. The major characteristics of the random variable (RV) are:It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n gets larger.There is a \"family\" of t distributions: every representative of the family is completely defined by the number of degrees of freedom which is one less than the number of data items."
                },
                {
                    "name": "Type 1 Error",
                    "description": "The decision is to reject the null hypothesis when, in fact, the null hypothesis is true.    "
                },
                {
                    "name": "Type 2 Error",
                    "description": "The decision is not to reject the null hypothesis when, in fact, the null hypothesis is false.    "
                }
            ]
        },
        {
            "title": "9-4-rare-events-the-sample-decision-and-conclusion",
            "paragraphs": [
                {
                    "context": "Suppose you make an assumption about a property of the population (this assumption is the null hypothesis). Then you gather sample data randomly. If the sample has properties that would be very unlikely to occur if the assumption is true, then you would conclude that your assumption about the population is probably incorrect. (Remember that your assumption is just an assumption\u2014it is not a fact and it may or may not be true. But your sample data are real and the data are showing you a fact that seems to contradict your assumption.)\n\nFor example, Didi and Ali are at a birthday party of a very wealthy friend. They hurry to be first in line to grab a prize from a tall basket that they cannot see inside because they will be blindfolded. There are 200 plastic bubbles in the basket and Didi and Ali have been told that there is only one with a $100 bill. Didi is the first person to reach into the basket and pull out a bubble. Her bubble contains a $100 bill. The probability of this happening is $$\\(\\frac{1}{200}\\)$$ = 0.005. Because this is so unlikely, Ali is hoping that what the two of them were told is wrong and there are more $100 bills in the basket. A \"rare event\" has occurred (Didi getting the $100 bill) so Ali doubts the assumption about only one $100 bill being in the basket.",
                    "id": "C_312969_0"
                }
            ],
            "section_title": "Rare Events",
            "chapter_learning_objectives": [],
            "chapter_summary": "When the probability of an event occurring is low, and it happens, it is called a rare event. Rare events are important to consider in hypothesis testing because they can inform your willingness not to reject or to reject a null hypothesis. To test a null hypothesis, find the p-value for the sample data and graph the results. When deciding whether or not to reject the null the hypothesis, keep these two parameters in mind:\u03b1 > p-value, reject the null hypothesis \u03b1 \u2264 p-value, do not reject the null hypothesis ",
            "chapter_introduction": "Establishing the type of distribution, sample size, and known or unknown standard deviation can help you figure out how to go about a hypothesis test. However, there are several other factors you should consider when working out a hypothesis test.",
            "bold_terms": [
                "null hypothesis",
                "unlikely",
                "assumption",
                "p-value",
                "probability that, if the null hypothesis is true, the results from another randomly selected sample will be as extreme or more extreme as the results obtained from the given sample",
                "Draw a graph that shows the p-value. The hypothesis test is easier to perform if you use a graph because you see the problem more clearly",
                "preset or preconceived \u03b1 (also called a \"significance level",
                "Type I error",
                "decision",
                "alternative hypothesis",
                "failed",
                "Conclusion",
                "conclusion"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) that arises from Bernoulli trials. There are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV \u03a7 is defined as the number of successes in n trials. The notation is: X ~ B(n, p) \u03bc = np  and the standard deviation is $$\\(\\sigma = ~\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\begin{pmatrix}\nn \\\\\nx \\\\\n\\end{pmatrix}p^{x}q^{n - x}\\)$$."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "     Given a random variable (RV) with known mean $$\\(\\mu\\)$$ and known standard deviation \u03c3. We are sampling with size n and we are interested in two new RVs - the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, $$\\(\\Sigma X\\)$$.If the size n of the sample is sufficiently large, then $$\\(\\left. \\overline{X} \\right.\\sim N\\left( {\\mu\\text{,}\\frac{\\sigma}{\\sqrt{n}}} \\right)\\)$$ and $$\\(\\left. \\Sigma X \\right.\\sim N(n\\mu,\\sqrt{n}\\sigma)\\)$$. If the size n of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distribution regardless of the shape of the population. The mean of the sample  means will equal the population mean and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:The desired confidence level.Information that is known about the  distribution (for example, known standard deviation).The sample and its size."
                },
                {
                    "name": "Hypothesis",
                    "description": "a statement about the value of a population parameter, in case of two hypotheses, the statement assumed to be true is called the null hypothesis (notation H0) and the contradictory statement is called the alternative hypothesis (notation Ha)."
                },
                {
                    "name": "Hypothesis Testing",
                    "description": "Based on sample evidence, a procedure for determining whether the hypothesis stated is a reasonable statement and should not be rejected, or is unreasonable and should be rejected.    "
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x) = ~\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\\frac{- {(x - \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution, and \u03c3 is the standard deviation, notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "p-value",
                    "description": "the probability that an event will happen purely by chance assuming the null hypothesis is true. The smaller the p-value, the stronger the evidence is against the null hypothesis."
                },
                {
                    "name": "Standard Deviation",
                    "description": "a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student. The major characteristics of the random variable (RV) are:It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n gets larger.There is a \"family\" of t distributions: every representative of the family is completely defined by the number of degrees of freedom which is one less than the number of data items."
                },
                {
                    "name": "Type 1 Error",
                    "description": "The decision is to reject the null hypothesis when, in fact, the null hypothesis is true.    "
                },
                {
                    "name": "Type 2 Error",
                    "description": "The decision is not to reject the null hypothesis when, in fact, the null hypothesis is false.    "
                }
            ]
        },
        {
            "title": "9-4-rare-events-the-sample-decision-and-conclusion",
            "paragraphs": [
                {
                    "context": "Use the sample data to calculate the actual probability of getting the test result, called the p-value. The p-value is the probability that, if the null hypothesis is true, the results from another randomly selected sample will be as extreme or more extreme as the results obtained from the given sample.\n\nA large p-value calculated from the data indicates that we should not reject the null hypothesis. The smaller the p-value, the more unlikely the outcome, and the stronger the evidence is against the null hypothesis. We would reject the null hypothesis if the evidence is strongly against it.\n\nDraw a graph that shows the p-value. The hypothesis test is easier to perform if you use a graph because you see the problem more clearly.",
                    "id": "C_415196_1"
                }
            ],
            "section_title": "Using the Sample to Test the Null Hypothesis",
            "chapter_learning_objectives": [],
            "chapter_summary": "When the probability of an event occurring is low, and it happens, it is called a rare event. Rare events are important to consider in hypothesis testing because they can inform your willingness not to reject or to reject a null hypothesis. To test a null hypothesis, find the p-value for the sample data and graph the results. When deciding whether or not to reject the null the hypothesis, keep these two parameters in mind:\u03b1 > p-value, reject the null hypothesis \u03b1 \u2264 p-value, do not reject the null hypothesis ",
            "chapter_introduction": "Establishing the type of distribution, sample size, and known or unknown standard deviation can help you figure out how to go about a hypothesis test. However, there are several other factors you should consider when working out a hypothesis test.",
            "bold_terms": [
                "null hypothesis",
                "unlikely",
                "assumption",
                "p-value",
                "probability that, if the null hypothesis is true, the results from another randomly selected sample will be as extreme or more extreme as the results obtained from the given sample",
                "Draw a graph that shows the p-value. The hypothesis test is easier to perform if you use a graph because you see the problem more clearly",
                "preset or preconceived \u03b1 (also called a \"significance level",
                "Type I error",
                "decision",
                "alternative hypothesis",
                "failed",
                "Conclusion",
                "conclusion"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) that arises from Bernoulli trials. There are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV \u03a7 is defined as the number of successes in n trials. The notation is: X ~ B(n, p) \u03bc = np  and the standard deviation is $$\\(\\sigma = ~\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\begin{pmatrix}\nn \\\\\nx \\\\\n\\end{pmatrix}p^{x}q^{n - x}\\)$$."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "     Given a random variable (RV) with known mean $$\\(\\mu\\)$$ and known standard deviation \u03c3. We are sampling with size n and we are interested in two new RVs - the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, $$\\(\\Sigma X\\)$$.If the size n of the sample is sufficiently large, then $$\\(\\left. \\overline{X} \\right.\\sim N\\left( {\\mu\\text{,}\\frac{\\sigma}{\\sqrt{n}}} \\right)\\)$$ and $$\\(\\left. \\Sigma X \\right.\\sim N(n\\mu,\\sqrt{n}\\sigma)\\)$$. If the size n of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distribution regardless of the shape of the population. The mean of the sample  means will equal the population mean and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:The desired confidence level.Information that is known about the  distribution (for example, known standard deviation).The sample and its size."
                },
                {
                    "name": "Hypothesis",
                    "description": "a statement about the value of a population parameter, in case of two hypotheses, the statement assumed to be true is called the null hypothesis (notation H0) and the contradictory statement is called the alternative hypothesis (notation Ha)."
                },
                {
                    "name": "Hypothesis Testing",
                    "description": "Based on sample evidence, a procedure for determining whether the hypothesis stated is a reasonable statement and should not be rejected, or is unreasonable and should be rejected.    "
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x) = ~\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\\frac{- {(x - \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution, and \u03c3 is the standard deviation, notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "p-value",
                    "description": "the probability that an event will happen purely by chance assuming the null hypothesis is true. The smaller the p-value, the stronger the evidence is against the null hypothesis."
                },
                {
                    "name": "Standard Deviation",
                    "description": "a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student. The major characteristics of the random variable (RV) are:It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n gets larger.There is a \"family\" of t distributions: every representative of the family is completely defined by the number of degrees of freedom which is one less than the number of data items."
                },
                {
                    "name": "Type 1 Error",
                    "description": "The decision is to reject the null hypothesis when, in fact, the null hypothesis is true.    "
                },
                {
                    "name": "Type 2 Error",
                    "description": "The decision is not to reject the null hypothesis when, in fact, the null hypothesis is false.    "
                }
            ]
        },
        {
            "title": "9-4-rare-events-the-sample-decision-and-conclusion",
            "paragraphs": [
                {
                    "context": "A systematic way to make a decision of whether to reject or not reject the null hypothesisis to compare the p-value and a preset or preconceived \u03b1 (also called a \"significance level\"). A preset \u03b1 is the probability of a Type I error (rejecting the null hypothesis when the null hypothesis is true). It may or may not be given to you at the beginning of the problem.\n\nWhen you make a decision to reject or not reject H0, do as follows:\n\nIf \u03b1 > p-value, reject H0. The results of the sample data are significant. There is sufficient evidence to conclude that H0 is an incorrect belief and that the alternative hypothesis, Ha, may be correct. If \u03b1 \u2264 p-value, do not reject H0. The results of the sample data are not significant.There is not sufficient evidence to conclude that the alternative hypothesis,Ha, may be correct. When you \"do not reject H0\", it does not mean that you should believe that H0 is true. It simply means that the sample data have failed to provide sufficient evidence to cast serious doubt about the truthfulness of Ho. \n\nConclusion: After you make your decision, write a thoughtful conclusion about the hypotheses in terms of the given problem.",
                    "id": "C_416544_2"
                }
            ],
            "section_title": "Decision and Conclusion",
            "chapter_learning_objectives": [],
            "chapter_summary": "When the probability of an event occurring is low, and it happens, it is called a rare event. Rare events are important to consider in hypothesis testing because they can inform your willingness not to reject or to reject a null hypothesis. To test a null hypothesis, find the p-value for the sample data and graph the results. When deciding whether or not to reject the null the hypothesis, keep these two parameters in mind:\u03b1 > p-value, reject the null hypothesis \u03b1 \u2264 p-value, do not reject the null hypothesis ",
            "chapter_introduction": "Establishing the type of distribution, sample size, and known or unknown standard deviation can help you figure out how to go about a hypothesis test. However, there are several other factors you should consider when working out a hypothesis test.",
            "bold_terms": [
                "null hypothesis",
                "unlikely",
                "assumption",
                "p-value",
                "probability that, if the null hypothesis is true, the results from another randomly selected sample will be as extreme or more extreme as the results obtained from the given sample",
                "Draw a graph that shows the p-value. The hypothesis test is easier to perform if you use a graph because you see the problem more clearly",
                "preset or preconceived \u03b1 (also called a \"significance level",
                "Type I error",
                "decision",
                "alternative hypothesis",
                "failed",
                "Conclusion",
                "conclusion"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) that arises from Bernoulli trials. There are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV \u03a7 is defined as the number of successes in n trials. The notation is: X ~ B(n, p) \u03bc = np  and the standard deviation is $$\\(\\sigma = ~\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\begin{pmatrix}\nn \\\\\nx \\\\\n\\end{pmatrix}p^{x}q^{n - x}\\)$$."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "     Given a random variable (RV) with known mean $$\\(\\mu\\)$$ and known standard deviation \u03c3. We are sampling with size n and we are interested in two new RVs - the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, $$\\(\\Sigma X\\)$$.If the size n of the sample is sufficiently large, then $$\\(\\left. \\overline{X} \\right.\\sim N\\left( {\\mu\\text{,}\\frac{\\sigma}{\\sqrt{n}}} \\right)\\)$$ and $$\\(\\left. \\Sigma X \\right.\\sim N(n\\mu,\\sqrt{n}\\sigma)\\)$$. If the size n of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distribution regardless of the shape of the population. The mean of the sample  means will equal the population mean and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:The desired confidence level.Information that is known about the  distribution (for example, known standard deviation).The sample and its size."
                },
                {
                    "name": "Hypothesis",
                    "description": "a statement about the value of a population parameter, in case of two hypotheses, the statement assumed to be true is called the null hypothesis (notation H0) and the contradictory statement is called the alternative hypothesis (notation Ha)."
                },
                {
                    "name": "Hypothesis Testing",
                    "description": "Based on sample evidence, a procedure for determining whether the hypothesis stated is a reasonable statement and should not be rejected, or is unreasonable and should be rejected.    "
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x) = ~\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\\frac{- {(x - \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution, and \u03c3 is the standard deviation, notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "p-value",
                    "description": "the probability that an event will happen purely by chance assuming the null hypothesis is true. The smaller the p-value, the stronger the evidence is against the null hypothesis."
                },
                {
                    "name": "Standard Deviation",
                    "description": "a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student. The major characteristics of the random variable (RV) are:It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n gets larger.There is a \"family\" of t distributions: every representative of the family is completely defined by the number of degrees of freedom which is one less than the number of data items."
                },
                {
                    "name": "Type 1 Error",
                    "description": "The decision is to reject the null hypothesis when, in fact, the null hypothesis is true.    "
                },
                {
                    "name": "Type 2 Error",
                    "description": "The decision is not to reject the null hypothesis when, in fact, the null hypothesis is false.    "
                }
            ]
        },
        {
            "title": "9-5-additional-information-and-full-hypothesis-test-examples",
            "paragraphs": [
                {
                    "context": "The traditional way to compare the two probabilities, \u03b1 and the p-value, is to compare the critical value (z-score from \u03b1) to the test statistic (z-score from data). The calculated test statistic for the p-value is \u20132.08. (From the Central Limit Theorem, the test statistic formula is $$\\(z = \\frac{\\overline{x} - \\mu_{X}}{(\\frac{\\sigma_{X}}{\\sqrt{n}})}\\)$$.LINK THIS PLEASE For this problem, $$\\(\\overline{x}\\)$$ = 16, \u03bcX = 16.43 from the null hypothes is, \u03c3X = 0.8, and n = 15.) You can find the critical value for \u03b1 = 0.05 in the normal table (see 15.Tables in the Table of Contents). The z-score for an area to the left equal to 0.05 is midway between \u20131.65 and \u20131.64 (0.05 is midway between 0.0505 and 0.0495). The z-score is \u20131.645. Since \u20131.645 > \u20132.08 (which demonstrates that \u03b1 > p-value), reject H0. Traditionally, the decisionto reject or not reject was done in this way. Today, comparing the two probabilities \u03b1 and the p-value is very common. For this problem, the p-value, 0.0187 is considerably smaller than \u03b1, 0.05. You can be confident about your decision to reject. The graph shows \u03b1, the p-value, and the test statistic and the critical value.\n\nThe next example is a poem written by a statistics student named Nicole Hart. The solution to the problem follows the poem. Notice that the hypothesis test is for a single population proportion. This means that the null and alternate hypotheses use the parameter p. The distribution for the test is normal. The estimated proportion p\u2032 is the proportion of fleas killed to the total fleas found on Fido. This is sample information. The problem gives a preconceived \u03b1 = 0.01, for comparison, and a 95% confidence interval computation. The poem is clever and humorous, so please enjoy it!",
                    "id": "C_411672_1"
                }
            ],
            "section_title": "Historical Note (Example 9.11",
            "chapter_learning_objectives": [],
            "chapter_summary": "The hypothesis test itself has an established process. This can be summarized as follows:Determine H0 and Ha. Remember, they are contradictory. Determine the random variable. Determine the distribution for the test. Draw a graph, calculate the test statistic, and use the test statistic to calculate thep-value. (A z-score and a t-score are examples of test statistics.) Compare the preconceived \u03b1 with the p-value, make a decision (reject or do not reject H0), and write a clear conclusion using English sentences. Notice that in performing the hypothesis test, you use \u03b1 and not \u03b2. \u03b2 is needed to help determine the sample size of the data that is used in calculating the p-value. Remember that the quantity 1 \u2013 \u03b2 is called the Power of the Test. A high power is desirable. If the power is too low, statisticians typically increase the sample size while keeping \u03b1 the same. If the power is low, the null hypothesis might not be rejected when it should be.",
            "chapter_introduction": "In a hypothesis test problem, you may see words such as \"the level of significance is 1%.\" The \"1%\" is the preconceived or preset \u03b1. The statistician setting up the hypothesis test selects the value of \u03b1 to use before collecting the sample data. If no level of significance is given, a common standard to use is \u03b1 = 0.05. When you calculate the p-value and draw the picture, the p-value is the area in the left tail, the right tail, or split evenly between the two tails. For this reason, we call the hypothesis test left, right, or two tailed. The alternative hypothesis, $$\\(H_{a}\\)$$, tells you if the test is left, right, or two-tailed. It is the key to conducting the appropriate test. Ha never has a symbol that contains an equal sign. Thinking about the meaning of the p-value: A data analyst (and anyone else) should have more confidence that he made the correct decision to reject the null hypothesis with a smaller p-value (for example, 0.001 as opposed to 0.04) even if using the 0.05 level for alpha. Similarly, for a large p-value such as 0.4, as opposed to a p-value of 0.056 (alpha = 0.05 is less than either number), a data analyst should have more confidence that she made the correct decision in not rejecting the null hypothesis.  This makes the data analyst use judgment rather than mindlessly applying rules. \n\nThe following examples illustrate a left-, right-, and two-tailed test.",
            "bold_terms": [
                "hypothesis test",
                "before",
                "If no level of significance is given, a common standard to use is \u03b1 = 0.05",
                "alternative hypothesis",
                "key",
                "never",
                "Thinking about the meaning of the",
                "p-value",
                "15.Tables"
            ],
            "chapter_concept": [
                {
                    "name": "Binomial Distribution",
                    "description": "a discrete random variable (RV) that arises from Bernoulli trials. There are a fixed number, n, of independent trials. \u201cIndependent\u201d means that the result of any trial (for example, trial 1) does not affect the results of the following trials, and all trials are conducted under the same conditions. Under these circumstances the binomial RV \u03a7 is defined as the number of successes in n trials. The notation is: X ~ B(n, p) \u03bc = np  and the standard deviation is $$\\(\\sigma = ~\\sqrt{npq}\\)$$. The probability of exactly x successes in n trials is $$\\(P(X = x) = \\begin{pmatrix}\nn \\\\\nx \\\\\n\\end{pmatrix}p^{x}q^{n - x}\\)$$."
                },
                {
                    "name": "Central Limit Theorem",
                    "description": "     Given a random variable (RV) with known mean $$\\(\\mu\\)$$ and known standard deviation \u03c3. We are sampling with size n and we are interested in two new RVs - the sample mean, $$\\(\\overline{X}\\)$$, and the sample sum, $$\\(\\Sigma X\\)$$.If the size n of the sample is sufficiently large, then $$\\(\\left. \\overline{X} \\right.\\sim N\\left( {\\mu\\text{,}\\frac{\\sigma}{\\sqrt{n}}} \\right)\\)$$ and $$\\(\\left. \\Sigma X \\right.\\sim N(n\\mu,\\sqrt{n}\\sigma)\\)$$. If the size n of the sample is sufficiently large, then the distribution of the sample means and the distribution of the sample sums will approximate a normal distribution regardless of the shape of the population. The mean of the sample  means will equal the population mean and the mean of the sample sums will equal n times the population mean. The standard deviation of the distribution of the sample means, $$\\(\\frac{\\sigma}{\\sqrt{n}}\\)$$, is called the standard error of the mean."
                },
                {
                    "name": "Confidence Interval (CI)",
                    "description": "an interval estimate for an unknown population parameter. This depends on:The desired confidence level.Information that is known about the  distribution (for example, known standard deviation).The sample and its size."
                },
                {
                    "name": "Hypothesis",
                    "description": "a statement about the value of a population parameter, in case of two hypotheses, the statement assumed to be true is called the null hypothesis (notation H0) and the contradictory statement is called the alternative hypothesis (notation Ha)."
                },
                {
                    "name": "Hypothesis Testing",
                    "description": "Based on sample evidence, a procedure for determining whether the hypothesis stated is a reasonable statement and should not be rejected, or is unreasonable and should be rejected.    "
                },
                {
                    "name": "Normal Distribution",
                    "description": "a continuous random variable (RV) with pdf $$\\(f(x) = ~\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\\frac{- {(x - \\mu)}^{2}}{2\\sigma^{2}}}\\)$$, where \u03bc is the mean of the distribution, and \u03c3 is the standard deviation, notation: X ~ N(\u03bc, \u03c3). If \u03bc = 0 and \u03c3 = 1, the RV is called the standard normal distribution."
                },
                {
                    "name": "p-value",
                    "description": "the probability that an event will happen purely by chance assuming the null hypothesis is true. The smaller the p-value, the stronger the evidence is against the null hypothesis."
                },
                {
                    "name": "Standard Deviation",
                    "description": "a number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Student's t-Distribution",
                    "description": "investigated and reported by William S. Gossett in 1908 and published under the pseudonym Student. The major characteristics of the random variable (RV) are:It is continuous and assumes any real values.The pdf is symmetrical about its mean of zero. However, it is more spread out and flatter at the apex than the normal distribution.It approaches the standard normal distribution as n gets larger.There is a \"family\" of t distributions: every representative of the family is completely defined by the number of degrees of freedom which is one less than the number of data items."
                },
                {
                    "name": "Type 1 Error",
                    "description": "The decision is to reject the null hypothesis when, in fact, the null hypothesis is true.    "
                },
                {
                    "name": "Type 2 Error",
                    "description": "The decision is not to reject the null hypothesis when, in fact, the null hypothesis is false.    "
                }
            ]
        },
        {
            "title": "10-1-two-population-means-with-unknown-standard-deviations",
            "paragraphs": [
                {
                    "context": "The test comparing two independent population means with unknown and possibly unequal population standard deviations is called the Aspin-Welch t-test.  The degrees of freedom formula was developed by Aspin-Welch.\n\nThe comparison of two population means is very common. A difference between the two samples depends on both the means and the standard deviations. Very different means can occur by chance if there is great variation among the individual samples. In order to account for the variation, we take the difference of the sample means,$$\\({\\overline{X}}_{1}\\)$$ \u2013 $$\\({\\overline{X}}_{2}\\)$$, and divide by the standard error in order to standardize the difference. The result is a t-score test statistic.\n\nBecause we do not know the population standard deviations, we estimate them using the two sample standard deviations from our independent samples. For the hypothesis test, we calculate the estimated standard deviation, or standard error, of the difference in sample means, $$\\({\\overline{X}}_{1}\\)$$ \u2013 $$\\({\\overline{X}}_{2}\\)$$.\n\n$$\\[\\sqrt{\\frac{\\left( s_{1} \\right)^{2}}{n_{1}} + \\frac{\\left( s_{2} \\right)^{2}}{n_{2}}}\\]$$\n\nThe test statistic (t-score) is calculated as follows:  \n\n$$\\[\\frac{\\text{(}{\\overline{x}}_{1}\u2013{\\overline{x}}_{2}\\text{)}\u2013\\text{(}\\mu_{1}\u2013\\mu_{2}\\text{)}}{\\sqrt{\\frac{{\\text{(}s_{1}\\text{)}}^{2}}{n_{1}} + \\frac{{\\text{(}s_{2}\\text{)}}^{2}}{n_{2}}}}\\]$$\n\nThe number of degrees of freedom (df) requires a somewhat complicated calculation. However, a computer or calculator calculates it easily. The df are not always a whole number. The test statistic calculated previously is approximated by the Student's t-distribution with df as follows:\n\n$$\\[df = \\frac{\\left( {\\frac{{(s_{1})}^{2}}{n_{1}} + \\frac{{(s_{2})}^{2}}{n_{2}}} \\right)^{2}}{\\left( \\frac{1}{n_{1}\u20131} \\right)\\left( \\frac{{(s_{1})}^{2}}{n_{1}} \\right)^{2} + \\left( \\frac{1}{n_{2}\u20131} \\right)\\left( \\frac{{(s_{2})}^{2}}{n_{2}} \\right)^{2}}\\]$$\n\nWhen both sample sizes n1 and n2 are five or larger, the Student's t approximation is very good. Notice that the sample variances (s1)2 and (s2)2 are not pooled. (If the question comes up, do not pool the variances.)",
                    "id": "C_597254_0"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "Two population means from independent samples where the population standard deviations are not knownRandom Variable: $$\\({\\overline{X}}_{1} - {\\overline{X}}_{2}\\)$$ = the difference of the sampling means Distribution: Student's t-distribution with degrees of freedom (variances not pooled) ",
            "chapter_introduction": "The two independent samples are simple random samples from two distinct populations. For the two distinct populations:if the sample sizes are small, the distributions are important (should be normal)if the sample sizes are large, the distributions are not important (need not be normal) ",
            "bold_terms": [
                "standard error",
                "the difference in sample means",
                "degrees of freedom (df",
                "Cohen's d"
            ],
            "chapter_concept": [
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary."
                },
                {
                    "name": "Pooled Proportion",
                    "description": "estimate of the common value of p1 and p2."
                },
                {
                    "name": "Standard Deviation",
                    "description": "A number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variable (Random Variable)",
                    "description": "a characteristic of interest in a population being studied. Common notation for variables are upper-case Latin letters X, Y, Z,...  Common notation for a specific value from the domain (set of all possible values of a variable) are lower-case Latin letters x, y, z,.... For example, if X is the number of children in a family, then x represents a specific integer 0, 1, 2, 3, .... Variables in statistics differ from variables in intermediate algebra in the two following ways.    The domain of the random variable (RV) is not necessarily a numerical set; the domain may be expressed in words; for example, if X = hair color, then the domain is {black, blond, gray, green, orange}. We can tell what specific value x of the random variable X takes only after performing the experiment."
                }
            ]
        },
        {
            "title": "10-1-two-population-means-with-unknown-standard-deviations",
            "paragraphs": [
                {
                    "context": "It is not necessary to compute this by hand. A calculator or computer easily computes it.",
                    "id": "C_684407_1"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "Two population means from independent samples where the population standard deviations are not knownRandom Variable: $$\\({\\overline{X}}_{1} - {\\overline{X}}_{2}\\)$$ = the difference of the sampling means Distribution: Student's t-distribution with degrees of freedom (variances not pooled) ",
            "chapter_introduction": "The two independent samples are simple random samples from two distinct populations. For the two distinct populations:if the sample sizes are small, the distributions are important (should be normal)if the sample sizes are large, the distributions are not important (need not be normal) ",
            "bold_terms": [
                "standard error",
                "the difference in sample means",
                "degrees of freedom (df",
                "Cohen's d"
            ],
            "chapter_concept": [
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary."
                },
                {
                    "name": "Pooled Proportion",
                    "description": "estimate of the common value of p1 and p2."
                },
                {
                    "name": "Standard Deviation",
                    "description": "A number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variable (Random Variable)",
                    "description": "a characteristic of interest in a population being studied. Common notation for variables are upper-case Latin letters X, Y, Z,...  Common notation for a specific value from the domain (set of all possible values of a variable) are lower-case Latin letters x, y, z,.... For example, if X is the number of children in a family, then x represents a specific integer 0, 1, 2, 3, .... Variables in statistics differ from variables in intermediate algebra in the two following ways.    The domain of the random variable (RV) is not necessarily a numerical set; the domain may be expressed in words; for example, if X = hair color, then the domain is {black, blond, gray, green, orange}. We can tell what specific value x of the random variable X takes only after performing the experiment."
                }
            ]
        },
        {
            "title": "10-1-two-population-means-with-unknown-standard-deviations",
            "paragraphs": [
                {
                    "context": "When the sum of the sample sizes is larger than 30 (n1 + n2 > 30) you can use the normal distribution to approximate the Student's t.\n\nCohen's Standards for Small, Medium, and Large Effect SizesCohen's d is a measure of effect size based on the differences between two means. Cohen\u2019s d, named for United States statistician Jacob Cohen, measures the relative strength of the differences between the means of two populations based on sample data. The calculated value of effect size is then compared to Cohen\u2019s standards of small, medium, and large effect sizes.\n\nCohen's d is the measure of the difference between two means divided by the pooled standard deviation: $$\\(d = \\frac{{\\overline{x}}_{1}\u2013{\\overline{x}}_{2}}{s_{pooled}}\\)$$ where $$\\(s_{pooled} = \\sqrt{\\frac{(n_{1}\u20131)s_{1}^{2} + (n_{2}\u20131)s_{2}^{2}}{n_{1} + n_{2}\u20132}}\\)$$",
                    "id": "C_704627_2"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "Two population means from independent samples where the population standard deviations are not knownRandom Variable: $$\\({\\overline{X}}_{1} - {\\overline{X}}_{2}\\)$$ = the difference of the sampling means Distribution: Student's t-distribution with degrees of freedom (variances not pooled) ",
            "chapter_introduction": "The two independent samples are simple random samples from two distinct populations. For the two distinct populations:if the sample sizes are small, the distributions are important (should be normal)if the sample sizes are large, the distributions are not important (need not be normal) ",
            "bold_terms": [
                "standard error",
                "the difference in sample means",
                "degrees of freedom (df",
                "Cohen's d"
            ],
            "chapter_concept": [
                {
                    "name": "Degrees of Freedom (df)",
                    "description": "the number of objects in a sample that are free to vary."
                },
                {
                    "name": "Pooled Proportion",
                    "description": "estimate of the common value of p1 and p2."
                },
                {
                    "name": "Standard Deviation",
                    "description": "A number that is equal to the square root of the variance and measures how far data values are from their mean; notation: s for sample standard deviation and \u03c3 for population standard deviation."
                },
                {
                    "name": "Variable (Random Variable)",
                    "description": "a characteristic of interest in a population being studied. Common notation for variables are upper-case Latin letters X, Y, Z,...  Common notation for a specific value from the domain (set of all possible values of a variable) are lower-case Latin letters x, y, z,.... For example, if X is the number of children in a family, then x represents a specific integer 0, 1, 2, 3, .... Variables in statistics differ from variables in intermediate algebra in the two following ways.    The domain of the random variable (RV) is not necessarily a numerical set; the domain may be expressed in words; for example, if X = hair color, then the domain is {black, blond, gray, green, orange}. We can tell what specific value x of the random variable X takes only after performing the experiment."
                }
            ]
        },
        {
            "title": "11-2-goodness-of-fit-test",
            "paragraphs": [
                {
                    "context": "The expected value for each cell needs to be at least five in order for you to use this test.",
                    "id": "C_476412_0"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "To assess whether a data set fits a specific distribution, you can apply the goodness-of-fit hypothesis test that uses the chi-square distribution. The null hypothesis for this test states that the data come from the assumed distribution. The test compares observed values against the values you would expect to have if your data followed the assumed distribution. The test is almost always right-tailed. Each observation or cell category must have an expected value of at least five.",
            "chapter_introduction": "In this type of hypothesis test, you determine whether the data \"fit\" a particular distribution or not. For example, you may suspect your unknown data fit a binomial distribution. You use a chi-square test (meaning the distribution for the hypothesis test is chi-square) to determine if there is a fit or not. The null and the alternative hypotheses for this test may be written in sentences or may be stated as equations or inequalities.\n\nThe test statistic for a goodness-of-fit test is:\n\n$$\\[\\underset{k}{\\Sigma}\\frac{{(O - E)}^{2}}{E}\\]$$\n\nwhere:\n\nO = observed values (data) E = expected values (from theory) k = the number of different data cells or categories \n\nThe observed values are the data values and the expected values are the values you would expect to get if the null hypothesis were true. There are n terms of the form $$\\(\\frac{{(O - E)}^{2}}{E}\\)$$.\n\nThe number of degrees of freedom is df = (number of categories \u2013 1).\n\nThe goodness-of-fit test is almost always right-tailed. If the observed values and the corresponding expected values are not close to each other, then the test statistic can get very large and will be way out in the right tail of the chi-square curve.",
            "bold_terms": [
                "fit",
                "The null and the alternative hypotheses for this test may be written in sentences or may be stated as equations or inequalities",
                "observed values",
                "expected values",
                "The observed values are the data values and the expected values are the values you would expect to get if the null hypothesis were true",
                "The goodness-of-fit test is almost always right-tailed"
            ],
            "chapter_concept": [
                {
                    "name": "Contingency Table",
                    "description": "a table that displays sample values for two different factors that may be dependent or contingent on one another; it facilitates determining conditional probabilities."
                }
            ]
        },
        {
            "title": "11-3-test-of-independence",
            "paragraphs": [
                {
                    "context": "The expected value for each cell needs to be at least five in order for you to use this test.",
                    "id": "C_700547_0"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "To assess whether two factors are independent or not, you can apply the test of independence that uses the chi-square distribution. The null hypothesis for this test states that the two factors are independent. The test compares observed values to expected values. The test is right-tailed. Each observation or cell category must have an expected value of at least 5.",
            "chapter_introduction": "Tests of independence involve using a contingency table of observed (data) values.\n\nThe test statistic for a test of independence is similar to that of a goodness-of-fit test:\n\n$$\\[\\underset{(i \\cdot j)}{\\Sigma}\\frac{{(O\u2013E)}^{2}}{E}\\]$$\n\nwhere:\n\nO = observed values E = expected values i = the number of rows in the table j = the number of columns in the table \n\nThere are $$\\(i \\cdot j\\)$$ terms of the form $$\\(\\frac{{(O\u2013E)}^{2}}{E}\\)$$. \n\nA test of independence determines whether two factors are independent or not. You first encountered the term independence in Probability Topics. As a review, consider the following example.",
            "bold_terms": [
                "contingency table",
                "test of independence",
                "A test of independence determines whether two factors are independent or not"
            ],
            "chapter_concept": [
                {
                    "name": "Contingency Table",
                    "description": "a table that displays sample values for two different factors that may be dependent or contingent on one another; it facilitates determining conditional probabilities."
                }
            ]
        },
        {
            "title": "11-4-test-for-homogeneity",
            "paragraphs": [
                {
                    "context": "The expected value for each cell needs to be at least five in order for you to use this test.\n\nHypothesesH0: The distributions of the two populations are the same.Ha:  The distributions of the two populations are not the same.\n\nTest StatisticUse a $$\\(\\chi^{2}\\)$$  test statistic.  It is computed in the same way as the test for independence.  \n\nDegrees of Freedom (df)df = number of columns - 1\n\nRequirementsAll values in the table must be greater than or equal to five. \n\nCommon UsesComparing two populations. For example:  men vs. women, before vs. after, east vs. west. The variable is categorical with more than two possible response values. ",
                    "id": "C_262187_0"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "To assess whether two data sets are derived from the same distribution\u2014which need not be known, you can apply the test for homogeneity that uses the chi-square distribution. The null hypothesis for this test states that the populations of the two data sets come from the same distribution. The test compares the observed values against the expected values if the two populations followed the same distribution. The test is right-tailed. Each observation or cell category must have an expected value of at least five.",
            "chapter_introduction": "The goodness\u2013of\u2013fit test can be used to decide whether a population fits a given distribution, but it will not suffice to decide whether two populations follow the same unknown distribution. A different test, called the test for homogeneity, can be used to draw a conclusion about whether two populations have the same distribution. To calculate the test statistic for a test for homogeneity, follow the same procedure as with the test of independence.",
            "bold_terms": [
                "test for homogeneity"
            ],
            "chapter_concept": [
                {
                    "name": "Contingency Table",
                    "description": "a table that displays sample values for two different factors that may be dependent or contingent on one another; it facilitates determining conditional probabilities."
                }
            ]
        },
        {
            "title": "12-1-linear-equations",
            "paragraphs": [
                {
                    "context": "For the linear equation y = a + bx, b = slope and a = y-intercept. From algebra recall that the slope is a number that describes the steepness of a line, and the y-intercept is the y coordinate of the point (0, a) where the line crosses the y-axis.",
                    "id": "C_28151_0"
                }
            ],
            "section_title": "Slope and Y-Intercept of a Linear Equation",
            "chapter_learning_objectives": [],
            "chapter_summary": "The most basic type of association is a linear association. This type of relationship can be defined algebraically by the equations used, numerically with actual or predicted data values, or graphically from a plotted curve. (Lines are classified as straight curves.) Algebraically, a linear equation typically takes the form y = mx + b, where m and b are constants, x is the independent variable, y is the dependent variable. In a statistical context, a linear equation is written in the form y = a + bx, where a and b are the constants. This form is used to help readers distinguish the statistical context from the algebraic context. In the equation y = a + bx, the constant b, called a coefficient, represents the slope. The constant a is called the y-intercept.The slope of a line is a value that describes the rate of change between the independent and dependent variables. The slope tells us how the dependent variable (y) changes for every one unit increase in the independent (x) variable, on average. The y-intercept is used to describe the dependent variable when the independent variable equals zero.",
            "chapter_introduction": "Linear regression for two variables is based on a linear equation with one independentvariable. The equation has the form:\n\n$$\\[y = a + \\text{bx}\\]$$\n\nwhere a and b are constant numbers.\n\nThe variable x is the independent variable, and y is the dependent variable. Typically, you choose a value to substitute for the independent variable and then solve for the dependent variable.\n\nThe graph of a linear equation of the form y = a + bx is a straight line. Any line that is not vertical can be described by this equation.",
            "bold_terms": [
                "x is the independent variable, and y is the dependent variable",
                "straight line"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-2-scatter-plots",
            "paragraphs": [
                {
                    "context": "Enter your X data into list L1 and your Y data into list L2. Press 2nd STATPLOT ENTER to use Plot 1.  On the input screen for PLOT 1, highlight On and press ENTER. (Make sure the other plots are OFF.) For TYPE: highlight the very first icon, which is the scatter plot, and press ENTER. For Xlist:, enter L1 ENTER and for Ylist: L2 ENTER. For Mark: it does not matter which symbol you highlight, but the square is the easiest to see. Press ENTER. Make sure there are no other equations that could be plotted.  Press Y = and clear any equations out. Press the ZOOM key and then the number 9 (for menu item \"ZoomStat\") ; the calculator will fit the window to the data.  You can press WINDOW to see the scaling of the axes. \n\nA scatter plot shows the direction of a relationship between the variables. A clear direction happens when there is either:\n\nHigh values of one variable occurring with high values of the other variable or low values of one variable occurring with low values of the other variable. High values of one variable occurring with low values of the other variable. \n\nYou can determine the strength of the relationship by looking at the scatter plot and seeing how close the points are to a line, a power function, an exponential function,or to some other type of function.  For a linear relationship there is an exception. Consider a scatter plot where all the points fall on a horizontal line providing a \"perfect fit.\" The horizontal line would in fact show no relationship.\n\nWhen you look at a scatterplot, you want to notice the overall pattern and any deviations from the pattern. The following scatterplot examples illustrate these concepts.\n\nIn this chapter, we are interested in scatter plots that show a linear pattern. Linear patterns are quite common. The linear relationship is strong if the points are close to a straight line,  except in the case of a horizontal line where there is no relationship. If we think that the points show a linear relationship, we would like to draw a line on the scatter plot. This line can be calculated through a process called linear regression. However, we only calculate a regression line if one of the variables helps to explain or predict the other variable. If x is the independent variable and y the dependent variable,then we can use a regression line to predict y for a given value of x",
                    "id": "C_711803_0"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "Scatter plots are particularly helpful graphs when we want to see if there is a linear relationship among data points. They indicate both the direction of the relationship between the x variables and the y variables, and the strength of the relationship. We calculate the strength of the relationship between an independent variable and a dependent variable using linear regression.",
            "chapter_introduction": "Before we take up the discussion of linear regression and correlation, we need to examine a way to display the relation between two variables x and y. The most common and easiest way is a scatter plot. The following example illustrates a scatter plot.",
            "bold_terms": [
                "scatter plot",
                "direction",
                "strength",
                "overall pattern",
                "deviations",
                "linear regression"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-3-the-regression-equation",
            "paragraphs": [
                {
                    "context": "If you know a person's pinky (smallest) finger length, do you think you could predict thatperson's height? Collect data from your class (pinky finger length, in inches). Theindependent variable, x, is pinky finger length and the dependent variable, y, is height. For each set of data, plot the points on graph paper. Make your graph big enough and use a ruler. Then \"by eye\" draw a line that appears to \"fit\" the data. For your line, pick two convenient points and use them to find the slope of the line. Find the y-intercept of the line by extending your line so it crosses the y-axis. Using the slopes and the y-intercepts, write your equation of \"best fit.\" Do you think everyone will have the same equation? Why or why not? According to your equation, what is the predicted height for a pinky length of 2.5 inches?\n\nThe third exam score, x, is the independent variable and the final exam score, y, is the dependent variable. We will plot a regression line that best \"fits\" the data. If each of you were to fit a line \"by eye,\" you would draw different lines. We can use what is called a least-squares regression line to obtain the best fit line.\n\nConsider the following diagram. Each point of data is of the the form (x, y) and each point of the line of best fit using least-squares linear regression has the form (x, \u0177).\n\nThe \u0177 is read \"y hat\" and is the estimated value of y. It is the value of y obtained using the regression line. It is not generally equal to y from data.\n\nThe term y0 \u2013 \u01770 = \u03b50 is called the \"error\" or residual. It is not an error in the sense of a mistake. The absolute value of a residual measures the vertical distance between the actual value of y and the estimated value of y. In other words, it measures the vertical distance between the actual data point and the predicted point on the line.\n\nIf the observed data point lies above the line, the residual is positive, and the line underestimates the actual data value for y.  If the observed data point lies below the line, the residual is negative, and the line overestimates that actual data value for y.\n\nIn the diagram in Figure 12.10, y0 \u2013 \u01770 = \u03b50 is the residual for the point shown. Here the point lies above the line and the residual is positive.\n\n\u03b5 = the Greek letter epsilon\n\nFor each data point, you can calculate the residuals or errors, yi - \u0177i = \u03b5i for i = 1, 2, 3, ..., 11.\n\nEach |\u03b5| is a vertical distance.\n\nFor the example about the third exam scores and the final exam scores for the 11 statistics students, there are 11 data points. Therefore, there are 11 \u03b5 values. If you square each \u03b5 and add, you get\n\n$$\\({(\\varepsilon_{1})}^{2} + {(\\varepsilon_{2})}^{2} + ... + {(\\varepsilon_{11})}^{2} = \\overset{11}{\\underset{i\\  = \\ 1}{\\Sigma}}\\varepsilon^{2}\\)$$\n\nThis is called the Sum of Squared Errors (SSE).\n\nUsing calculus, you can determine the values of a and b that make the SSE a minimum. When you make the SSE aminimum, you have determined the points that are on the line of best fit. It turns out thatthe line of best fit has the equation:\n\n$$\\[\\hat{y} = a + bx\\]$$\n\nwhere $$\\(a = \\overline{y} - b\\overline{x}\\)$$ and $$\\(b = \\frac{\\Sigma(x - \\overline{x})(y - \\overline{y})}{\\Sigma{(x - \\overline{x})}^{2}}\\)$$.\n\nThe sample means of the x values and the y values are $$\\(\\overline{x}\\)$$ and $$\\(\\overline{y}\\)$$, respectively. The best fit line always passes through the point $$\\((\\overline{x},\\overline{y})\\)$$.\n\nThe slope b can be written as $$\\(b = r\\left( \\frac{s_{y}}{s_{x}} \\right)\\)$$ where sy = the standard deviation of the y values and sx = the standard deviation of the x values. r is the correlationcoefficient, which is discussed in the next section.",
                    "id": "C_571922_0"
                }
            ],
            "section_title": "Collaborative Exercise",
            "chapter_learning_objectives": [],
            "chapter_summary": "A regression line, or a line of best fit, can be drawn on a scatter plot and used to predict outcomes for the x and y variables in a given data set or sample data. There are several ways to find a regression line, but usually the least-squares regression line is used because it creates a uniform line. Residuals, also called \u201cerrors,\u201d measure the distance from the actual value of y and the estimated value of y. The Sum of Squared Errors, when set to its minimum, calculates the points on the line of best fit. Regression lines can be used to predict values within the given set of data, but should not be used to make predictions for values outside the set of data.The correlation coefficient r measures the strength of the linear association between x and y. The variable r has to be between \u20131 and +1. When r is positive, the x and y will tend to increase and decrease together. When r is negative, x will increase and y will decrease, or the opposite, x will decrease and y will increase. The coefficient of determination r2, is equal to the square of the correlation coefficient. When expressed as a percent, r2 represents the percent of variation in the dependent variable y that can be explained by variation in the independent variable x using the regression line.",
            "chapter_introduction": "Data rarely fit a straight line exactly. Usually, you must be satisfied with roughpredictions. Typically, you have a set of data whose scatter plot appears to \"fit\" astraight line. This is called a Line of Best Fit or Least-Squares Line.",
            "bold_terms": [
                "fit",
                "Line of Best Fit",
                "or",
                "Least-Squares Line",
                "use a ruler",
                "least-squares regression line",
                "y hat",
                "estimated value of y",
                "error\" or",
                "residual",
                "absolute value of a residual",
                "epsilon",
                "Sum of Squared Errors (SSE",
                "SSE",
                "linear regression",
                "least-squares regression line",
                "but not necessarily for x-values outside that domain",
                "INTERPRETATION OF THE SLOPE",
                "On",
                "correlation coefficient, r",
                "positive correlation",
                "negative correlation",
                "The variable r2 is called the",
                "coefficient of determination",
                "Interpretation of r2 in the context of this example"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-3-the-regression-equation",
            "paragraphs": [
                {
                    "context": "The process of fitting the best-fit line is called linear regression. The idea behind finding the best-fit line is based on the assumption that the data are scattered about a straight line. The criteria for the best fit line is that the sum of the squared errors (SSE) is minimized, that is, made as small as possible. Any other line you might choose would have a higher SSE than the best fit line. This best fit line is called the  least-squares regression line .",
                    "id": "C_384710_1"
                }
            ],
            "section_title": "Least Squares Criteria for Best Fit",
            "chapter_learning_objectives": [],
            "chapter_summary": "A regression line, or a line of best fit, can be drawn on a scatter plot and used to predict outcomes for the x and y variables in a given data set or sample data. There are several ways to find a regression line, but usually the least-squares regression line is used because it creates a uniform line. Residuals, also called \u201cerrors,\u201d measure the distance from the actual value of y and the estimated value of y. The Sum of Squared Errors, when set to its minimum, calculates the points on the line of best fit. Regression lines can be used to predict values within the given set of data, but should not be used to make predictions for values outside the set of data.The correlation coefficient r measures the strength of the linear association between x and y. The variable r has to be between \u20131 and +1. When r is positive, the x and y will tend to increase and decrease together. When r is negative, x will increase and y will decrease, or the opposite, x will decrease and y will increase. The coefficient of determination r2, is equal to the square of the correlation coefficient. When expressed as a percent, r2 represents the percent of variation in the dependent variable y that can be explained by variation in the independent variable x using the regression line.",
            "chapter_introduction": "Data rarely fit a straight line exactly. Usually, you must be satisfied with roughpredictions. Typically, you have a set of data whose scatter plot appears to \"fit\" astraight line. This is called a Line of Best Fit or Least-Squares Line.",
            "bold_terms": [
                "fit",
                "Line of Best Fit",
                "or",
                "Least-Squares Line",
                "use a ruler",
                "least-squares regression line",
                "y hat",
                "estimated value of y",
                "error\" or",
                "residual",
                "absolute value of a residual",
                "epsilon",
                "Sum of Squared Errors (SSE",
                "SSE",
                "linear regression",
                "least-squares regression line",
                "but not necessarily for x-values outside that domain",
                "INTERPRETATION OF THE SLOPE",
                "On",
                "correlation coefficient, r",
                "positive correlation",
                "negative correlation",
                "The variable r2 is called the",
                "coefficient of determination",
                "Interpretation of r2 in the context of this example"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-3-the-regression-equation",
            "paragraphs": [
                {
                    "context": "Computer spreadsheets, statistical software, and many calculators can quickly calculate the best-fit line and create the graphs. The calculations tend to be tedious if done by hand. Instructions to use the TI-83, TI-83+, and TI-84+ calculators to find the best-fit line and create a scatterplot are shown at the end of this section.\n\nTHIRD EXAM vs FINAL EXAM EXAMPLE:The graph of the line of best fit for the third-exam/final-exam example is as follows:\n\nThe least squares regression line (best-fit line) for the third-exam/final-exam example has the equation:\n\n$$\\[\\hat{y} = - 173.51 + 4.83x\\]$$",
                    "id": "C_224780_2"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "A regression line, or a line of best fit, can be drawn on a scatter plot and used to predict outcomes for the x and y variables in a given data set or sample data. There are several ways to find a regression line, but usually the least-squares regression line is used because it creates a uniform line. Residuals, also called \u201cerrors,\u201d measure the distance from the actual value of y and the estimated value of y. The Sum of Squared Errors, when set to its minimum, calculates the points on the line of best fit. Regression lines can be used to predict values within the given set of data, but should not be used to make predictions for values outside the set of data.The correlation coefficient r measures the strength of the linear association between x and y. The variable r has to be between \u20131 and +1. When r is positive, the x and y will tend to increase and decrease together. When r is negative, x will increase and y will decrease, or the opposite, x will decrease and y will increase. The coefficient of determination r2, is equal to the square of the correlation coefficient. When expressed as a percent, r2 represents the percent of variation in the dependent variable y that can be explained by variation in the independent variable x using the regression line.",
            "chapter_introduction": "Data rarely fit a straight line exactly. Usually, you must be satisfied with roughpredictions. Typically, you have a set of data whose scatter plot appears to \"fit\" astraight line. This is called a Line of Best Fit or Least-Squares Line.",
            "bold_terms": [
                "fit",
                "Line of Best Fit",
                "or",
                "Least-Squares Line",
                "use a ruler",
                "least-squares regression line",
                "y hat",
                "estimated value of y",
                "error\" or",
                "residual",
                "absolute value of a residual",
                "epsilon",
                "Sum of Squared Errors (SSE",
                "SSE",
                "linear regression",
                "least-squares regression line",
                "but not necessarily for x-values outside that domain",
                "INTERPRETATION OF THE SLOPE",
                "On",
                "correlation coefficient, r",
                "positive correlation",
                "negative correlation",
                "The variable r2 is called the",
                "coefficient of determination",
                "Interpretation of r2 in the context of this example"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-3-the-regression-equation",
            "paragraphs": [
                {
                    "context": "Remember, it is always important to plot a scatter diagram first. If the scatter plot indicates that there is a linear relationship between the variables, then it is reasonable to use a best fit line to make predictions for y given x within the domain of x-values in the sample data, but not necessarily for x-values outside that domain. You could use the line to predict the final exam score for a student who earned a grade of 73 on the third exam. You should NOT use the line to predict the final exam score for a student who earned a grade of 50 on the third exam, because 50 is not within the domain of the x-values in the sample data, which are between 65 and 75.",
                    "id": "C_746381_3"
                }
            ],
            "section_title": "Reminder",
            "chapter_learning_objectives": [],
            "chapter_summary": "A regression line, or a line of best fit, can be drawn on a scatter plot and used to predict outcomes for the x and y variables in a given data set or sample data. There are several ways to find a regression line, but usually the least-squares regression line is used because it creates a uniform line. Residuals, also called \u201cerrors,\u201d measure the distance from the actual value of y and the estimated value of y. The Sum of Squared Errors, when set to its minimum, calculates the points on the line of best fit. Regression lines can be used to predict values within the given set of data, but should not be used to make predictions for values outside the set of data.The correlation coefficient r measures the strength of the linear association between x and y. The variable r has to be between \u20131 and +1. When r is positive, the x and y will tend to increase and decrease together. When r is negative, x will increase and y will decrease, or the opposite, x will decrease and y will increase. The coefficient of determination r2, is equal to the square of the correlation coefficient. When expressed as a percent, r2 represents the percent of variation in the dependent variable y that can be explained by variation in the independent variable x using the regression line.",
            "chapter_introduction": "Data rarely fit a straight line exactly. Usually, you must be satisfied with roughpredictions. Typically, you have a set of data whose scatter plot appears to \"fit\" astraight line. This is called a Line of Best Fit or Least-Squares Line.",
            "bold_terms": [
                "fit",
                "Line of Best Fit",
                "or",
                "Least-Squares Line",
                "use a ruler",
                "least-squares regression line",
                "y hat",
                "estimated value of y",
                "error\" or",
                "residual",
                "absolute value of a residual",
                "epsilon",
                "Sum of Squared Errors (SSE",
                "SSE",
                "linear regression",
                "least-squares regression line",
                "but not necessarily for x-values outside that domain",
                "INTERPRETATION OF THE SLOPE",
                "On",
                "correlation coefficient, r",
                "positive correlation",
                "negative correlation",
                "The variable r2 is called the",
                "coefficient of determination",
                "Interpretation of r2 in the context of this example"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-3-the-regression-equation",
            "paragraphs": [
                {
                    "context": "The slope of the line, b, describes how changes in the variables are related. It is important to interpret the slope of the line in the context of the situation represented by the data. You should be able to write a sentence interpreting the slope in plain English.\n\nINTERPRETATION OF THE SLOPE: The slope of the best-fit line tells us how the dependent variable (y) changes for every one unit increase in the independent (x) variable, on average. \n\nTHIRD EXAM vs FINAL EXAM EXAMPLESlope: The slope of the line is b = 4.83.Interpretation: For a one-point increase in the score on the third exam, the final exam score increases by 4.83 points, on average.",
                    "id": "C_617352_4"
                }
            ],
            "section_title": "UNDERSTANDING SLOPE",
            "chapter_learning_objectives": [],
            "chapter_summary": "A regression line, or a line of best fit, can be drawn on a scatter plot and used to predict outcomes for the x and y variables in a given data set or sample data. There are several ways to find a regression line, but usually the least-squares regression line is used because it creates a uniform line. Residuals, also called \u201cerrors,\u201d measure the distance from the actual value of y and the estimated value of y. The Sum of Squared Errors, when set to its minimum, calculates the points on the line of best fit. Regression lines can be used to predict values within the given set of data, but should not be used to make predictions for values outside the set of data.The correlation coefficient r measures the strength of the linear association between x and y. The variable r has to be between \u20131 and +1. When r is positive, the x and y will tend to increase and decrease together. When r is negative, x will increase and y will decrease, or the opposite, x will decrease and y will increase. The coefficient of determination r2, is equal to the square of the correlation coefficient. When expressed as a percent, r2 represents the percent of variation in the dependent variable y that can be explained by variation in the independent variable x using the regression line.",
            "chapter_introduction": "Data rarely fit a straight line exactly. Usually, you must be satisfied with roughpredictions. Typically, you have a set of data whose scatter plot appears to \"fit\" astraight line. This is called a Line of Best Fit or Least-Squares Line.",
            "bold_terms": [
                "fit",
                "Line of Best Fit",
                "or",
                "Least-Squares Line",
                "use a ruler",
                "least-squares regression line",
                "y hat",
                "estimated value of y",
                "error\" or",
                "residual",
                "absolute value of a residual",
                "epsilon",
                "Sum of Squared Errors (SSE",
                "SSE",
                "linear regression",
                "least-squares regression line",
                "but not necessarily for x-values outside that domain",
                "INTERPRETATION OF THE SLOPE",
                "On",
                "correlation coefficient, r",
                "positive correlation",
                "negative correlation",
                "The variable r2 is called the",
                "coefficient of determination",
                "Interpretation of r2 in the context of this example"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-3-the-regression-equation",
            "paragraphs": [
                {
                    "context": "Using the Linear Regression T Test: LinRegTTest\n\n In the STAT list editor, enter the X data in list L1 and the Y data in list L2, paired so that the corresponding (x,y) values are next to each other in the lists. (If a particular pair of values is repeated, enter it as many times as it appears in the data.)  On the STAT TESTS menu, scroll down with the cursor to select the LinRegTTest. (Be careful to select LinRegTTest, as some calculators may also have a different item called LinRegTInt.) On the LinRegTTest input screen enter: Xlist: L1 ; Ylist: L2 ; Freq: 1 On the next line, at the prompt \u03b2 or \u03c1, highlight \"\u2260 0\" and press ENTER Leave the line for \"RegEq:\" blank Highlight Calculate and press ENTER. \n\nThe output screen contains a lot of information. For now we will focus on a few items from the output, and will return later to the other items.The second line says y = a + bx. Scroll down to find the values a = \u2013173.513, and b = 4.8273; the equation of the best fit line is \u0177 = \u2013173.51 + 4.83xThe two items at the bottom are r2 = 0.43969 and r = 0.663. For now, just note where to find these values; we will discuss them in the next two sections.\n\nGraphing the Scatterplot and Regression Line\n\nWe are assuming your X data is already entered in list L1 and your Y data is in list L2 Press 2nd STATPLOT ENTER to use Plot 1 On the input screen for PLOT 1, highlight On, and press ENTER For TYPE: highlight the very first icon which is the scatterplot and press ENTER Indicate Xlist: L1 and Ylist: L2 For Mark: it does not matter which symbol you highlight.  Press the ZOOM key and then the number 9 (for menu item \"ZoomStat\") ; the calculator will fit the window to the data   To graph the best-fit line, press the \"Y=\" key and type the equation \u2013173.5 + 4.83X into equation Y1. (The X key is immediately left of the STAT key). Press ZOOM 9 again to graph it.  Optional: If you want to change the viewing window, press the WINDOW key.  Enter your desired window using Xmin, Xmax, Ymin, Ymax ",
                    "id": "C_689553_5"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "A regression line, or a line of best fit, can be drawn on a scatter plot and used to predict outcomes for the x and y variables in a given data set or sample data. There are several ways to find a regression line, but usually the least-squares regression line is used because it creates a uniform line. Residuals, also called \u201cerrors,\u201d measure the distance from the actual value of y and the estimated value of y. The Sum of Squared Errors, when set to its minimum, calculates the points on the line of best fit. Regression lines can be used to predict values within the given set of data, but should not be used to make predictions for values outside the set of data.The correlation coefficient r measures the strength of the linear association between x and y. The variable r has to be between \u20131 and +1. When r is positive, the x and y will tend to increase and decrease together. When r is negative, x will increase and y will decrease, or the opposite, x will decrease and y will increase. The coefficient of determination r2, is equal to the square of the correlation coefficient. When expressed as a percent, r2 represents the percent of variation in the dependent variable y that can be explained by variation in the independent variable x using the regression line.",
            "chapter_introduction": "Data rarely fit a straight line exactly. Usually, you must be satisfied with roughpredictions. Typically, you have a set of data whose scatter plot appears to \"fit\" astraight line. This is called a Line of Best Fit or Least-Squares Line.",
            "bold_terms": [
                "fit",
                "Line of Best Fit",
                "or",
                "Least-Squares Line",
                "use a ruler",
                "least-squares regression line",
                "y hat",
                "estimated value of y",
                "error\" or",
                "residual",
                "absolute value of a residual",
                "epsilon",
                "Sum of Squared Errors (SSE",
                "SSE",
                "linear regression",
                "least-squares regression line",
                "but not necessarily for x-values outside that domain",
                "INTERPRETATION OF THE SLOPE",
                "On",
                "correlation coefficient, r",
                "positive correlation",
                "negative correlation",
                "The variable r2 is called the",
                "coefficient of determination",
                "Interpretation of r2 in the context of this example"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-3-the-regression-equation",
            "paragraphs": [
                {
                    "context": "Another way to graph the line after you create a scatter plot is to use LinRegTTest.\n\nMake sure you have done the scatter plot. Check it on your screen. Go to LinRegTTest and enter the lists. At RegEq: press VARS and arrow over to Y-VARS. Press 1 for 1:Function. Press 1 for 1:Y1. Then arrow down to Calculate and do the calculation for the line of best fit. Press Y = (you will see the regression equation). Press GRAPH. The line will be drawn.\"  ",
                    "id": "C_344717_6"
                }
            ],
            "section_title": "NOTE",
            "chapter_learning_objectives": [],
            "chapter_summary": "A regression line, or a line of best fit, can be drawn on a scatter plot and used to predict outcomes for the x and y variables in a given data set or sample data. There are several ways to find a regression line, but usually the least-squares regression line is used because it creates a uniform line. Residuals, also called \u201cerrors,\u201d measure the distance from the actual value of y and the estimated value of y. The Sum of Squared Errors, when set to its minimum, calculates the points on the line of best fit. Regression lines can be used to predict values within the given set of data, but should not be used to make predictions for values outside the set of data.The correlation coefficient r measures the strength of the linear association between x and y. The variable r has to be between \u20131 and +1. When r is positive, the x and y will tend to increase and decrease together. When r is negative, x will increase and y will decrease, or the opposite, x will decrease and y will increase. The coefficient of determination r2, is equal to the square of the correlation coefficient. When expressed as a percent, r2 represents the percent of variation in the dependent variable y that can be explained by variation in the independent variable x using the regression line.",
            "chapter_introduction": "Data rarely fit a straight line exactly. Usually, you must be satisfied with roughpredictions. Typically, you have a set of data whose scatter plot appears to \"fit\" astraight line. This is called a Line of Best Fit or Least-Squares Line.",
            "bold_terms": [
                "fit",
                "Line of Best Fit",
                "or",
                "Least-Squares Line",
                "use a ruler",
                "least-squares regression line",
                "y hat",
                "estimated value of y",
                "error\" or",
                "residual",
                "absolute value of a residual",
                "epsilon",
                "Sum of Squared Errors (SSE",
                "SSE",
                "linear regression",
                "least-squares regression line",
                "but not necessarily for x-values outside that domain",
                "INTERPRETATION OF THE SLOPE",
                "On",
                "correlation coefficient, r",
                "positive correlation",
                "negative correlation",
                "The variable r2 is called the",
                "coefficient of determination",
                "Interpretation of r2 in the context of this example"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-3-the-regression-equation",
            "paragraphs": [
                {
                    "context": "Besides looking at the scatter plot and seeing that a line seems reasonable, how can you tell if the line is a good predictor? Use the correlation coefficient as another indicator (besides the scatterplot) of the strength of the relationship between x and y.\n\nThe correlation coefficient, r,  developed by Karl Pearson in the early 1900s, is numerical and provides a measure of strength and direction of the linear association between the independent variable x and the dependent variable y.\n\nThe correlation coefficient is calculated as\n\n$$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$\n\nwhere n = the number of data points.\n\nIf you suspect a linear relationship between x and y, then r can measure how strong the linear relationship is.\n\nWhat the VALUE of r tells us:\n\nThe value of r is always between \u20131 and +1: \u20131 \u2264 r \u2264 1. The size of the correlation r indicates the strength of the linear relationship between x and y. Values of r close to \u20131 or to +1 indicate a stronger linear relationship between x and y. If r = 0 there is likely no linear correlation. It is important to view the scatterplot, however, because data that exhibit a curved or horizontal pattern may have a correlation of 0. If r = 1, there is perfect positive correlation. If r = \u20131, there is perfect negative correlation. In both these cases, all of the original data points lie on a straight line. Of course,in the real world, this will not generally happen. \n\nWhat the SIGN of r tells us\n\nA positive value of r means that when x increases, y tends to increase and when x decreases, y tends to decrease (positive correlation). A negative value of r means that when x increases, y tends to decrease and when x decreases, y tends to increase (negative correlation). The sign of r is the same as the sign of the slope, b, of the best-fit line. ",
                    "id": "C_275365_7"
                }
            ],
            "section_title": "The Correlation Coefficient r",
            "chapter_learning_objectives": [],
            "chapter_summary": "A regression line, or a line of best fit, can be drawn on a scatter plot and used to predict outcomes for the x and y variables in a given data set or sample data. There are several ways to find a regression line, but usually the least-squares regression line is used because it creates a uniform line. Residuals, also called \u201cerrors,\u201d measure the distance from the actual value of y and the estimated value of y. The Sum of Squared Errors, when set to its minimum, calculates the points on the line of best fit. Regression lines can be used to predict values within the given set of data, but should not be used to make predictions for values outside the set of data.The correlation coefficient r measures the strength of the linear association between x and y. The variable r has to be between \u20131 and +1. When r is positive, the x and y will tend to increase and decrease together. When r is negative, x will increase and y will decrease, or the opposite, x will decrease and y will increase. The coefficient of determination r2, is equal to the square of the correlation coefficient. When expressed as a percent, r2 represents the percent of variation in the dependent variable y that can be explained by variation in the independent variable x using the regression line.",
            "chapter_introduction": "Data rarely fit a straight line exactly. Usually, you must be satisfied with roughpredictions. Typically, you have a set of data whose scatter plot appears to \"fit\" astraight line. This is called a Line of Best Fit or Least-Squares Line.",
            "bold_terms": [
                "fit",
                "Line of Best Fit",
                "or",
                "Least-Squares Line",
                "use a ruler",
                "least-squares regression line",
                "y hat",
                "estimated value of y",
                "error\" or",
                "residual",
                "absolute value of a residual",
                "epsilon",
                "Sum of Squared Errors (SSE",
                "SSE",
                "linear regression",
                "least-squares regression line",
                "but not necessarily for x-values outside that domain",
                "INTERPRETATION OF THE SLOPE",
                "On",
                "correlation coefficient, r",
                "positive correlation",
                "negative correlation",
                "The variable r2 is called the",
                "coefficient of determination",
                "Interpretation of r2 in the context of this example"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-3-the-regression-equation",
            "paragraphs": [
                {
                    "context": "The formula for r looks formidable. However, computer spreadsheets, statistical software, and many calculators can quickly calculate r. The correlation coefficient r is the bottom item in the output screens for the LinRegTTest on the TI-83, TI-83+, or TI-84+ calculator (see previous section for instructions).",
                    "id": "C_572263_8"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "A regression line, or a line of best fit, can be drawn on a scatter plot and used to predict outcomes for the x and y variables in a given data set or sample data. There are several ways to find a regression line, but usually the least-squares regression line is used because it creates a uniform line. Residuals, also called \u201cerrors,\u201d measure the distance from the actual value of y and the estimated value of y. The Sum of Squared Errors, when set to its minimum, calculates the points on the line of best fit. Regression lines can be used to predict values within the given set of data, but should not be used to make predictions for values outside the set of data.The correlation coefficient r measures the strength of the linear association between x and y. The variable r has to be between \u20131 and +1. When r is positive, the x and y will tend to increase and decrease together. When r is negative, x will increase and y will decrease, or the opposite, x will decrease and y will increase. The coefficient of determination r2, is equal to the square of the correlation coefficient. When expressed as a percent, r2 represents the percent of variation in the dependent variable y that can be explained by variation in the independent variable x using the regression line.",
            "chapter_introduction": "Data rarely fit a straight line exactly. Usually, you must be satisfied with roughpredictions. Typically, you have a set of data whose scatter plot appears to \"fit\" astraight line. This is called a Line of Best Fit or Least-Squares Line.",
            "bold_terms": [
                "fit",
                "Line of Best Fit",
                "or",
                "Least-Squares Line",
                "use a ruler",
                "least-squares regression line",
                "y hat",
                "estimated value of y",
                "error\" or",
                "residual",
                "absolute value of a residual",
                "epsilon",
                "Sum of Squared Errors (SSE",
                "SSE",
                "linear regression",
                "least-squares regression line",
                "but not necessarily for x-values outside that domain",
                "INTERPRETATION OF THE SLOPE",
                "On",
                "correlation coefficient, r",
                "positive correlation",
                "negative correlation",
                "The variable r2 is called the",
                "coefficient of determination",
                "Interpretation of r2 in the context of this example"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-3-the-regression-equation",
            "paragraphs": [
                {
                    "context": "The variable r2 is called the coefficient of determination and is the square of the correlation coefficient, but is usually stated as a percent, rather than in decimal form. It has an interpretation in the context of the data:\n\n$$\\(r^{2}\\)$$, when expressed as a percent, represents the percent of variation in the dependent (predicted) variable y that can be explained by variation in the independent (explanatory) variable x using the regression (best-fit) line. 1 \u2013 $$\\(r^{2}\\)$$, when expressed as a percentage, represents the percent of variation in y that is NOT explained by variation in x using the regression line. This can be seen as the scattering of the observed data points about the regression line. \n\nConsider the third exam/final exam example introduced in the previous section\n\nThe line of best fit is: \u0177 = \u2013173.51 + 4.83x The correlation coefficient is r = 0.6631 The coefficient of determination is r2 = 0.66312 = 0.4397 Interpretation of r2 in the context of this example: Approximately 44% of the variation (0.4397 is approximately 0.44) in the final-exam grades can be explained by the variation in the grades on the third exam, using the best-fit regression line. Therefore, approximately 56% of the variation (1 \u2013 0.44 = 0.56) in the final exam grades can NOT be explained by the variation in the grades on the third exam, using the best-fit regression line. (This is seen as the scattering of the points about the line.) ",
                    "id": "C_146713_9"
                }
            ],
            "section_title": "The Coefficient of Determination",
            "chapter_learning_objectives": [],
            "chapter_summary": "A regression line, or a line of best fit, can be drawn on a scatter plot and used to predict outcomes for the x and y variables in a given data set or sample data. There are several ways to find a regression line, but usually the least-squares regression line is used because it creates a uniform line. Residuals, also called \u201cerrors,\u201d measure the distance from the actual value of y and the estimated value of y. The Sum of Squared Errors, when set to its minimum, calculates the points on the line of best fit. Regression lines can be used to predict values within the given set of data, but should not be used to make predictions for values outside the set of data.The correlation coefficient r measures the strength of the linear association between x and y. The variable r has to be between \u20131 and +1. When r is positive, the x and y will tend to increase and decrease together. When r is negative, x will increase and y will decrease, or the opposite, x will decrease and y will increase. The coefficient of determination r2, is equal to the square of the correlation coefficient. When expressed as a percent, r2 represents the percent of variation in the dependent variable y that can be explained by variation in the independent variable x using the regression line.",
            "chapter_introduction": "Data rarely fit a straight line exactly. Usually, you must be satisfied with roughpredictions. Typically, you have a set of data whose scatter plot appears to \"fit\" astraight line. This is called a Line of Best Fit or Least-Squares Line.",
            "bold_terms": [
                "fit",
                "Line of Best Fit",
                "or",
                "Least-Squares Line",
                "use a ruler",
                "least-squares regression line",
                "y hat",
                "estimated value of y",
                "error\" or",
                "residual",
                "absolute value of a residual",
                "epsilon",
                "Sum of Squared Errors (SSE",
                "SSE",
                "linear regression",
                "least-squares regression line",
                "but not necessarily for x-values outside that domain",
                "INTERPRETATION OF THE SLOPE",
                "On",
                "correlation coefficient, r",
                "positive correlation",
                "negative correlation",
                "The variable r2 is called the",
                "coefficient of determination",
                "Interpretation of r2 in the context of this example"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-4-testing-the-significance-of-the-correlation-coefficient",
            "paragraphs": [
                {
                    "context": "If r is significant and the scatter plot shows a  linear trend, the line can be used to predict the value ofy for values of x that are within the domain of observed x values. If r is not significant OR if the scatter plot does not show a linear trend, the line should not be used for prediction. If r is significant and if the scatter plot shows a linear trend, the line may NOT be appropriate or reliable for prediction OUTSIDE the domain of observed x values in the data. ",
                    "id": "C_945229_0"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "Linear regression is a procedure for fitting a straight line of the form \u0177 = a + bx to data. The conditions for regression are:Linear In the population, there is a linear relationship that models the average value of y for different values of x. Independent The residuals are assumed to be independent. Normal The y values are distributed normally for any value of x. Equal variance The standard deviation of the y values is equal for each x value. Random The data are produced from a well-designed random sample or randomized experiment. The slope b and intercept a of the least-squares line estimate the slope \u03b2 and intercept \u03b1 of the population (true) regression line. To estimate the population standard deviation of y, \u03c3, use the standard deviation of the residuals, s. $$\\(s = \\sqrt{\\frac{SEE}{n - 2}}\\)$$. The variable \u03c1 (rho) is the population correlation coefficient. To test the null hypothesis H0: \u03c1 = hypothesized value, use a linear regression t-test.  The most common null hypothesis is H0: \u03c1 = 0 which indicates there is no linear relationship between x and y in the population. The TI-83, 83+, 84, 84+ calculator function LinRegTTest can perform this test (STATS TESTS LinRegTTest).",
            "chapter_introduction": "The correlation coefficient, r, tells us about the strength and direction of the linear relationship between x and y. However, the reliability of the linear model also depends on how many observed data points are in the sample. We need to look at both the value of the correlation coefficient r and the sample size n, together.\n\nWe perform a hypothesis test of the  \"significance of the correlation coefficient\"  to decide whether the linear relationship in the sample data is strong enough to use to model the relationship in the population.\n\nThe sample data are used to compute r, the correlation coefficient for the sample. If we had data for the entire population, we could find the population correlation coefficient. But because we have only sample data, we cannot calculate the population correlation coefficient. The sample correlation coefficient, r, is our estimate of the unknown population correlation coefficient.\n\nThe symbol for the population correlation coefficient is \u03c1, the Greek letter \"rho.\" \u03c1 = population correlation coefficient (unknown) r = sample correlation coefficient (known; calculated from sample data) \n\nThe hypothesis test lets us decide whether the value of the population correlation coefficient \u03c1 is \"close to zero\" or \"significantly different from zero\". We decide this based on the sample correlation coefficient r and the sample size n.\n\nIf the test concludes that the correlation coefficient is significantly different from zero, we say that the correlation coefficient is \"significant.\"\n\nConclusion: There is sufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is significantly different from zero. What the conclusion means: There is a significant linear relationship between x and y. We can use the regression line to model the linear relationship between x and y in the population. \n\nIf the test concludes that the correlation coefficient is not significantly different from zero (it is close to zero), we say that correlation coefficient is \"not significant\".\n\nConclusion:  \"There is insufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is not significantly different from zero.\" What the conclusion means: There is not a significant linear relationship between x and y. Therefore, we CANNOT use the regression line to model a linear relationship between x and y in the population. ",
            "bold_terms": [
                "significance of the correlation coefficient",
                "Null Hypothesis: H0: \u03c1 = 0",
                "Alternate Hypothesis: Ha: \u03c1 \u2260 0",
                "Null Hypothesis H0",
                "Alternate Hypothesis Ha",
                "Method 1: Using the p-value",
                "Method 2: Using a table of critical values",
                "\u2260 0",
                "p",
                "Because r is significant and the scatter plot shows a linear trend, the regression line can be used to predict final exam scores",
                "rrr is significant or not",
                "Given a third-exam score (x value), can we use the line to predict the final exam score (predicted y value"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-4-testing-the-significance-of-the-correlation-coefficient",
            "paragraphs": [
                {
                    "context": " Null Hypothesis: H0: \u03c1 = 0  Alternate Hypothesis: Ha: \u03c1 \u2260 0 \n\nWHAT THE HYPOTHESES MEAN IN WORDS:\n\nNull Hypothesis H0: The population correlation coefficient IS NOT significantly different from zero. There IS NOT a significant linear relationship (correlation) between x and y in the population. Alternate Hypothesis Ha: The population correlation coefficient IS significantly DIFFERENT FROM zero. There IS A SIGNIFICANT LINEAR RELATIONSHIP (correlation) between x and y in the population. \n\nDRAWING A CONCLUSION:There are two methods of making the decision. The two methods are equivalent and give the same result.\n\nMethod 1: Using the p-value Method 2: Using a table of critical values \n\nIn this chapter of this textbook, we will always use a significance level of 5%, \u03b1 = 0.05",
                    "id": "C_763947_1"
                }
            ],
            "section_title": "PERFORMING THE HYPOTHESIS TEST",
            "chapter_learning_objectives": [],
            "chapter_summary": "Linear regression is a procedure for fitting a straight line of the form \u0177 = a + bx to data. The conditions for regression are:Linear In the population, there is a linear relationship that models the average value of y for different values of x. Independent The residuals are assumed to be independent. Normal The y values are distributed normally for any value of x. Equal variance The standard deviation of the y values is equal for each x value. Random The data are produced from a well-designed random sample or randomized experiment. The slope b and intercept a of the least-squares line estimate the slope \u03b2 and intercept \u03b1 of the population (true) regression line. To estimate the population standard deviation of y, \u03c3, use the standard deviation of the residuals, s. $$\\(s = \\sqrt{\\frac{SEE}{n - 2}}\\)$$. The variable \u03c1 (rho) is the population correlation coefficient. To test the null hypothesis H0: \u03c1 = hypothesized value, use a linear regression t-test.  The most common null hypothesis is H0: \u03c1 = 0 which indicates there is no linear relationship between x and y in the population. The TI-83, 83+, 84, 84+ calculator function LinRegTTest can perform this test (STATS TESTS LinRegTTest).",
            "chapter_introduction": "The correlation coefficient, r, tells us about the strength and direction of the linear relationship between x and y. However, the reliability of the linear model also depends on how many observed data points are in the sample. We need to look at both the value of the correlation coefficient r and the sample size n, together.\n\nWe perform a hypothesis test of the  \"significance of the correlation coefficient\"  to decide whether the linear relationship in the sample data is strong enough to use to model the relationship in the population.\n\nThe sample data are used to compute r, the correlation coefficient for the sample. If we had data for the entire population, we could find the population correlation coefficient. But because we have only sample data, we cannot calculate the population correlation coefficient. The sample correlation coefficient, r, is our estimate of the unknown population correlation coefficient.\n\nThe symbol for the population correlation coefficient is \u03c1, the Greek letter \"rho.\" \u03c1 = population correlation coefficient (unknown) r = sample correlation coefficient (known; calculated from sample data) \n\nThe hypothesis test lets us decide whether the value of the population correlation coefficient \u03c1 is \"close to zero\" or \"significantly different from zero\". We decide this based on the sample correlation coefficient r and the sample size n.\n\nIf the test concludes that the correlation coefficient is significantly different from zero, we say that the correlation coefficient is \"significant.\"\n\nConclusion: There is sufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is significantly different from zero. What the conclusion means: There is a significant linear relationship between x and y. We can use the regression line to model the linear relationship between x and y in the population. \n\nIf the test concludes that the correlation coefficient is not significantly different from zero (it is close to zero), we say that correlation coefficient is \"not significant\".\n\nConclusion:  \"There is insufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is not significantly different from zero.\" What the conclusion means: There is not a significant linear relationship between x and y. Therefore, we CANNOT use the regression line to model a linear relationship between x and y in the population. ",
            "bold_terms": [
                "significance of the correlation coefficient",
                "Null Hypothesis: H0: \u03c1 = 0",
                "Alternate Hypothesis: Ha: \u03c1 \u2260 0",
                "Null Hypothesis H0",
                "Alternate Hypothesis Ha",
                "Method 1: Using the p-value",
                "Method 2: Using a table of critical values",
                "\u2260 0",
                "p",
                "Because r is significant and the scatter plot shows a linear trend, the regression line can be used to predict final exam scores",
                "rrr is significant or not",
                "Given a third-exam score (x value), can we use the line to predict the final exam score (predicted y value"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-4-testing-the-significance-of-the-correlation-coefficient",
            "paragraphs": [
                {
                    "context": "Using the p-value method, you could choose any appropriate significance level you want; you are not limited to using \u03b1 = 0.05. But the table of critical values provided in this textbook assumes that we are using a significance level of 5%, \u03b1 = 0.05. (If we wanted to use a different significance level than 5% with the critical value method, we would need different tables of critical values that are not provided in this textbook.)",
                    "id": "C_288025_2"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "Linear regression is a procedure for fitting a straight line of the form \u0177 = a + bx to data. The conditions for regression are:Linear In the population, there is a linear relationship that models the average value of y for different values of x. Independent The residuals are assumed to be independent. Normal The y values are distributed normally for any value of x. Equal variance The standard deviation of the y values is equal for each x value. Random The data are produced from a well-designed random sample or randomized experiment. The slope b and intercept a of the least-squares line estimate the slope \u03b2 and intercept \u03b1 of the population (true) regression line. To estimate the population standard deviation of y, \u03c3, use the standard deviation of the residuals, s. $$\\(s = \\sqrt{\\frac{SEE}{n - 2}}\\)$$. The variable \u03c1 (rho) is the population correlation coefficient. To test the null hypothesis H0: \u03c1 = hypothesized value, use a linear regression t-test.  The most common null hypothesis is H0: \u03c1 = 0 which indicates there is no linear relationship between x and y in the population. The TI-83, 83+, 84, 84+ calculator function LinRegTTest can perform this test (STATS TESTS LinRegTTest).",
            "chapter_introduction": "The correlation coefficient, r, tells us about the strength and direction of the linear relationship between x and y. However, the reliability of the linear model also depends on how many observed data points are in the sample. We need to look at both the value of the correlation coefficient r and the sample size n, together.\n\nWe perform a hypothesis test of the  \"significance of the correlation coefficient\"  to decide whether the linear relationship in the sample data is strong enough to use to model the relationship in the population.\n\nThe sample data are used to compute r, the correlation coefficient for the sample. If we had data for the entire population, we could find the population correlation coefficient. But because we have only sample data, we cannot calculate the population correlation coefficient. The sample correlation coefficient, r, is our estimate of the unknown population correlation coefficient.\n\nThe symbol for the population correlation coefficient is \u03c1, the Greek letter \"rho.\" \u03c1 = population correlation coefficient (unknown) r = sample correlation coefficient (known; calculated from sample data) \n\nThe hypothesis test lets us decide whether the value of the population correlation coefficient \u03c1 is \"close to zero\" or \"significantly different from zero\". We decide this based on the sample correlation coefficient r and the sample size n.\n\nIf the test concludes that the correlation coefficient is significantly different from zero, we say that the correlation coefficient is \"significant.\"\n\nConclusion: There is sufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is significantly different from zero. What the conclusion means: There is a significant linear relationship between x and y. We can use the regression line to model the linear relationship between x and y in the population. \n\nIf the test concludes that the correlation coefficient is not significantly different from zero (it is close to zero), we say that correlation coefficient is \"not significant\".\n\nConclusion:  \"There is insufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is not significantly different from zero.\" What the conclusion means: There is not a significant linear relationship between x and y. Therefore, we CANNOT use the regression line to model a linear relationship between x and y in the population. ",
            "bold_terms": [
                "significance of the correlation coefficient",
                "Null Hypothesis: H0: \u03c1 = 0",
                "Alternate Hypothesis: Ha: \u03c1 \u2260 0",
                "Null Hypothesis H0",
                "Alternate Hypothesis Ha",
                "Method 1: Using the p-value",
                "Method 2: Using a table of critical values",
                "\u2260 0",
                "p",
                "Because r is significant and the scatter plot shows a linear trend, the regression line can be used to predict final exam scores",
                "rrr is significant or not",
                "Given a third-exam score (x value), can we use the line to predict the final exam score (predicted y value"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-4-testing-the-significance-of-the-correlation-coefficient",
            "paragraphs": [
                {
                    "context": "To calculate the p-value using LinRegTTEST:On the LinRegTTEST input screen, on the line prompt for \u03b2 or \u03c1, highlight \"\u2260 0\"The output screen shows the p-value on the line that reads \"p =\".(Most computer statistical software can calculate the p-value.)\n\nAn alternative way to calculate the p-value (p) given by LinRegTTest is the command 2*tcdf(abs(t),10^99, n-2) in 2nd DISTR.\n\nH0: \u03c1 = 0\n\nHa: \u03c1 \u2260 0\n\n\u03b1 = 0.05\n\nThe p-value is 0.026 (from LinRegTTest on your calculator or from computer software). The p-value, 0.026, is less than the significance level of \u03b1 = 0.05. Decision: Reject the Null Hypothesis H0 Conclusion: There is sufficient evidence to conclude that there is a significant linear relationship between the third exam score (x) and the final exam score (y) because the correlation coefficient is significantly different from zero. \n\nBecause r is significant and the scatter plot shows a linear trend, the regression line can be used to predict final exam scores.",
                    "id": "C_269717_4"
                }
            ],
            "section_title": "Using the TI-83, 83+, 84, 84+ Calculator",
            "chapter_learning_objectives": [],
            "chapter_summary": "Linear regression is a procedure for fitting a straight line of the form \u0177 = a + bx to data. The conditions for regression are:Linear In the population, there is a linear relationship that models the average value of y for different values of x. Independent The residuals are assumed to be independent. Normal The y values are distributed normally for any value of x. Equal variance The standard deviation of the y values is equal for each x value. Random The data are produced from a well-designed random sample or randomized experiment. The slope b and intercept a of the least-squares line estimate the slope \u03b2 and intercept \u03b1 of the population (true) regression line. To estimate the population standard deviation of y, \u03c3, use the standard deviation of the residuals, s. $$\\(s = \\sqrt{\\frac{SEE}{n - 2}}\\)$$. The variable \u03c1 (rho) is the population correlation coefficient. To test the null hypothesis H0: \u03c1 = hypothesized value, use a linear regression t-test.  The most common null hypothesis is H0: \u03c1 = 0 which indicates there is no linear relationship between x and y in the population. The TI-83, 83+, 84, 84+ calculator function LinRegTTest can perform this test (STATS TESTS LinRegTTest).",
            "chapter_introduction": "The correlation coefficient, r, tells us about the strength and direction of the linear relationship between x and y. However, the reliability of the linear model also depends on how many observed data points are in the sample. We need to look at both the value of the correlation coefficient r and the sample size n, together.\n\nWe perform a hypothesis test of the  \"significance of the correlation coefficient\"  to decide whether the linear relationship in the sample data is strong enough to use to model the relationship in the population.\n\nThe sample data are used to compute r, the correlation coefficient for the sample. If we had data for the entire population, we could find the population correlation coefficient. But because we have only sample data, we cannot calculate the population correlation coefficient. The sample correlation coefficient, r, is our estimate of the unknown population correlation coefficient.\n\nThe symbol for the population correlation coefficient is \u03c1, the Greek letter \"rho.\" \u03c1 = population correlation coefficient (unknown) r = sample correlation coefficient (known; calculated from sample data) \n\nThe hypothesis test lets us decide whether the value of the population correlation coefficient \u03c1 is \"close to zero\" or \"significantly different from zero\". We decide this based on the sample correlation coefficient r and the sample size n.\n\nIf the test concludes that the correlation coefficient is significantly different from zero, we say that the correlation coefficient is \"significant.\"\n\nConclusion: There is sufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is significantly different from zero. What the conclusion means: There is a significant linear relationship between x and y. We can use the regression line to model the linear relationship between x and y in the population. \n\nIf the test concludes that the correlation coefficient is not significantly different from zero (it is close to zero), we say that correlation coefficient is \"not significant\".\n\nConclusion:  \"There is insufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is not significantly different from zero.\" What the conclusion means: There is not a significant linear relationship between x and y. Therefore, we CANNOT use the regression line to model a linear relationship between x and y in the population. ",
            "bold_terms": [
                "significance of the correlation coefficient",
                "Null Hypothesis: H0: \u03c1 = 0",
                "Alternate Hypothesis: Ha: \u03c1 \u2260 0",
                "Null Hypothesis H0",
                "Alternate Hypothesis Ha",
                "Method 1: Using the p-value",
                "Method 2: Using a table of critical values",
                "\u2260 0",
                "p",
                "Because r is significant and the scatter plot shows a linear trend, the regression line can be used to predict final exam scores",
                "rrr is significant or not",
                "Given a third-exam score (x value), can we use the line to predict the final exam score (predicted y value"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-4-testing-the-significance-of-the-correlation-coefficient",
            "paragraphs": [
                {
                    "context": "The 95% Critical Values of the Sample Correlation Coefficient Table can be used to give you a good idea of whether the computed value of rrr is significant or not. Compare r to the appropriate critical value in the table. If r is not between the positive and negative critical values, then the correlation coefficient is significant. If r is significant, then you may want to use the line for prediction.",
                    "id": "C_227403_5"
                }
            ],
            "section_title": "METHOD 2: Using a table of Critical Values to make a decision",
            "chapter_learning_objectives": [],
            "chapter_summary": "Linear regression is a procedure for fitting a straight line of the form \u0177 = a + bx to data. The conditions for regression are:Linear In the population, there is a linear relationship that models the average value of y for different values of x. Independent The residuals are assumed to be independent. Normal The y values are distributed normally for any value of x. Equal variance The standard deviation of the y values is equal for each x value. Random The data are produced from a well-designed random sample or randomized experiment. The slope b and intercept a of the least-squares line estimate the slope \u03b2 and intercept \u03b1 of the population (true) regression line. To estimate the population standard deviation of y, \u03c3, use the standard deviation of the residuals, s. $$\\(s = \\sqrt{\\frac{SEE}{n - 2}}\\)$$. The variable \u03c1 (rho) is the population correlation coefficient. To test the null hypothesis H0: \u03c1 = hypothesized value, use a linear regression t-test.  The most common null hypothesis is H0: \u03c1 = 0 which indicates there is no linear relationship between x and y in the population. The TI-83, 83+, 84, 84+ calculator function LinRegTTest can perform this test (STATS TESTS LinRegTTest).",
            "chapter_introduction": "The correlation coefficient, r, tells us about the strength and direction of the linear relationship between x and y. However, the reliability of the linear model also depends on how many observed data points are in the sample. We need to look at both the value of the correlation coefficient r and the sample size n, together.\n\nWe perform a hypothesis test of the  \"significance of the correlation coefficient\"  to decide whether the linear relationship in the sample data is strong enough to use to model the relationship in the population.\n\nThe sample data are used to compute r, the correlation coefficient for the sample. If we had data for the entire population, we could find the population correlation coefficient. But because we have only sample data, we cannot calculate the population correlation coefficient. The sample correlation coefficient, r, is our estimate of the unknown population correlation coefficient.\n\nThe symbol for the population correlation coefficient is \u03c1, the Greek letter \"rho.\" \u03c1 = population correlation coefficient (unknown) r = sample correlation coefficient (known; calculated from sample data) \n\nThe hypothesis test lets us decide whether the value of the population correlation coefficient \u03c1 is \"close to zero\" or \"significantly different from zero\". We decide this based on the sample correlation coefficient r and the sample size n.\n\nIf the test concludes that the correlation coefficient is significantly different from zero, we say that the correlation coefficient is \"significant.\"\n\nConclusion: There is sufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is significantly different from zero. What the conclusion means: There is a significant linear relationship between x and y. We can use the regression line to model the linear relationship between x and y in the population. \n\nIf the test concludes that the correlation coefficient is not significantly different from zero (it is close to zero), we say that correlation coefficient is \"not significant\".\n\nConclusion:  \"There is insufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is not significantly different from zero.\" What the conclusion means: There is not a significant linear relationship between x and y. Therefore, we CANNOT use the regression line to model a linear relationship between x and y in the population. ",
            "bold_terms": [
                "significance of the correlation coefficient",
                "Null Hypothesis: H0: \u03c1 = 0",
                "Alternate Hypothesis: Ha: \u03c1 \u2260 0",
                "Null Hypothesis H0",
                "Alternate Hypothesis Ha",
                "Method 1: Using the p-value",
                "Method 2: Using a table of critical values",
                "\u2260 0",
                "p",
                "Because r is significant and the scatter plot shows a linear trend, the regression line can be used to predict final exam scores",
                "rrr is significant or not",
                "Given a third-exam score (x value), can we use the line to predict the final exam score (predicted y value"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-4-testing-the-significance-of-the-correlation-coefficient",
            "paragraphs": [
                {
                    "context": "Consider the third exam/final exam example.The line of best fit is: \u0177 = \u2013173.51+4.83x  with r = 0.6631 and there are n = 11 data points. Can the regression line be used for prediction? Given a third-exam score (x value), can we use the line to predict the final exam score (predicted y value)?\n\nH0: \u03c1 = 0  Ha: \u03c1 \u2260 0  \u03b1 = 0.05 \n\nUse the \"95% Critical Value\" table for r with df = n \u2013 2 = 11 \u2013 2 = 9. The critical values are \u20130.602 and +0.602 Since 0.6631 > 0.602, r is significant. Decision: Reject the null hypothesis. Conclusion:There is sufficient evidence to conclude that there is a significant  linear relationship between the third exam score (x) and the final exam score (y) because the correlation coefficient is significantly different from zero. \n\nBecause r is significant and the scatter plot shows a linear trend, the regression line can be used to predict final exam scores.",
                    "id": "C_106067_6"
                }
            ],
            "section_title": "THIRD-EXAM vs FINAL-EXAM EXAMPLE: critical value method",
            "chapter_learning_objectives": [],
            "chapter_summary": "Linear regression is a procedure for fitting a straight line of the form \u0177 = a + bx to data. The conditions for regression are:Linear In the population, there is a linear relationship that models the average value of y for different values of x. Independent The residuals are assumed to be independent. Normal The y values are distributed normally for any value of x. Equal variance The standard deviation of the y values is equal for each x value. Random The data are produced from a well-designed random sample or randomized experiment. The slope b and intercept a of the least-squares line estimate the slope \u03b2 and intercept \u03b1 of the population (true) regression line. To estimate the population standard deviation of y, \u03c3, use the standard deviation of the residuals, s. $$\\(s = \\sqrt{\\frac{SEE}{n - 2}}\\)$$. The variable \u03c1 (rho) is the population correlation coefficient. To test the null hypothesis H0: \u03c1 = hypothesized value, use a linear regression t-test.  The most common null hypothesis is H0: \u03c1 = 0 which indicates there is no linear relationship between x and y in the population. The TI-83, 83+, 84, 84+ calculator function LinRegTTest can perform this test (STATS TESTS LinRegTTest).",
            "chapter_introduction": "The correlation coefficient, r, tells us about the strength and direction of the linear relationship between x and y. However, the reliability of the linear model also depends on how many observed data points are in the sample. We need to look at both the value of the correlation coefficient r and the sample size n, together.\n\nWe perform a hypothesis test of the  \"significance of the correlation coefficient\"  to decide whether the linear relationship in the sample data is strong enough to use to model the relationship in the population.\n\nThe sample data are used to compute r, the correlation coefficient for the sample. If we had data for the entire population, we could find the population correlation coefficient. But because we have only sample data, we cannot calculate the population correlation coefficient. The sample correlation coefficient, r, is our estimate of the unknown population correlation coefficient.\n\nThe symbol for the population correlation coefficient is \u03c1, the Greek letter \"rho.\" \u03c1 = population correlation coefficient (unknown) r = sample correlation coefficient (known; calculated from sample data) \n\nThe hypothesis test lets us decide whether the value of the population correlation coefficient \u03c1 is \"close to zero\" or \"significantly different from zero\". We decide this based on the sample correlation coefficient r and the sample size n.\n\nIf the test concludes that the correlation coefficient is significantly different from zero, we say that the correlation coefficient is \"significant.\"\n\nConclusion: There is sufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is significantly different from zero. What the conclusion means: There is a significant linear relationship between x and y. We can use the regression line to model the linear relationship between x and y in the population. \n\nIf the test concludes that the correlation coefficient is not significantly different from zero (it is close to zero), we say that correlation coefficient is \"not significant\".\n\nConclusion:  \"There is insufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is not significantly different from zero.\" What the conclusion means: There is not a significant linear relationship between x and y. Therefore, we CANNOT use the regression line to model a linear relationship between x and y in the population. ",
            "bold_terms": [
                "significance of the correlation coefficient",
                "Null Hypothesis: H0: \u03c1 = 0",
                "Alternate Hypothesis: Ha: \u03c1 \u2260 0",
                "Null Hypothesis H0",
                "Alternate Hypothesis Ha",
                "Method 1: Using the p-value",
                "Method 2: Using a table of critical values",
                "\u2260 0",
                "p",
                "Because r is significant and the scatter plot shows a linear trend, the regression line can be used to predict final exam scores",
                "rrr is significant or not",
                "Given a third-exam score (x value), can we use the line to predict the final exam score (predicted y value"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-4-testing-the-significance-of-the-correlation-coefficient",
            "paragraphs": [
                {
                    "context": "Testing the significance of the correlation coefficient requires that certain assumptions about the data are satisfied. The premise of this test is that the data are a sample of observed points taken from a larger population.  We have not examined the entire population because it is not possible or feasible to do so.  We are examining the sample to draw a conclusion about whether the linear relationship that we see between x and y in the sample data provides strong enough evidence so that we can conclude that there is a linear relationship between x and y in the population.\n\nThe regression line equation that we calculate from the sample data gives the best-fit line for our particular sample. We want to use this best-fit line for the sample as an estimate of the best-fit line for the population. Examining the scatterplot and testing the significance of the correlation coefficient helps us determine if it is appropriate to do this.",
                    "id": "C_987933_7"
                }
            ],
            "section_title": "Assumptions in Testing the Significance of the Correlation Coefficient",
            "chapter_learning_objectives": [],
            "chapter_summary": "Linear regression is a procedure for fitting a straight line of the form \u0177 = a + bx to data. The conditions for regression are:Linear In the population, there is a linear relationship that models the average value of y for different values of x. Independent The residuals are assumed to be independent. Normal The y values are distributed normally for any value of x. Equal variance The standard deviation of the y values is equal for each x value. Random The data are produced from a well-designed random sample or randomized experiment. The slope b and intercept a of the least-squares line estimate the slope \u03b2 and intercept \u03b1 of the population (true) regression line. To estimate the population standard deviation of y, \u03c3, use the standard deviation of the residuals, s. $$\\(s = \\sqrt{\\frac{SEE}{n - 2}}\\)$$. The variable \u03c1 (rho) is the population correlation coefficient. To test the null hypothesis H0: \u03c1 = hypothesized value, use a linear regression t-test.  The most common null hypothesis is H0: \u03c1 = 0 which indicates there is no linear relationship between x and y in the population. The TI-83, 83+, 84, 84+ calculator function LinRegTTest can perform this test (STATS TESTS LinRegTTest).",
            "chapter_introduction": "The correlation coefficient, r, tells us about the strength and direction of the linear relationship between x and y. However, the reliability of the linear model also depends on how many observed data points are in the sample. We need to look at both the value of the correlation coefficient r and the sample size n, together.\n\nWe perform a hypothesis test of the  \"significance of the correlation coefficient\"  to decide whether the linear relationship in the sample data is strong enough to use to model the relationship in the population.\n\nThe sample data are used to compute r, the correlation coefficient for the sample. If we had data for the entire population, we could find the population correlation coefficient. But because we have only sample data, we cannot calculate the population correlation coefficient. The sample correlation coefficient, r, is our estimate of the unknown population correlation coefficient.\n\nThe symbol for the population correlation coefficient is \u03c1, the Greek letter \"rho.\" \u03c1 = population correlation coefficient (unknown) r = sample correlation coefficient (known; calculated from sample data) \n\nThe hypothesis test lets us decide whether the value of the population correlation coefficient \u03c1 is \"close to zero\" or \"significantly different from zero\". We decide this based on the sample correlation coefficient r and the sample size n.\n\nIf the test concludes that the correlation coefficient is significantly different from zero, we say that the correlation coefficient is \"significant.\"\n\nConclusion: There is sufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is significantly different from zero. What the conclusion means: There is a significant linear relationship between x and y. We can use the regression line to model the linear relationship between x and y in the population. \n\nIf the test concludes that the correlation coefficient is not significantly different from zero (it is close to zero), we say that correlation coefficient is \"not significant\".\n\nConclusion:  \"There is insufficient evidence to conclude that there is a significant  linear relationship between x and y because the correlation coefficient is not significantly different from zero.\" What the conclusion means: There is not a significant linear relationship between x and y. Therefore, we CANNOT use the regression line to model a linear relationship between x and y in the population. ",
            "bold_terms": [
                "significance of the correlation coefficient",
                "Null Hypothesis: H0: \u03c1 = 0",
                "Alternate Hypothesis: Ha: \u03c1 \u2260 0",
                "Null Hypothesis H0",
                "Alternate Hypothesis Ha",
                "Method 1: Using the p-value",
                "Method 2: Using a table of critical values",
                "\u2260 0",
                "p",
                "Because r is significant and the scatter plot shows a linear trend, the regression line can be used to predict final exam scores",
                "rrr is significant or not",
                "Given a third-exam score (x value), can we use the line to predict the final exam score (predicted y value"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-6-outliers",
            "paragraphs": [
                {
                    "context": "We could guess at outliers by looking at a graph of the scatterplot and best fit-line. However, we would like some guideline as to how far away a point needs to be in order to be considered an outlier.  As a rough rule of thumb, we can flag any point that is located further than two standard deviations above or below the best-fit line as an outlier. The standard deviation used is the standard deviation of the residuals or errors.\n\nWe can do this visually in the scatter plot by drawing an extra pair of lines that are two standard deviations above and below the best-fit line. Any data points that are outside this extra pair of lines are flagged as potential outliers. Or we can do this numerically by calculating each residual and comparing it to twice the standard deviation. On the TI-83, 83+, or 84+, the graphical approach is easier. The graphical procedure is shown first, followed by the numerical calculations. You would generally need to use only one of these methods.",
                    "id": "C_497817_0"
                }
            ],
            "section_title": "Identifying Outliers",
            "chapter_learning_objectives": [],
            "chapter_summary": "To determine if a point is an outlier, do one of the following:        Input the following equations into the TI 83, 83+,84, 84+:        y1=a+bxy2=a+bx+2sy3=a+bx\u22122sy1=a+bxy2=a+bx+2sy3=a+bx\u22122sy1=a+bxy2=a+bx+2sy3=a+bx\u22122s where s is the standard deviation of the residualsIf any point is above y2 or below y3 then the point is considered to be an outlier. Use the residuals and compare their absolute values to 2s where s is the standard deviation of the residuals. If the absolute value of any residual is greater than or equal to 2s, then the corresponding point is an outlier. Note: The calculator function LinRegTTest (STATS TESTS LinRegTTest) calculates s. ",
            "chapter_introduction": "In some data sets, there are values (observed data points) called outliers. Outliers are observed data points that are far from the least squares line. They have large \"errors\", where the \"error\" or residual is the vertical distance from the line to the point. \n\nOutliers need to be examined closely. Sometimes, for some reason or another, they should not be included in the analysis of the data. It is possible that an outlier is a result of erroneous data. Other times, an outlier mayhold valuable information about the population under study and should remain included in the data. The key is to examine carefully what causes a data point to be an outlier.\n\nBesides outliers, a sample may contain one or a few points that are called influential points. Influential points are observed data points that are far from the other observed data points in the horizontal direction. These points may have a big effect on the slope of the regression line. To begin to identify an influential point, you can remove it from the data set and see if the slope of the regression line is changed significantly.\n\nComputers and many calculators can be used to identify outliers from the data. Computer output for regression analysis will often identify both outliers and influential points so that you can examine them.",
            "bold_terms": [
                "observed data points",
                "outliers",
                "Outliers are observed data points that are far from the least squares line",
                "influential points",
                "As a rough rule of thumb, we can flag any point that is located further than two standard deviations above or below the best-fit line as an outlier",
                "square each |y \u2013 \u0177",
                "Then, add (sum) all the |y \u2013 \u0177| squared terms",
                "SSE",
                "Next, calculate s, the standard deviation of all the y \u2013 \u0177 = \u03b5 values where n = the total number of data points",
                "potential outlier",
                "at least",
                "Therefore, the data point (65,175) is a potential outlier"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-6-outliers",
            "paragraphs": [
                {
                    "context": "In Table 12.5, the first two columns are the third-exam and final-exam data. The third column shows the predicted \u0177 values calculated from the line of best fit: \u0177 = \u2013173.5 + 4.83x. The residuals, or errors, have been calculated in the fourth column of the table: observed y value\u2212predicted y value = y \u2212 \u0177.\n\ns is the standard deviation of all the y \u2212 \u0177 = \u03b5 values where n = the total number of data points. If each residual is calculated and squared, and the results are added, we get the SSE. The standard deviation of the residuals is calculated from the SSE as:\n\n$$\\(s = \\sqrt{\\frac{SSE}{n - 2}}\\)$$",
                    "id": "C_665594_1"
                }
            ],
            "section_title": "Numerical Identification of Outliers",
            "chapter_learning_objectives": [],
            "chapter_summary": "To determine if a point is an outlier, do one of the following:        Input the following equations into the TI 83, 83+,84, 84+:        y1=a+bxy2=a+bx+2sy3=a+bx\u22122sy1=a+bxy2=a+bx+2sy3=a+bx\u22122sy1=a+bxy2=a+bx+2sy3=a+bx\u22122s where s is the standard deviation of the residualsIf any point is above y2 or below y3 then the point is considered to be an outlier. Use the residuals and compare their absolute values to 2s where s is the standard deviation of the residuals. If the absolute value of any residual is greater than or equal to 2s, then the corresponding point is an outlier. Note: The calculator function LinRegTTest (STATS TESTS LinRegTTest) calculates s. ",
            "chapter_introduction": "In some data sets, there are values (observed data points) called outliers. Outliers are observed data points that are far from the least squares line. They have large \"errors\", where the \"error\" or residual is the vertical distance from the line to the point. \n\nOutliers need to be examined closely. Sometimes, for some reason or another, they should not be included in the analysis of the data. It is possible that an outlier is a result of erroneous data. Other times, an outlier mayhold valuable information about the population under study and should remain included in the data. The key is to examine carefully what causes a data point to be an outlier.\n\nBesides outliers, a sample may contain one or a few points that are called influential points. Influential points are observed data points that are far from the other observed data points in the horizontal direction. These points may have a big effect on the slope of the regression line. To begin to identify an influential point, you can remove it from the data set and see if the slope of the regression line is changed significantly.\n\nComputers and many calculators can be used to identify outliers from the data. Computer output for regression analysis will often identify both outliers and influential points so that you can examine them.",
            "bold_terms": [
                "observed data points",
                "outliers",
                "Outliers are observed data points that are far from the least squares line",
                "influential points",
                "As a rough rule of thumb, we can flag any point that is located further than two standard deviations above or below the best-fit line as an outlier",
                "square each |y \u2013 \u0177",
                "Then, add (sum) all the |y \u2013 \u0177| squared terms",
                "SSE",
                "Next, calculate s, the standard deviation of all the y \u2013 \u0177 = \u03b5 values where n = the total number of data points",
                "potential outlier",
                "at least",
                "Therefore, the data point (65,175) is a potential outlier"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-6-outliers",
            "paragraphs": [
                {
                    "context": "We divide by (n \u2013 2) because the regression model involves two estimates.\n\nRather than calculate the value of s ourselves, we can find s using the computer or calculator. For this example, the calculator function LinRegTTest found s = 16.4 as the standard deviation of the residuals 35; \u201317; 16; \u20136; \u201319; 9; 3; \u20131; \u201310; \u20139; \u20131.\n\nWe are looking for all data points for which the residual is greater than 2s = 2(16.4) = 32.8 or less than \u201332.8. Compare these values to the residuals in column four of the table. The only such data point is the student who had a grade of 65 on the third exam and 175 on the final exam; the residual for this student is 35.",
                    "id": "C_323833_2"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "To determine if a point is an outlier, do one of the following:        Input the following equations into the TI 83, 83+,84, 84+:        y1=a+bxy2=a+bx+2sy3=a+bx\u22122sy1=a+bxy2=a+bx+2sy3=a+bx\u22122sy1=a+bxy2=a+bx+2sy3=a+bx\u22122s where s is the standard deviation of the residualsIf any point is above y2 or below y3 then the point is considered to be an outlier. Use the residuals and compare their absolute values to 2s where s is the standard deviation of the residuals. If the absolute value of any residual is greater than or equal to 2s, then the corresponding point is an outlier. Note: The calculator function LinRegTTest (STATS TESTS LinRegTTest) calculates s. ",
            "chapter_introduction": "In some data sets, there are values (observed data points) called outliers. Outliers are observed data points that are far from the least squares line. They have large \"errors\", where the \"error\" or residual is the vertical distance from the line to the point. \n\nOutliers need to be examined closely. Sometimes, for some reason or another, they should not be included in the analysis of the data. It is possible that an outlier is a result of erroneous data. Other times, an outlier mayhold valuable information about the population under study and should remain included in the data. The key is to examine carefully what causes a data point to be an outlier.\n\nBesides outliers, a sample may contain one or a few points that are called influential points. Influential points are observed data points that are far from the other observed data points in the horizontal direction. These points may have a big effect on the slope of the regression line. To begin to identify an influential point, you can remove it from the data set and see if the slope of the regression line is changed significantly.\n\nComputers and many calculators can be used to identify outliers from the data. Computer output for regression analysis will often identify both outliers and influential points so that you can examine them.",
            "bold_terms": [
                "observed data points",
                "outliers",
                "Outliers are observed data points that are far from the least squares line",
                "influential points",
                "As a rough rule of thumb, we can flag any point that is located further than two standard deviations above or below the best-fit line as an outlier",
                "square each |y \u2013 \u0177",
                "Then, add (sum) all the |y \u2013 \u0177| squared terms",
                "SSE",
                "Next, calculate s, the standard deviation of all the y \u2013 \u0177 = \u03b5 values where n = the total number of data points",
                "potential outlier",
                "at least",
                "Therefore, the data point (65,175) is a potential outlier"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-6-outliers",
            "paragraphs": [
                {
                    "context": "Numerically and graphically, we have identified the point (65, 175) as an outlier. We should re-examine the data for this point to see if there are any problems with the data. If there is an error, we should fix the error if possible, or delete the data. If the data is correct, we would leave it in the data set. For this problem, we will suppose that we examined the data and found that this outlier data was an error. Therefore we will continue on and delete the outlier, so that we can explore how it affects the results, as a learning experience.\n\nCompute a new best-fit line and correlation coefficient using the ten remaining points:On the TI-83, TI-83+, TI-84+ calculators, delete the outlier from L1 and L2. Using the LinRegTTest, the new line of best fit and the correlation coefficient are:\n\n\u0177 = \u2013355.19 + 7.39x and r = 0.9121\n\nThe new line with r = 0.9121 is a stronger correlation than the original (r = 0.6631) because r = 0.9121 is closer to one. This means that the new line is a better fit to the ten remaining data values. The line can better predict the final exam score given the third exam score.",
                    "id": "C_104814_3"
                }
            ],
            "section_title": "How does the outlier affect the best fit line",
            "chapter_learning_objectives": [],
            "chapter_summary": "To determine if a point is an outlier, do one of the following:        Input the following equations into the TI 83, 83+,84, 84+:        y1=a+bxy2=a+bx+2sy3=a+bx\u22122sy1=a+bxy2=a+bx+2sy3=a+bx\u22122sy1=a+bxy2=a+bx+2sy3=a+bx\u22122s where s is the standard deviation of the residualsIf any point is above y2 or below y3 then the point is considered to be an outlier. Use the residuals and compare their absolute values to 2s where s is the standard deviation of the residuals. If the absolute value of any residual is greater than or equal to 2s, then the corresponding point is an outlier. Note: The calculator function LinRegTTest (STATS TESTS LinRegTTest) calculates s. ",
            "chapter_introduction": "In some data sets, there are values (observed data points) called outliers. Outliers are observed data points that are far from the least squares line. They have large \"errors\", where the \"error\" or residual is the vertical distance from the line to the point. \n\nOutliers need to be examined closely. Sometimes, for some reason or another, they should not be included in the analysis of the data. It is possible that an outlier is a result of erroneous data. Other times, an outlier mayhold valuable information about the population under study and should remain included in the data. The key is to examine carefully what causes a data point to be an outlier.\n\nBesides outliers, a sample may contain one or a few points that are called influential points. Influential points are observed data points that are far from the other observed data points in the horizontal direction. These points may have a big effect on the slope of the regression line. To begin to identify an influential point, you can remove it from the data set and see if the slope of the regression line is changed significantly.\n\nComputers and many calculators can be used to identify outliers from the data. Computer output for regression analysis will often identify both outliers and influential points so that you can examine them.",
            "bold_terms": [
                "observed data points",
                "outliers",
                "Outliers are observed data points that are far from the least squares line",
                "influential points",
                "As a rough rule of thumb, we can flag any point that is located further than two standard deviations above or below the best-fit line as an outlier",
                "square each |y \u2013 \u0177",
                "Then, add (sum) all the |y \u2013 \u0177| squared terms",
                "SSE",
                "Next, calculate s, the standard deviation of all the y \u2013 \u0177 = \u03b5 values where n = the total number of data points",
                "potential outlier",
                "at least",
                "Therefore, the data point (65,175) is a potential outlier"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-6-outliers",
            "paragraphs": [
                {
                    "context": "If you do not have the function LinRegTTest, then you can calculate the outlier in the first example by doing the following.First, square each |y \u2013 \u0177|\n\nThe squares are 352; 172; 162; 62; 192; 92; 32; 12; 102; 92; 12\n\nThen, add (sum) all the |y \u2013 \u0177| squared terms using the formula\n\n$$\\(\\overset{11}{\\underset{i~ = ~1}{\\Sigma}}\\left( \\left| y_{i} - {\\hat{y}}_{i} \\right| \\right)^{2} = \\overset{11}{\\underset{i~ = ~1}{\\Sigma}}\\varepsilon_{i}{}^{2}\\)$$ (Recall that yi \u2013 \u0177i = \u03b5i.)\n\n= 352 + 172 + 162 + 62 + 192 + 92 + 32 + 12 + 102 + 92 + 12\n\n = 2440 =  SSE. The result, SSE is the Sum of Squared Errors.\n\nNext, calculate s, the standard deviation of all the y \u2013 \u0177 = \u03b5 values where n = the total number of data points.\n\nThe calculation is $$\\(s = \\sqrt{\\frac{\\text{SSE}}{n\u20132}}\\)$$.\n\nFor the third exam/final exam problem, $$\\(s = \\sqrt{\\frac{2440}{11\u20132}} = 16.47\\)$$.\n\nNext, multiply s by 2:(2)(16.47) = 32.9432.94 is 2 standard deviations away from the mean of the y \u2013 \u0177 values.\n\nIf we were to measure the vertical distance from any data point to the corresponding point on the line of best fit and that distance is at least 2s, then we would consider the data point to be \"too far\" from the line of best fit. We call that point a potential outlier.\n\nFor the example, if any of the |y \u2013 \u0177| values are at least 32.94, the corresponding (x, y) data point is a potential outlier.\n\nFor the third exam/final exam problem, all the |y \u2013 \u0177|'s are less than 31.29 except for the first one which is 35.\n\n35 > 31.29 That is, |y \u2013 \u0177| \u2265 (2)(s)\n\nThe point which corresponds to |y \u2013 \u0177| = 35 is (65, 175). Therefore, the data point (65,175) is a potential outlier. For this example, we will delete it. (Remember, we do not always delete an outlier.)",
                    "id": "C_243386_4"
                }
            ],
            "section_title": "Numerical Identification of Outliers: Calculating s and Finding Outliers Manually",
            "chapter_learning_objectives": [],
            "chapter_summary": "To determine if a point is an outlier, do one of the following:        Input the following equations into the TI 83, 83+,84, 84+:        y1=a+bxy2=a+bx+2sy3=a+bx\u22122sy1=a+bxy2=a+bx+2sy3=a+bx\u22122sy1=a+bxy2=a+bx+2sy3=a+bx\u22122s where s is the standard deviation of the residualsIf any point is above y2 or below y3 then the point is considered to be an outlier. Use the residuals and compare their absolute values to 2s where s is the standard deviation of the residuals. If the absolute value of any residual is greater than or equal to 2s, then the corresponding point is an outlier. Note: The calculator function LinRegTTest (STATS TESTS LinRegTTest) calculates s. ",
            "chapter_introduction": "In some data sets, there are values (observed data points) called outliers. Outliers are observed data points that are far from the least squares line. They have large \"errors\", where the \"error\" or residual is the vertical distance from the line to the point. \n\nOutliers need to be examined closely. Sometimes, for some reason or another, they should not be included in the analysis of the data. It is possible that an outlier is a result of erroneous data. Other times, an outlier mayhold valuable information about the population under study and should remain included in the data. The key is to examine carefully what causes a data point to be an outlier.\n\nBesides outliers, a sample may contain one or a few points that are called influential points. Influential points are observed data points that are far from the other observed data points in the horizontal direction. These points may have a big effect on the slope of the regression line. To begin to identify an influential point, you can remove it from the data set and see if the slope of the regression line is changed significantly.\n\nComputers and many calculators can be used to identify outliers from the data. Computer output for regression analysis will often identify both outliers and influential points so that you can examine them.",
            "bold_terms": [
                "observed data points",
                "outliers",
                "Outliers are observed data points that are far from the least squares line",
                "influential points",
                "As a rough rule of thumb, we can flag any point that is located further than two standard deviations above or below the best-fit line as an outlier",
                "square each |y \u2013 \u0177",
                "Then, add (sum) all the |y \u2013 \u0177| squared terms",
                "SSE",
                "Next, calculate s, the standard deviation of all the y \u2013 \u0177 = \u03b5 values where n = the total number of data points",
                "potential outlier",
                "at least",
                "Therefore, the data point (65,175) is a potential outlier"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "12-6-outliers",
            "paragraphs": [
                {
                    "context": "When outliers are deleted, the researcher should either record that data was deleted, and why, or the researcher should provide results both with and without the deleted data. If data is erroneous and the correct values are known (e.g., student one actually scored a 70 instead of a 65), then this correction can be made to the data.\n\nThe next step is to compute a new best-fit line using the ten remainingpoints. The new line of best fit and the correlation coefficient are:\n\n\u0177 = \u2013355.19 + 7.39x and r = 0.9121",
                    "id": "C_240444_5"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "To determine if a point is an outlier, do one of the following:        Input the following equations into the TI 83, 83+,84, 84+:        y1=a+bxy2=a+bx+2sy3=a+bx\u22122sy1=a+bxy2=a+bx+2sy3=a+bx\u22122sy1=a+bxy2=a+bx+2sy3=a+bx\u22122s where s is the standard deviation of the residualsIf any point is above y2 or below y3 then the point is considered to be an outlier. Use the residuals and compare their absolute values to 2s where s is the standard deviation of the residuals. If the absolute value of any residual is greater than or equal to 2s, then the corresponding point is an outlier. Note: The calculator function LinRegTTest (STATS TESTS LinRegTTest) calculates s. ",
            "chapter_introduction": "In some data sets, there are values (observed data points) called outliers. Outliers are observed data points that are far from the least squares line. They have large \"errors\", where the \"error\" or residual is the vertical distance from the line to the point. \n\nOutliers need to be examined closely. Sometimes, for some reason or another, they should not be included in the analysis of the data. It is possible that an outlier is a result of erroneous data. Other times, an outlier mayhold valuable information about the population under study and should remain included in the data. The key is to examine carefully what causes a data point to be an outlier.\n\nBesides outliers, a sample may contain one or a few points that are called influential points. Influential points are observed data points that are far from the other observed data points in the horizontal direction. These points may have a big effect on the slope of the regression line. To begin to identify an influential point, you can remove it from the data set and see if the slope of the regression line is changed significantly.\n\nComputers and many calculators can be used to identify outliers from the data. Computer output for regression analysis will often identify both outliers and influential points so that you can examine them.",
            "bold_terms": [
                "observed data points",
                "outliers",
                "Outliers are observed data points that are far from the least squares line",
                "influential points",
                "As a rough rule of thumb, we can flag any point that is located further than two standard deviations above or below the best-fit line as an outlier",
                "square each |y \u2013 \u0177",
                "Then, add (sum) all the |y \u2013 \u0177| squared terms",
                "SSE",
                "Next, calculate s, the standard deviation of all the y \u2013 \u0177 = \u03b5 values where n = the total number of data points",
                "potential outlier",
                "at least",
                "Therefore, the data point (65,175) is a potential outlier"
            ],
            "chapter_concept": [
                {
                    "name": "Coefficient of Correlation",
                    "description": "a measure developed by Karl Pearson (early 1900s) that gives the strength of association between the independent variable and the dependent variable; the formula is:    $$\\[r = \\frac{n\\Sigma(xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{\\left\\lbrack {n\\Sigma x^{2} - {(\\Sigma x)}^{2}} \\right\\rbrack\\left\\lbrack {n\\Sigma y^{2} - {(\\Sigma y)}^{2}} \\right\\rbrack}}\\]$$ where n is the number of data points. The coefficient cannot be more than 1 or less than \u20131. The closer the coefficient is to \u00b11, the stronger the evidence of a significant linear relationship between x and y.    "
                },
                {
                    "name": "Outlier",
                    "description": "an observation that does not fit the rest of the data"
                }
            ]
        },
        {
            "title": "13-1-one-way-anova",
            "paragraphs": [
                {
                    "context": "The null hypothesis is simply that all the group population means are the same. The alternative hypothesis is that at least one pair of means is different. For example, if there are k groups:\n\nH0: \u03bc1 = \u03bc2 = \u03bc3 = ... = \u03bck\n\nHa: At least two of the group means \u03bc1, \u03bc2, \u03bc3, ..., \u03bck are not equal. That is, \u03bci \u2260 \u03bcj for some i \u2260 j. \n\nThe graphs, a set of box plots representing the distribution of values with the group means indicated by a horizontal line through the box, help in the understanding of the hypothesis test. In the first graph (red box plots), H0: \u03bc1 = \u03bc2 = \u03bc3 and the three populations have the same distribution if the null hypothesis is true.  The variance of the combined data is approximately the same as the variance of each of the populations.\n\nIf the null hypothesis is false, then the variance of the combined data is larger which is caused by the different means as shown in the second graph (green box plots).",
                    "id": "C_112121_0"
                }
            ],
            "section_title": "The Null and Alternative Hypotheses",
            "chapter_learning_objectives": [],
            "chapter_summary": "Analysis of variance extends the comparison of two groups to several, each a level of a categorical variable (factor). Samples from each group are independent, and must be randomly selected from normal populations with equal variances. We test the null hypothesis of equal means of the response in every group versus the alternative hypothesis of one or more group means being different from the others. A one-way ANOVA hypothesis test determines if several population means are equal. The distribution for the test is the F distribution with two different degrees of freedom.",
            "chapter_introduction": "The purpose of a one-way ANOVA test is to determine the existence of a statistically significant difference among several group means. The test actually uses variances to help determine if the means are equal or not. In order to perform a one-way ANOVA test, there are five basic assumptions to be fulfilled:\n\nEach population from which a sample is taken is assumed to be normal. All samples are randomly selected and independent.  The populations are assumed to have equal standard deviations (or variances). The factor is a categorical variable. The response is a numerical variable. ",
            "bold_terms": [
                "variances",
                "assumptions",
                "equal standard deviations",
                "or variances"
            ],
            "chapter_concept": [
                {
                    "name": "Analysis of Variance",
                    "description": "also referred to as ANOVA, is a method of testing whether or not the means of three or more populations are equal. The method is applicable if:all populations of interest are normally distributed.the populations have equal standard deviations.samples (not necessarily of the same size) are randomly and independently selected from each population.The test statistic for analysis of variance is the F-ratio."
                },
                {
                    "name": "One-Way ANOVA",
                    "description": "a method of testing whether or not the means of three or more populations are equal; the method is applicable if:all populations of interest are normally distributed.the populations have equal standard deviations.samples (not necessarily of the same size) are randomly and independently selected from each population.there is one independent variable and one dependent variable.The test statistic for analysis of variance is the F-ratio."
                },
                {
                    "name": "Variance",
                    "description": "mean of the squared deviations from the mean; the square of the standard deviation. For a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "13-2-the-f-distribution-and-the-f-ratio",
            "paragraphs": [
                {
                    "context": "The F distribution is derived from the Student's t-distribution. The values of the F distribution are squares of the corresponding values of the t-distribution. One-Way ANOVA expands the t-test for comparing more than two groups. The scope of that derivation is beyond the level of this course. It is preferable to use ANOVA when there are more than two groups instead of performing pairwise t-tests because performing multiple tests introduces the likelihood of making a Type 1 error.\n\nTo calculate the F ratio, two estimates of the variance are made.\n\nVariance between samples: An estimate of \u03c32 that is the variance of the sample means multiplied by n (when the sample sizes are the same.). If the samples are different sizes, the variance between samples is weighted to account for the different sample sizes. The variance is also called variation due to treatment or explained variation. Variance within samples: An estimate of \u03c32 that is the average of the sample variances (also known as a pooled variance). When the sample sizes are different, the variance within samples is weighted. The variance is also called the variation due to error or unexplained variation. \n\nSSbetween = the sum of squares that represents the variation among the different samples SSwithin = the sum of squares that represents the variation within samples that is due to chance. \n\nTo find a \"sum of squares\" means to add together squared quantities that, in somecases, may be weighted. We used sum of squares to calculate the sample variance andthe sample standard deviation in Descriptive Statistics.\n\nMS means \"mean square.\" MSbetween is the variance between groups, and MSwithin is the variance within groups.\n\nCalculation of Sum of Squares and Mean Square\n\nk = the number of different groups nj = the size of the jth group sj = the sum of the values in the jth group n = total number of all the values combined (total\u00a0sample\u00a0size: \u2211nj) x = one value: \u2211x = \u2211sj Sum of squares of all values from every group combined: \u2211x2 Between group variability: SStotal = \u2211x2 \u2013  $$\\(\\frac{\\left( {\\sum x^{2}} \\right)}{n}\\)$$ Total sum of squares: \u2211x2 \u2013  $$\\(\\frac{\\left( {\\sum x} \\right)^{2}}{n}\\)$$ Explained variation: sum of squares representing variation among the different samples: SSbetween =  $$\\(\\sum\\left\\lbrack \\frac{{(s_{j})}^{2}}{n_{j}} \\right\\rbrack - \\frac{{(\\sum s_{j})}^{2}}{n}\\)$$ Unexplained variation: sum of squares representing variation within samples due to chance:  $$\\(SS_{\\text{within}} = SS_{\\text{total}}\u2013SS_{\\text{between}}\\)$$  df's for different groups (df's for the numerator): df = k \u2013 1 Equation for errors within samples (df's for the denominator): dfwithin = n \u2013 k Mean square (variance estimate) explained by the different groups: MSbetween =  $$\\(\\frac{SS_{\\text{between}}}{df_{\\text{between}}}\\)$$  Mean square (variance estimate) that is due to chance (unexplained): MSwithin =  $$\\(\\frac{SS_{\\text{within}}}{df_{\\text{within}}}\\)$$  \n\nMSbetween and MSwithin can be written as follows:\n\n $$\\(MS_{\\text{between}} = \\frac{SS_{\\text{between}}}{df_{\\text{between}}} = \\frac{SS_{\\text{between}}}{k - 1}\\)$$   $$\\(MS_{within} = \\frac{SS_{within}}{df_{within}} = \\frac{SS_{within}}{n - k}\\)$$ \n\nThe one-way ANOVA test depends on the fact that MSbetween can be influenced by population differences among means of the several groups. Since MSwithin compares values of each group to its own group mean, the fact that group means might be different does not affect MSwithin.\n\nThe null hypothesis says that all groups are samples from populations having the same normal distribution. The alternate hypothesis says that at least two of the sample groups come from populations with different normal distributions. If the null hypothesis is true, MSbetween and MSwithin should both estimate the same value.",
                    "id": "C_896130_0"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "Analysis of variance compares the means of a response variable for several groups. ANOVA compares the variation within each group to the variation of the mean of each group. The ratio of these two is the F statistic from an F distribution with (number of groups \u2013 1) as the numerator degrees of freedom and (number of observations \u2013 number of groups) as the denominator degrees of freedom.  These statistics are summarized in the ANOVA table.",
            "chapter_introduction": "The distribution used for the hypothesis test is a new one. It is called the F distribution, named after Sir Ronald Fisher, an English statistician. The F statistic is a ratio (a fraction). There are two sets of degrees of freedom; one for the numerator and one for the denominator.\n\nFor example, if F follows an F distribution and the number of degrees of freedom for the numerator is four, and the number of degrees of freedom for the denominator is ten, then F ~ F4,10.",
            "bold_terms": [
                "F distribution",
                "F ratio",
                "Variance between samples",
                "variation due to treatment or explained variation",
                "Variance within samples",
                "variation due to error or unexplained variation",
                "sum of squares",
                "mean square",
                "Calculation of Sum of Squares and Mean Square",
                "The one-way ANOVA hypothesis test is always right-tailed"
            ],
            "chapter_concept": [
                {
                    "name": "Analysis of Variance",
                    "description": "also referred to as ANOVA, is a method of testing whether or not the means of three or more populations are equal. The method is applicable if:all populations of interest are normally distributed.the populations have equal standard deviations.samples (not necessarily of the same size) are randomly and independently selected from each population.The test statistic for analysis of variance is the F-ratio."
                },
                {
                    "name": "One-Way ANOVA",
                    "description": "a method of testing whether or not the means of three or more populations are equal; the method is applicable if:all populations of interest are normally distributed.the populations have equal standard deviations.samples (not necessarily of the same size) are randomly and independently selected from each population.there is one independent variable and one dependent variable.The test statistic for analysis of variance is the F-ratio."
                },
                {
                    "name": "Variance",
                    "description": "mean of the squared deviations from the mean; the square of the standard deviation. For a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "13-2-the-f-distribution-and-the-f-ratio",
            "paragraphs": [
                {
                    "context": "The null hypothesis says that all the group population means are equal. The hypothesis of equal means implies that the populations have the same normal distribution, because it is assumed that the populations are normal and that they have equal variances.\n\nF-Ratio or F Statistic$$\\(F = \\frac{MS_{\\text{between}}}{MS_{\\text{within}}}\\)$$\n\nIf MSbetween and MSwithin estimate the same value (following the belief that H0 is true), then the F-ratio should be approximately equal to one. Mostly, just sampling errors would contribute to variations away from one. As it turns out, MSbetween consists of the population variance plus a variance produced from the differences between the samples. MSwithin is an estimate of the population variance. Since variances are always positive, if the null hypothesis is false, MSbetween will generally be larger than MSwithin.Then the F-ratio will be larger than one. However, if the population effect is small, it is not unlikely that MSwithin will be larger in a given sample.\n\nThe foregoing calculations were done with groups of different sizes. If the groups are the same size, the calculations simplify somewhat and the F-ratio can be written as:\n\nF-Ratio Formula when the groups are the same size$$\\(F = \\frac{n \\cdot s_{\\overline{x}}{}^{2}}{s^{2}{}_{\\text{pooled}}}\\)$$ \n\nData are typically put into a table for easy viewing.  One-Way ANOVA results are often displayed in this manner by computer software.\n\nThe one-way ANOVA hypothesis test is always right-tailed because larger F-values are way out in the right tail of the F-distribution curve and tend to make us reject H0.",
                    "id": "C_310665_1"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "Analysis of variance compares the means of a response variable for several groups. ANOVA compares the variation within each group to the variation of the mean of each group. The ratio of these two is the F statistic from an F distribution with (number of groups \u2013 1) as the numerator degrees of freedom and (number of observations \u2013 number of groups) as the denominator degrees of freedom.  These statistics are summarized in the ANOVA table.",
            "chapter_introduction": "The distribution used for the hypothesis test is a new one. It is called the F distribution, named after Sir Ronald Fisher, an English statistician. The F statistic is a ratio (a fraction). There are two sets of degrees of freedom; one for the numerator and one for the denominator.\n\nFor example, if F follows an F distribution and the number of degrees of freedom for the numerator is four, and the number of degrees of freedom for the denominator is ten, then F ~ F4,10.",
            "bold_terms": [
                "F distribution",
                "F ratio",
                "Variance between samples",
                "variation due to treatment or explained variation",
                "Variance within samples",
                "variation due to error or unexplained variation",
                "sum of squares",
                "mean square",
                "Calculation of Sum of Squares and Mean Square",
                "The one-way ANOVA hypothesis test is always right-tailed"
            ],
            "chapter_concept": [
                {
                    "name": "Analysis of Variance",
                    "description": "also referred to as ANOVA, is a method of testing whether or not the means of three or more populations are equal. The method is applicable if:all populations of interest are normally distributed.the populations have equal standard deviations.samples (not necessarily of the same size) are randomly and independently selected from each population.The test statistic for analysis of variance is the F-ratio."
                },
                {
                    "name": "One-Way ANOVA",
                    "description": "a method of testing whether or not the means of three or more populations are equal; the method is applicable if:all populations of interest are normally distributed.the populations have equal standard deviations.samples (not necessarily of the same size) are randomly and independently selected from each population.there is one independent variable and one dependent variable.The test statistic for analysis of variance is the F-ratio."
                },
                {
                    "name": "Variance",
                    "description": "mean of the squared deviations from the mean; the square of the standard deviation. For a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "13-2-the-f-distribution-and-the-f-ratio",
            "paragraphs": [
                {
                    "context": "The notation for the F distribution is F ~ Fdf(num),df(denom)\n\nwhere df(num) = dfbetween and df(denom) = dfwithin \n\nThe mean for the F distribution is  $$\\(\\mu = \\frac{df(denom)}{df(denom)\u20132}\\)$$ ",
                    "id": "C_149505_2"
                }
            ],
            "section_title": "Notation",
            "chapter_learning_objectives": [],
            "chapter_summary": "Analysis of variance compares the means of a response variable for several groups. ANOVA compares the variation within each group to the variation of the mean of each group. The ratio of these two is the F statistic from an F distribution with (number of groups \u2013 1) as the numerator degrees of freedom and (number of observations \u2013 number of groups) as the denominator degrees of freedom.  These statistics are summarized in the ANOVA table.",
            "chapter_introduction": "The distribution used for the hypothesis test is a new one. It is called the F distribution, named after Sir Ronald Fisher, an English statistician. The F statistic is a ratio (a fraction). There are two sets of degrees of freedom; one for the numerator and one for the denominator.\n\nFor example, if F follows an F distribution and the number of degrees of freedom for the numerator is four, and the number of degrees of freedom for the denominator is ten, then F ~ F4,10.",
            "bold_terms": [
                "F distribution",
                "F ratio",
                "Variance between samples",
                "variation due to treatment or explained variation",
                "Variance within samples",
                "variation due to error or unexplained variation",
                "sum of squares",
                "mean square",
                "Calculation of Sum of Squares and Mean Square",
                "The one-way ANOVA hypothesis test is always right-tailed"
            ],
            "chapter_concept": [
                {
                    "name": "Analysis of Variance",
                    "description": "also referred to as ANOVA, is a method of testing whether or not the means of three or more populations are equal. The method is applicable if:all populations of interest are normally distributed.the populations have equal standard deviations.samples (not necessarily of the same size) are randomly and independently selected from each population.The test statistic for analysis of variance is the F-ratio."
                },
                {
                    "name": "One-Way ANOVA",
                    "description": "a method of testing whether or not the means of three or more populations are equal; the method is applicable if:all populations of interest are normally distributed.the populations have equal standard deviations.samples (not necessarily of the same size) are randomly and independently selected from each population.there is one independent variable and one dependent variable.The test statistic for analysis of variance is the F-ratio."
                },
                {
                    "name": "Variance",
                    "description": "mean of the squared deviations from the mean; the square of the standard deviation. For a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "13-3-facts-about-the-f-distribution",
            "paragraphs": [
                {
                    "context": "From the class, create four groups of the same size as follows: men under 22, men at least 22, women under 22, women at least 22. Have each member of each group record the number of states in the United States he or she has visited. Run an ANOVA test to determine if the average number of states visited in the four groups are the same. Test at a 1% level of significance. Use one of the solution sheets in Appendix E Solution Sheets.",
                    "id": "C_453226_0"
                }
            ],
            "section_title": "Collaborative Exercise",
            "chapter_learning_objectives": [],
            "chapter_summary": "The graph of the F distribution is always positive and skewed right, though the shape can be mounded or exponential depending on the combination of numerator and denominator degrees of freedom. The F statistic is the ratio of a measure of the variation in the group means to a similar measure of the variation within the groups. If the null hypothesis is correct, then the numerator should be small compared to the denominator. A small F statistic will result, and the area under the F curve to the right will be large, representing a large p-value. When the null hypothesis of equal group means is incorrect, then the numerator should be large compared to the denominator, giving a large F statistic and a small area (small p-value) to the right of the statistic under the F curve.When the data have unequal group sizes (unbalanced data), then techniques from 13.2 The F Distribution and the F-Ratio need to be used for hand calculations. In the case of balanced data (the groups are the same size) however, simplified calculations based on group means and variances may be used. In practice, of course, software is usually employed in the analysis. As in any analysis, graphs of various sorts should be used in conjunction with numerical techniques. Always look of your data!",
            "chapter_introduction": "Here are some facts about the F distribution.\n\nThe curve is not symmetrical but skewed to the right. There is a different curve for each set of dfs. The F statistic is greater than or equal to zero. As the degrees of freedom for the numerator and for the denominator get larger, the curve approximates the normal. Other uses for the F distribution include comparing two variances and two-way Analysis of Variance. Two-Way Analysis is beyond the scope of this chapter. ",
            "bold_terms": [
                "Here are some facts about the F distribution"
            ],
            "chapter_concept": [
                {
                    "name": "Analysis of Variance",
                    "description": "also referred to as ANOVA, is a method of testing whether or not the means of three or more populations are equal. The method is applicable if:all populations of interest are normally distributed.the populations have equal standard deviations.samples (not necessarily of the same size) are randomly and independently selected from each population.The test statistic for analysis of variance is the F-ratio."
                },
                {
                    "name": "One-Way ANOVA",
                    "description": "a method of testing whether or not the means of three or more populations are equal; the method is applicable if:all populations of interest are normally distributed.the populations have equal standard deviations.samples (not necessarily of the same size) are randomly and independently selected from each population.there is one independent variable and one dependent variable.The test statistic for analysis of variance is the F-ratio."
                },
                {
                    "name": "Variance",
                    "description": "mean of the squared deviations from the mean; the square of the standard deviation. For a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        },
        {
            "title": "13-4-test-of-two-variances",
            "paragraphs": [
                {
                    "context": "The F ratio could also be $$\\(\\frac{{(s_{2})}^{2}}{{(s_{1})}^{2}}\\)$$. It depends on Ha and on which sample variance is larger.\n\nIf the two populations have equal variances, then $$\\(s_{1}^{2}\\)$$ and $$\\(s_{2}^{2}\\)$$ are close in value and $$\\(F = \\frac{{(s_{1})}^{2}}{{(s_{2})}^{2}}\\)$$ is close to one. But if the two population variances are very different, $$\\(s_{1}^{2}\\)$$ and $$\\(s_{2}^{2}\\)$$ tend to be very different, too. Choosing $$\\(s_{1}^{2}\\)$$ as the larger sample variance causes the ratio $$\\(\\frac{{(s_{1})}^{2}}{{(s_{2})}^{2}}\\)$$ to be greater than one. If $$\\(s_{1}^{2}\\)$$ and $$\\(s_{2}^{2}\\)$$ are far apart, then $$\\(F = \\frac{{(s_{1})}^{2}}{{(s_{2})}^{2}}\\)$$ is a large number.\n\nTherefore, if F is close to one, the evidence favors the null hypothesis (the two population variances are equal). But if F is much larger than one, then the evidence is against the null hypothesis. A test of two variances may be left, right, or two-tailed.",
                    "id": "C_123837_0"
                }
            ],
            "section_title": "Note",
            "chapter_learning_objectives": [],
            "chapter_summary": "The F test for the equality of two variances rests heavily on the assumption of normal distributions. The test is unreliable if this assumption is not met. If both distributions are normal, then the ratio of the two sample variances is distributed as an F statistic, with numerator and denominator degrees of freedom that are one less than the samples sizes of the corresponding two groups. A test of two variances hypothesis test determines if two variances are the same. The distribution for the hypothesis test is the F distribution with two different degrees of freedom.",
            "chapter_introduction": "Another of the uses of the F distribution is testing two variances. It is often desirable to compare two variances rather than two averages. For instance, college administrators would like two college professors grading exams to have the same variation in their grading. In order for a lid to fit a container, the variation in the lid and the container should be the same. A supermarket might be interested in the variability of check-out times for two checkers.\n\nIn order to perform a F test of two variances, it is important that the following are true:\n\nThe populations from which the two samples are drawn are normally distributed. The two populations are independent of each other. \n\nUnlike most other tests in this book, the F test for equality of two variances is very sensitive to deviations from normality. If the two distributions are not normal, the test can give higher p-values than it should, or lower ones, in ways that are unpredictable. Many texts suggest that students not use this test at all, but in the interest of completeness we include it here.\n\nSuppose we sample randomly from two independent normal populations. Let $$\\(\\sigma_{1}^{2}\\)$$ and $$\\(\\sigma_{2}^{2}\\)$$ be the population variances and $$\\(s_{1}^{2}\\)$$ and $$\\(s_{2}^{2}\\)$$ be the sample variances. Let thesample sizes be n1 and n2. Since we are interested in comparing the two sample variances, we use the F ratio:\n\n$$\\(F = \\frac{\\left\\lbrack \\frac{{(s_{1})}^{2}}{{(\\sigma_{1})}^{2}} \\right\\rbrack}{\\left\\lbrack \\frac{{(s_{2})}^{2}}{{(\\sigma_{2})}^{2}} \\right\\rbrack}\\)$$\n\nF has the distribution F ~ F(n1 \u2013 1, n2 \u2013 1)\n\nwhere n1 \u2013 1 are the degrees of freedom for the numerator and n2 \u2013 1 are the degrees of freedom for the denominator.\n\nIf the null hypothesis is $$\\(\\sigma_{1}^{2} = \\sigma_{2}^{2}\\)$$, then the F Ratio becomes $$\\(F = \\frac{\\left\\lbrack \\frac{{(s_{1})}^{2}}{{(\\sigma_{1})}^{2}} \\right\\rbrack}{\\left\\lbrack \\frac{{(s_{2})}^{2}}{{(\\sigma_{2})}^{2}} \\right\\rbrack} = \\frac{{(s_{1})}^{2}}{{(s_{2})}^{2}}\\)$$.",
            "bold_terms": [
                "A test of two variances may be left, right, or two-tailed"
            ],
            "chapter_concept": [
                {
                    "name": "Analysis of Variance",
                    "description": "also referred to as ANOVA, is a method of testing whether or not the means of three or more populations are equal. The method is applicable if:all populations of interest are normally distributed.the populations have equal standard deviations.samples (not necessarily of the same size) are randomly and independently selected from each population.The test statistic for analysis of variance is the F-ratio."
                },
                {
                    "name": "One-Way ANOVA",
                    "description": "a method of testing whether or not the means of three or more populations are equal; the method is applicable if:all populations of interest are normally distributed.the populations have equal standard deviations.samples (not necessarily of the same size) are randomly and independently selected from each population.there is one independent variable and one dependent variable.The test statistic for analysis of variance is the F-ratio."
                },
                {
                    "name": "Variance",
                    "description": "mean of the squared deviations from the mean; the square of the standard deviation. For a set of data, a deviation can be represented as x \u2013 $$\\(\\overline{x}\\)$$ where x is a value of the data and $$\\(\\overline{x}\\)$$ is the sample mean. The sample variance is equal to the sum of the squares of the deviations divided by the difference of the sample size and one."
                }
            ]
        }
    ]
}